{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3ceecd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-27T01:46:45.044670Z",
     "iopub.status.busy": "2026-01-27T01:46:45.044151Z",
     "iopub.status.idle": "2026-01-27T01:46:52.544802Z",
     "shell.execute_reply": "2026-01-27T01:46:52.544071Z"
    },
    "papermill": {
     "duration": 7.508814,
     "end_time": "2026-01-27T01:46:52.546284",
     "exception": false,
     "start_time": "2026-01-27T01:46:45.037470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/open-clip-dependencies-2/timm-1.0.22-py3-none-any.whl\r\n",
      "Installing collected packages: timm\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.19\r\n",
      "    Uninstalling timm-1.0.19:\r\n",
      "      Successfully uninstalled timm-1.0.19\r\n",
      "Successfully installed timm-1.0.22\r\n",
      "Processing /kaggle/input/protobuf528-1209/protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 6.33.0\r\n",
      "    Uninstalling protobuf-6.33.0:\r\n",
      "      Successfully uninstalled protobuf-6.33.0\r\n",
      "Successfully installed protobuf-5.28.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps /kaggle/input/open-clip-dependencies-2/timm-1.0.22-py3-none-any.whl\n",
    "!pip install --no-deps /kaggle/input/protobuf528-1209/protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6ce3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:46:52.558351Z",
     "iopub.status.busy": "2026-01-27T01:46:52.558100Z",
     "iopub.status.idle": "2026-01-27T01:46:52.569228Z",
     "shell.execute_reply": "2026-01-27T01:46:52.568459Z"
    },
    "papermill": {
     "duration": 0.018519,
     "end_time": "2026-01-27T01:46:52.570277",
     "exception": false,
     "start_time": "2026-01-27T01:46:52.551758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing infer_single.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile infer_single.py\n",
    "\n",
    "# üì¶\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.amp import autocast, GradScaler       \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "\n",
    "dir = Path('/kaggle/input/csiro-biomass')\n",
    "DIRS = {\n",
    "    \"dir\"  : dir,\n",
    "    \"train\": Path(dir, \"train\"),\n",
    "    \"test\" : Path(dir, \"test\"),\n",
    "    \"model\": Path('/kaggle/input/single-1209-swa-models'),\n",
    "    \"data\" : Path(\"/kaggle/working/\"),\n",
    "}\n",
    "\n",
    "\n",
    "def show_df_info(df, name: str):\n",
    "    print(f\"üìä {name:<16} shape: {str(df.shape):<16}  ÂàóÂêç: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "def move_column_first(df, col_name):\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(f\"Âàó '{col_name}' ‰∏çÂ≠òÂú®‰∫é DataFrame ‰∏≠„ÄÇ\")\n",
    "\n",
    "    cols = [col_name] + [c for c in df.columns if c != col_name]\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def setup_seed(seed, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "# Model \n",
    "class MySingleStreamModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                backbone_name=\"convnext_tiny\", \n",
    "                pretrained=True, \n",
    "                config = None):\n",
    "        super().__init__()\n",
    "        print(\"Current backbone:\", backbone_name)\n",
    "        img_size = (config[\"img_size\"], config.get(\"img_width\", config[\"img_size\"]))\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            img_size=img_size\n",
    "        )\n",
    "        in_dim = self.backbone.num_features\n",
    "\n",
    "        params = list(self.backbone.parameters())\n",
    "        freeze_until = int(len(params) * config[\"freeze_ratio\"])\n",
    "        for i, p in enumerate(params):\n",
    "            p.requires_grad = i >= freeze_until \n",
    "\n",
    "        self.feature_dim = in_dim\n",
    "        print(\"feature dim = \", self.feature_dim)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.feature_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1)\n",
    "            )\n",
    "        self.head_green  = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead   = make_head()\n",
    "        self.head_gdm = make_head()\n",
    "        self.head_total = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.backbone(img)\n",
    "        \n",
    "        G = self.softplus(self.head_green(feat))\n",
    "        C = self.softplus(self.head_clover(feat))\n",
    "        D = self.softplus(self.head_dead(feat))\n",
    "        # G = torch.where(G < 0.4, torch.zeros_like(G), G)\n",
    "        # C = torch.where(C < 0.4, torch.zeros_like(C), C)\n",
    "        # D = torch.where(D < 0.4, torch.zeros_like(D), D)\n",
    "        GDM   = self.softplus(self.head_gdm(feat))\n",
    "        Total = self.softplus(self.head_total(feat))\n",
    "\n",
    "        preds = torch.cat([G, C, D, GDM, Total], dim=1)\n",
    "        return preds\n",
    "\n",
    "    def compute_loss(self, preds, targets):\n",
    "        preds = preds.view(-1, 5)\n",
    "        targets = targets.view(-1, 5)\n",
    "        weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5], device=preds.device)\n",
    "        y_true_flat = targets.view(-1)\n",
    "        y_pred_flat = preds.view(-1)\n",
    "        w_flat = torch.cat([\n",
    "            torch.full_like(targets[:, i], weights[i], device=preds.device)\n",
    "            for i in range(5)\n",
    "        ])\n",
    "        y_mean = torch.sum(w_flat * y_true_flat) / torch.sum(w_flat)\n",
    "        ss_res = torch.sum(w_flat * (y_true_flat - y_pred_flat) ** 2)\n",
    "        ss_tot = torch.sum(w_flat * (y_true_flat - y_mean) ** 2)\n",
    "        loss = ss_res / ss_tot\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SingleStreamDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, config, pre_transform=None, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.target_cols = config[\"target_cols\"]\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = Path(self.image_dir, str(row[\"image_path\"]))\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to read image: {img_path} ({e})\")\n",
    "            image = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "\n",
    "        image = np.array(image)\n",
    "        if self.pre_transform:\n",
    "            image = self.pre_transform(image=image)[\"image\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if self.target_cols is not None:\n",
    "            targets = torch.tensor(\n",
    "                row[self.target_cols].astype(float).values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            return image, targets\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "\n",
    "def get_pre_transforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=(0.8, 1.2), \n",
    "                contrast_limit=(0.8, 1.2),   \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.ColorJitter(p=0.7)\n",
    "        ], p=0.4),\n",
    "    ])\n",
    "\n",
    "\n",
    "def _get_resize_dims(config):\n",
    "    height = config[\"img_size\"]\n",
    "    width = int(config.get(\"img_width\", config[\"img_size\"]))\n",
    "    return height, width\n",
    "\n",
    "\n",
    "def get_train_transforms(config):\n",
    "    height, width = _get_resize_dims(config)\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(config):\n",
    "    height, width = _get_resize_dims(config)\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_tta_transforms(config):\n",
    "    height, width = _get_resize_dims(config)\n",
    "    return {\n",
    "        \"base\": A.Compose([\n",
    "            A.Resize(height, width),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        \"hflip\": A.Compose([\n",
    "            A.HorizontalFlip(p=1.0)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "\n",
    "config = {\n",
    "    # ‚öôÔ∏è basic train params\n",
    "    \"seed\"                           : 43,  \n",
    "    \"freeze_ratio\"                   : 0.8,\n",
    "    \"num_workers\"                    : 4,\n",
    "    \"prefetch_factor\"                : 3,\n",
    "    \"batch_size\"                     : 4,\n",
    "    \"img_size\"                       : 1024,\n",
    "    \"img_ratio\"                      : 2.0,\n",
    "    \"backbone_name\"                  : \"vit_large_patch16_dinov3_qkvb.lvd1689m\",\n",
    "\n",
    "    \"target_cols\": [\n",
    "        \"Dry_Green_g\",\n",
    "        \"Dry_Clover_g\",\n",
    "        \"Dry_Dead_g\",\n",
    "        \"GDM_g\",\n",
    "        \"Dry_Total_g\"\n",
    "    ]\n",
    "}\n",
    "config[\"img_width\"] = int(config[\"img_size\"] * config.get(\"img_ratio\", 1.0))\n",
    "isPREDICT   = True\n",
    "DEBUG       = False\n",
    "\n",
    "\n",
    "def load_and_prepare_test_df():\n",
    "    df_file_path = Path(DIRS[\"dir\"]) / \"test.csv\"\n",
    "    df = pd.read_csv(df_file_path)\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "    df = move_column_first(df, \"ID\")\n",
    "    df[\"target\"] = 0  \n",
    "    df_targets = (\n",
    "        df.pivot_table(index=\"ID\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None\n",
    "    df_meta = df[[\"ID\", \"image_path\"]].drop_duplicates(subset=\"ID\")\n",
    "    df_test = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_test, \"df_test\")\n",
    "    print(f\"‚úÖ Test set loaded: {df_test.shape}\")\n",
    "    return df_test\n",
    "\n",
    "\n",
    "def load_model_for_inference(model_path, device, config):\n",
    "    model = MySingleStreamModel(config[\"backbone_name\"], pretrained=False, config=config)\n",
    "    model = model.to(device).to(memory_format=torch.channels_last)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_with_model(model, dataloader, device):\n",
    "    preds_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (images, targets) in enumerate(dataloader):\n",
    "            images = images.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                preds = model(images)\n",
    "            preds_list.append(preds.cpu().numpy())\n",
    "    return np.concatenate(preds_list, axis=0)\n",
    "\n",
    "\n",
    "def predict_ensemble(df_test, pre_transform, transform, model_dir, device, config):\n",
    "    model_paths = sorted(Path(model_dir).glob(\"*.pt\"))\n",
    "    assert len(model_paths) > 0, f\"‚ùå No model files found in: {model_dir}\"\n",
    "\n",
    "    print(f\"‚úÖ Detected {len(model_paths)} ‰∏™Ê®°Âûã:\")\n",
    "    for p in model_paths:\n",
    "        print(\"   -\", p.name)\n",
    "    test_dataset = SingleStreamDataset(\n",
    "        df_test,\n",
    "        DIRS[\"dir\"],\n",
    "        config,\n",
    "        pre_transform=pre_transform,\n",
    "        transform=transform,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    fold_preds = []\n",
    "    for fold, model_path in enumerate(model_paths):\n",
    "        print(f\"Fold {fold+1}/{len(model_paths)} Êé®ÁêÜ: {model_path.name}\")\n",
    "        model = load_model_for_inference(model_path, device, config)\n",
    "        fold_pred = predict_with_model(model, test_loader, device)\n",
    "        fold_preds.append(fold_pred)\n",
    "    preds_mean = np.mean(fold_preds, axis=0)\n",
    "    df_pred = pd.DataFrame(preds_mean, columns=config[\"target_cols\"])\n",
    "    df_pred[\"ID\"] = df_test[\"ID\"]\n",
    "    df_pred = df_pred[[\"ID\"] + config[\"target_cols\"]]\n",
    "    show_df_info(df_pred, \"df_pred\")\n",
    "    return df_pred\n",
    "\n",
    "\n",
    "def generate_submission(df_pred_final):\n",
    "    ordered_target_cols = [\n",
    "        \"Dry_Green_g\",  \n",
    "        \"Dry_Clover_g\", \n",
    "        \"Dry_Dead_g\",  \n",
    "        \"GDM_g\",       \n",
    "        \"Dry_Total_g\"  \n",
    "    ]\n",
    "\n",
    "    if \"Dry_Clover_g\" in df_pred_final.columns:\n",
    "        df_pred_final[\"Dry_Clover_g\"] = df_pred_final[\"Dry_Clover_g\"] * 0.8\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Warning: Column Dry_Clover_g not found in DataFrame\")\n",
    "        \n",
    "\n",
    "    df_submit = (\n",
    "        df_pred_final.melt(\n",
    "            id_vars=\"ID\",\n",
    "            value_vars=ordered_target_cols,\n",
    "            var_name=\"target_name\",\n",
    "            value_name=\"target\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_submit[\"sample_id\"] = df_submit[\"ID\"] + \"__\" + df_submit[\"target_name\"]\n",
    "    df_submit = df_submit[[\"sample_id\", \"target\"]]\n",
    "    df_submit = df_submit.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "    print(df_submit.head(10))\n",
    "    df_submit.to_csv(\"submission1.csv\", index=False)\n",
    "    print(\"\\n‚úÖ Submission file generated: submission1.csv\")\n",
    "\n",
    "\n",
    "def run_tta_prediction(df_test, model_dir, device, config):\n",
    "    tta_transforms = get_tta_transforms(config)\n",
    "    tta_names = list(tta_transforms.keys())\n",
    "    print(f\"\\n‚úÖ Detected {len(tta_names)} TTA modes: {tta_names}\\n\")\n",
    "\n",
    "    all_preds = []\n",
    "    for name, _ in tta_transforms.items():\n",
    "        print(f\"\\nüöÄ TTA mode: {name}\")\n",
    "        if name == \"base\":\n",
    "            pre_transform = None\n",
    "            transform = tta_transforms[name]\n",
    "        else:\n",
    "            pre_transform = tta_transforms[name]\n",
    "            transform = tta_transforms[\"base\"]\n",
    "        df_pred = predict_ensemble(df_test, pre_transform, transform, model_dir, device, config)\n",
    "        all_preds.append(df_pred[config[\"target_cols\"]].values)\n",
    "\n",
    "    mean_preds = np.mean(all_preds, axis=0)\n",
    "    df_pred_final = df_pred.copy()\n",
    "    df_pred_final[config[\"target_cols\"]] = mean_preds\n",
    "    return df_pred_final\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and isPREDICT:\n",
    "    print(\"\\nüß† Starting prediction pipeline...\")\n",
    "    setup_seed(config[\"seed\"])    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    df_test = load_and_prepare_test_df()\n",
    "    print(f\"\\nCurrent dataset shape: {df_test.shape}\\n\")\n",
    "\n",
    "    model_dir = DIRS[\"model\"]\n",
    "    print(f\"Model directory loaded: {model_dir}\")\n",
    "\n",
    "    df_pred_final = run_tta_prediction(df_test, model_dir, device, config)\n",
    "    generate_submission(df_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a787bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:46:52.581352Z",
     "iopub.status.busy": "2026-01-27T01:46:52.581110Z",
     "iopub.status.idle": "2026-01-27T01:46:52.590208Z",
     "shell.execute_reply": "2026-01-27T01:46:52.589549Z"
    },
    "papermill": {
     "duration": 0.015902,
     "end_time": "2026-01-27T01:46:52.591178",
     "exception": false,
     "start_time": "2026-01-27T01:46:52.575276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing infer_dual.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile infer_dual.py\n",
    "\n",
    "# üì¶\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.amp import autocast, GradScaler       \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "dir = Path('/kaggle/input/csiro-biomass')\n",
    "DIRS = {\n",
    "    \"dir\"  : dir,\n",
    "    \"train\": Path(dir, \"train\"),\n",
    "    \"test\" : Path(dir, \"test\"),\n",
    "    \"model\": Path('/kaggle/input', \"dinvov3large-1204-cv\"),\n",
    "    \"data\" : Path(\"/kaggle/working/\"),\n",
    "}\n",
    "\n",
    "\n",
    "def setup_seed(seed, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "def show_df_info(df, name: str):\n",
    "    print(f\"üìä {name:<16} shape: {str(df.shape):<16}  ÂàóÂêç: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "def move_column_first(df, col_name):\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(f\"Âàó '{col_name}' ‰∏çÂ≠òÂú®‰∫é DataFrame ‰∏≠„ÄÇ\")\n",
    "    cols = [col_name] + [c for c in df.columns if c != col_name]\n",
    "    return df[cols]\n",
    "\n",
    "    \n",
    "class MyDualStreamModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                backbone_name=\"convnext_tiny\", \n",
    "                pretrained=True, \n",
    "                config = None):\n",
    "        super().__init__()\n",
    "        print(\"Current backbone:\", backbone_name)\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)\n",
    "        in_dim = self.backbone.num_features\n",
    "\n",
    "        params = list(self.backbone.parameters())\n",
    "        freeze_until = int(len(params) * config[\"freeze_ratio\"])\n",
    "        for i, p in enumerate(params):\n",
    "            p.requires_grad = i >= freeze_until     \n",
    "        self.fusion_dim = in_dim * 2\n",
    "        print(\"feature fusion dim = \", self.fusion_dim)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1)\n",
    "            )\n",
    "        self.head_green  = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead   = make_head()\n",
    "        self.head_gdm = make_head()\n",
    "        self.head_total = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "\n",
    "    def forward(self, img_left, img_right):\n",
    "        feat_left  = self.backbone(img_left)\n",
    "        feat_right = self.backbone(img_right)\n",
    "        fused = torch.cat([feat_left, feat_right], dim=1)\n",
    "        G = self.softplus(self.head_green(fused))\n",
    "        C = self.softplus(self.head_clover(fused))\n",
    "        D = self.softplus(self.head_dead(fused))\n",
    "        # G = torch.where(G < 0.4, torch.zeros_like(G), G)\n",
    "        # C = torch.where(C < 0.4, torch.zeros_like(C), C)\n",
    "        # D = torch.where(D < 0.4, torch.zeros_like(D), D)\n",
    "        GDM   = G + C\n",
    "        Total = G + C + D\n",
    "        preds = torch.cat([G, C, D, GDM, Total], dim=1)\n",
    "        return preds\n",
    "\n",
    "\n",
    "class DualStreamDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, config, pre_transform=None, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.target_cols = config[\"target_cols\"]\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = Path(self.image_dir, str(row[\"image_path\"]))\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to read image: {img_path} ({e})\")\n",
    "            image = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "\n",
    "        image = np.array(image)\n",
    "        if self.pre_transform:\n",
    "            image = self.pre_transform(image=image)[\"image\"]\n",
    "        h, w, _ = image.shape\n",
    "        mid = w // 2\n",
    "        img_left = image[:, :mid]\n",
    "        img_right = image[:, mid:]\n",
    "        if self.transform:\n",
    "            img_left = self.transform(image=img_left)[\"image\"]\n",
    "            img_right = self.transform(image=img_right)[\"image\"]\n",
    "        if self.target_cols is not None:\n",
    "            targets = torch.tensor(\n",
    "                row[self.target_cols].astype(float).values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            return img_left, img_right, targets\n",
    "        else:\n",
    "            return img_left, img_right\n",
    "\n",
    "\n",
    "def get_pre_transforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=(0.8, 1.2), \n",
    "                contrast_limit=(0.8, 1.2),   \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.ColorJitter(p=0.7)\n",
    "        ], p=0.4),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_train_transforms(size):\n",
    "    return A.Compose([\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(size):\n",
    "    return A.Compose([\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_tta_transforms(size):\n",
    "    return {\n",
    "        \"base\": A.Compose([\n",
    "            A.Resize(size, size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        \"hflip\": A.Compose([\n",
    "            A.HorizontalFlip(p=1.0)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"seed\"                           : 43,  \n",
    "    \"freeze_ratio\"                   : 0.8,\n",
    "    \"num_workers\"                    : 4,\n",
    "    \"prefetch_factor\"                : 3,\n",
    "    \"batch_size\"                     : 8,\n",
    "    \"img_size\"                       : 1024,\n",
    "    \"backbone_name\"                  : \"vit_large_patch16_dinov3_qkvb.lvd1689m\",\n",
    "    \"target_cols\": [\n",
    "        \"Dry_Green_g\",\n",
    "        \"Dry_Clover_g\",\n",
    "        \"Dry_Dead_g\",\n",
    "        \"GDM_g\",\n",
    "        \"Dry_Total_g\"\n",
    "    ]\n",
    "}\n",
    "isPREDICT   = True\n",
    "DEBUG       = False\n",
    "\n",
    "\n",
    "def load_and_prepare_test_df():\n",
    "    df_file_path = Path(DIRS[\"dir\"]) / \"test.csv\"\n",
    "    df = pd.read_csv(df_file_path)\n",
    "\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "    df = move_column_first(df, \"ID\")\n",
    "    df[\"target\"] = 0  \n",
    "\n",
    "    df_targets = (\n",
    "        df.pivot_table(index=\"ID\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None\n",
    "\n",
    "    df_meta = df[[\"ID\", \"image_path\"]].drop_duplicates(subset=\"ID\")\n",
    "    df_test = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_test, \"df_test\")\n",
    "\n",
    "    print(f\"‚úÖ Test set loaded: {df_test.shape}\")\n",
    "    return df_test\n",
    "\n",
    "\n",
    "def load_model_for_inference(model_path, device, config):\n",
    "    model = MyDualStreamModel(config[\"backbone_name\"], pretrained=False, config=config)\n",
    "    model = model.to(device).to(memory_format=torch.channels_last)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_with_model(model, dataloader, device):\n",
    "    preds_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (img_left, img_right, targets) in enumerate(dataloader):\n",
    "            img_left   = img_left.to(device, non_blocking=True)\n",
    "            img_right  = img_right.to(device, non_blocking=True)\n",
    "            targets    = targets.to(device, non_blocking=True)\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                preds = model(img_left, img_right)\n",
    "            preds_list.append(preds.cpu().numpy())\n",
    "    return np.concatenate(preds_list, axis=0)\n",
    "\n",
    "\n",
    "def predict_ensemble(df_test, pre_transform, transform, model_dir, device, config):\n",
    "    model_paths = sorted(Path(model_dir).glob(\"fold*.pt\"))\n",
    "    assert len(model_paths) > 0, f\"‚ùå No model files found in: {model_dir}\"\n",
    "    print(f\"‚úÖ Detected {len(model_paths)} ‰∏™Ê®°Âûã:\")\n",
    "    for p in model_paths:\n",
    "        print(\"   -\", p.name)\n",
    "    test_dataset = DualStreamDataset(\n",
    "        df_test,\n",
    "        DIRS[\"dir\"],\n",
    "        config,\n",
    "        pre_transform=pre_transform,\n",
    "        transform=transform,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    fold_preds = []\n",
    "    for fold, model_path in enumerate(model_paths):\n",
    "        print(f\"Fold {fold+1}/{len(model_paths)} Êé®ÁêÜ: {model_path.name}\")\n",
    "        model = load_model_for_inference(model_path, device, config)\n",
    "        fold_pred = predict_with_model(model, test_loader, device)\n",
    "        fold_preds.append(fold_pred)\n",
    "    preds_mean = np.mean(fold_preds, axis=0)\n",
    "    df_pred = pd.DataFrame(preds_mean, columns=config[\"target_cols\"])\n",
    "    df_pred[\"ID\"] = df_test[\"ID\"]\n",
    "    df_pred = df_pred[[\"ID\"] + config[\"target_cols\"]]\n",
    "    show_df_info(df_pred, \"df_pred\")\n",
    "    return df_pred\n",
    "\n",
    "\n",
    "def generate_submission(df_pred_final):\n",
    "    ordered_target_cols = [\n",
    "        \"Dry_Green_g\",  \n",
    "        \"Dry_Clover_g\", \n",
    "        \"Dry_Dead_g\",   \n",
    "        \"GDM_g\",        \n",
    "        \"Dry_Total_g\"   \n",
    "    ]\n",
    "    if \"Dry_Clover_g\" in df_pred_final.columns:\n",
    "        df_pred_final[\"Dry_Clover_g\"] = df_pred_final[\"Dry_Clover_g\"] * 0.8\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Warning: Column Dry_Clover_g not found in DataFrame\")\n",
    "        \n",
    "    df_submit = (\n",
    "        df_pred_final.melt(\n",
    "            id_vars=\"ID\",\n",
    "            value_vars=ordered_target_cols,\n",
    "            var_name=\"target_name\",\n",
    "            value_name=\"target\"\n",
    "        )\n",
    "    )\n",
    "    df_submit[\"sample_id\"] = df_submit[\"ID\"] + \"__\" + df_submit[\"target_name\"]\n",
    "    df_submit = df_submit[[\"sample_id\", \"target\"]]\n",
    "    df_submit = df_submit.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "    print(df_submit.head(10))\n",
    "    df_submit.to_csv(\"submission2.csv\", index=False)\n",
    "    print(\"\\n‚úÖ Submission file generated: submission2.csv\")\n",
    "\n",
    "\n",
    "def run_tta_prediction(df_test, model_dir, device, config):\n",
    "    tta_transforms = get_tta_transforms(config[\"img_size\"])\n",
    "    tta_names = list(tta_transforms.keys())\n",
    "    print(f\"\\n‚úÖ Detected {len(tta_names)} TTA modes: {tta_names}\\n\")\n",
    "    all_preds = []\n",
    "    for name, _ in tta_transforms.items():\n",
    "        print(f\"\\nüöÄ TTA mode: {name}\")\n",
    "        if name == \"base\":\n",
    "            pre_transform = None\n",
    "            transform = tta_transforms[name]\n",
    "        else:\n",
    "            pre_transform = tta_transforms[name]\n",
    "            transform = tta_transforms[\"base\"]\n",
    "        df_pred = predict_ensemble(df_test, pre_transform, transform, model_dir, device, config)\n",
    "        all_preds.append(df_pred[config[\"target_cols\"]].values)\n",
    "    mean_preds = np.mean(all_preds, axis=0)\n",
    "    df_pred_final = df_pred.copy()\n",
    "    df_pred_final[config[\"target_cols\"]] = mean_preds\n",
    "    return df_pred_final\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and isPREDICT:\n",
    "    print(\"\\nüß† Starting prediction pipeline...\")\n",
    "    setup_seed(config[\"seed\"])    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "   \n",
    "    df_test = load_and_prepare_test_df()\n",
    "    print(f\"\\nCurrent dataset shape: {df_test.shape}\\n\")\n",
    "    \n",
    "    model_dir = DIRS[\"model\"]\n",
    "    print(f\"Model directory loaded: {model_dir}\")\n",
    "\n",
    "    df_pred_final = run_tta_prediction(df_test, model_dir, device, config)\n",
    "    generate_submission(df_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f930d412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:46:52.601461Z",
     "iopub.status.busy": "2026-01-27T01:46:52.601253Z",
     "iopub.status.idle": "2026-01-27T01:49:49.720368Z",
     "shell.execute_reply": "2026-01-27T01:49:49.719659Z"
    },
    "papermill": {
     "duration": 177.130564,
     "end_time": "2026-01-27T01:49:49.726469",
     "exception": false,
     "start_time": "2026-01-27T01:46:52.595905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Single Stream\n",
      "GPU 1: Dual Stream\n",
      "single&&dual doneÔºÅ\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "CUDA_VISIBLE_DEVICES=0 python infer_single.py > log_single.txt 2>&1 &\n",
    "CUDA_VISIBLE_DEVICES=1 python infer_dual.py > log_dual.txt 2>&1 &\n",
    "echo \"GPU 0: Single Stream\"\n",
    "echo \"GPU 1: Dual Stream\"\n",
    "\n",
    "wait\n",
    "\n",
    "echo \"single&&dual doneÔºÅ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d18ceaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:49.737087Z",
     "iopub.status.busy": "2026-01-27T01:49:49.736866Z",
     "iopub.status.idle": "2026-01-27T01:49:49.857000Z",
     "shell.execute_reply": "2026-01-27T01:49:49.856346Z"
    },
    "papermill": {
     "duration": 0.126843,
     "end_time": "2026-01-27T01:49:49.858159",
     "exception": false,
     "start_time": "2026-01-27T01:49:49.731316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "üß† Starting prediction pipeline...\r\n",
      "üìä df_test          shape: (1, 7)            ÂàóÂêç: ['ID', 'image_path', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\r\n",
      "‚úÖ Test set loaded: (1, 7)\r\n",
      "\r\n",
      "Current dataset shape: (1, 7)\r\n",
      "\r\n",
      "Model directory loaded: /kaggle/input/single-1209-swa-models\r\n",
      "\r\n",
      "‚úÖ Detected 2 TTA modes: ['base', 'hflip']\r\n",
      "\r\n",
      "\r\n",
      "üöÄ TTA mode: base\r\n",
      "‚úÖ Detected 5 ‰∏™Ê®°Âûã:\r\n",
      "   - fold1_swa.pt\r\n",
      "   - fold2_swa.pt\r\n",
      "   - fold3_swa.pt\r\n",
      "   - fold4_swa.pt\r\n",
      "   - fold5_swa.pt\r\n",
      "Fold 1/5 Êé®ÁêÜ: fold1_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 2/5 Êé®ÁêÜ: fold2_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 3/5 Êé®ÁêÜ: fold3_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 4/5 Êé®ÁêÜ: fold4_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 5/5 Êé®ÁêÜ: fold5_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "\r\n",
      "üöÄ TTA mode: hflip\r\n",
      "‚úÖ Detected 5 ‰∏™Ê®°Âûã:\r\n",
      "   - fold1_swa.pt\r\n",
      "   - fold2_swa.pt\r\n",
      "   - fold3_swa.pt\r\n",
      "   - fold4_swa.pt\r\n",
      "   - fold5_swa.pt\r\n",
      "Fold 1/5 Êé®ÁêÜ: fold1_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 2/5 Êé®ÁêÜ: fold2_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 3/5 Êé®ÁêÜ: fold3_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 4/5 Êé®ÁêÜ: fold4_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Fold 5/5 Êé®ÁêÜ: fold5_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "                    sample_id     target\r\n",
      "0  ID1001187975__Dry_Clover_g   0.134021\r\n",
      "1    ID1001187975__Dry_Dead_g  28.343750\r\n",
      "2   ID1001187975__Dry_Green_g  35.392189\r\n",
      "3   ID1001187975__Dry_Total_g  63.806248\r\n",
      "4         ID1001187975__GDM_g  35.234375\r\n",
      "\r\n",
      "‚úÖ Submission file generated: submission1.csv\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1000 log_single.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23213410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:49.868984Z",
     "iopub.status.busy": "2026-01-27T01:49:49.868779Z",
     "iopub.status.idle": "2026-01-27T01:49:49.983648Z",
     "shell.execute_reply": "2026-01-27T01:49:49.983007Z"
    },
    "papermill": {
     "duration": 0.12177,
     "end_time": "2026-01-27T01:49:49.984818",
     "exception": false,
     "start_time": "2026-01-27T01:49:49.863048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "üß† Starting prediction pipeline...\r\n",
      "üìä df_test          shape: (1, 7)            ÂàóÂêç: ['ID', 'image_path', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\r\n",
      "‚úÖ Test set loaded: (1, 7)\r\n",
      "\r\n",
      "Current dataset shape: (1, 7)\r\n",
      "\r\n",
      "Model directory loaded: /kaggle/input/dinvov3large-1204-cv\r\n",
      "\r\n",
      "‚úÖ Detected 2 TTA modes: ['base', 'hflip']\r\n",
      "\r\n",
      "\r\n",
      "üöÄ TTA mode: base\r\n",
      "‚úÖ Detected 5 ‰∏™Ê®°Âûã:\r\n",
      "   - fold1_swa.pt\r\n",
      "   - fold2_swa.pt\r\n",
      "   - fold3_swa.pt\r\n",
      "   - fold4_swa.pt\r\n",
      "   - fold5_swa.pt\r\n",
      "Fold 1/5 Êé®ÁêÜ: fold1_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 2/5 Êé®ÁêÜ: fold2_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 3/5 Êé®ÁêÜ: fold3_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 4/5 Êé®ÁêÜ: fold4_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 5/5 Êé®ÁêÜ: fold5_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "\r\n",
      "üöÄ TTA mode: hflip\r\n",
      "‚úÖ Detected 5 ‰∏™Ê®°Âûã:\r\n",
      "   - fold1_swa.pt\r\n",
      "   - fold2_swa.pt\r\n",
      "   - fold3_swa.pt\r\n",
      "   - fold4_swa.pt\r\n",
      "   - fold5_swa.pt\r\n",
      "Fold 1/5 Êé®ÁêÜ: fold1_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 2/5 Êé®ÁêÜ: fold2_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 3/5 Êé®ÁêÜ: fold3_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 4/5 Êé®ÁêÜ: fold4_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Fold 5/5 Êé®ÁêÜ: fold5_swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "                    sample_id     target\r\n",
      "0  ID1001187975__Dry_Clover_g   0.093125\r\n",
      "1    ID1001187975__Dry_Dead_g  35.014061\r\n",
      "2   ID1001187975__Dry_Green_g  37.481247\r\n",
      "3   ID1001187975__Dry_Total_g  72.611725\r\n",
      "4         ID1001187975__GDM_g  37.597656\r\n",
      "\r\n",
      "‚úÖ Submission file generated: submission2.csv\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1000 log_dual.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0be21e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:49.996114Z",
     "iopub.status.busy": "2026-01-27T01:49:49.995369Z",
     "iopub.status.idle": "2026-01-27T01:49:51.705015Z",
     "shell.execute_reply": "2026-01-27T01:49:51.704377Z"
    },
    "papermill": {
     "duration": 1.716489,
     "end_time": "2026-01-27T01:49:51.706291",
     "exception": false,
     "start_time": "2026-01-27T01:49:49.989802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544e76ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:51.717982Z",
     "iopub.status.busy": "2026-01-27T01:49:51.717421Z",
     "iopub.status.idle": "2026-01-27T01:49:51.985106Z",
     "shell.execute_reply": "2026-01-27T01:49:51.984269Z"
    },
    "papermill": {
     "duration": 0.274695,
     "end_time": "2026-01-27T01:49:51.986285",
     "exception": false,
     "start_time": "2026-01-27T01:49:51.711590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â§ÑÁêÜÂêéÁªüËÆ°:\n",
      "  Ë¥üÂÄºÊï∞Èáè: 0\n",
      "  ÂéüÂßãÂÄº‰Ωé‰∫é0.1ÁöÑÊï∞Èáè: 1\n",
      "  Ë¢´ÁΩÆ‰∏∫0ÁöÑÊï∞Èáè: 0\n",
      "  ÊúÄÁªàÂÄºËåÉÂõ¥: [0.126, 65.567]\n",
      "\n",
      "‚úÖ Êèê‰∫§Êñá‰ª∂Â∑≤‰øùÂ≠ò: submission.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.125842\n",
      "1    ID1001187975__Dry_Dead_g  29.677812\n",
      "2   ID1001187975__Dry_Green_g  35.810001\n",
      "3   ID1001187975__Dry_Total_g  65.567343\n",
      "4         ID1001187975__GDM_g  35.707031\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv('submission1.csv')\n",
    "df2 = pd.read_csv('submission2.csv')\n",
    "\n",
    "df1 = df1.sort_values('sample_id').reset_index(drop=True)\n",
    "df2 = df2.sort_values('sample_id').reset_index(drop=True)\n",
    "\n",
    "if not df1['sample_id'].equals(df2['sample_id']):\n",
    "    print(\"Ë≠¶ÂëäÔºö‰∏§‰∏™Êñá‰ª∂ÁöÑsample_id‰∏çÂÆåÂÖ®‰∏ÄËá¥ÔºÅ\")\n",
    "    print(\"Â∞ÜÊåâsample_idÂØπÈΩê...\")\n",
    "    df_merged = pd.merge(df1, df2, on='sample_id', suffixes=('_1', '_2'))\n",
    "else:\n",
    "    df_merged = df1.copy()\n",
    "    df_merged['target_1'] = df1['target']\n",
    "    df_merged['target_2'] = df2['target']\n",
    "\n",
    "\n",
    "df_merged['target'] = 0.8 * df_merged['target_1'] + 0.2 * df_merged['target_2']\n",
    "df_merged['target'] = df_merged['target'].apply(lambda x: max(x, 0) if x >= 0.1 else 0)\n",
    "df_merged['target'] = df_merged['target'].clip(lower=0)\n",
    "result_df = df_merged[['sample_id', 'target']].copy()\n",
    "\n",
    "negative_count = (result_df['target'] < 0).sum()\n",
    "below_01_count = ((df_merged['target_1'] < 0.1) | (df_merged['target_2'] < 0.1)).sum()\n",
    "clipped_count = (result_df['target'] == 0).sum()\n",
    "\n",
    "print(f\"Â§ÑÁêÜÂêéÁªüËÆ°:\")\n",
    "print(f\"  Ë¥üÂÄºÊï∞Èáè: {negative_count}\")\n",
    "print(f\"  ÂéüÂßãÂÄº‰Ωé‰∫é0.1ÁöÑÊï∞Èáè: {below_01_count}\")\n",
    "print(f\"  Ë¢´ÁΩÆ‰∏∫0ÁöÑÊï∞Èáè: {clipped_count}\")\n",
    "print(f\"  ÊúÄÁªàÂÄºËåÉÂõ¥: [{result_df['target'].min():.3f}, {result_df['target'].max():.3f}]\")\n",
    "\n",
    "result_df.to_csv('submission_stage1.csv', index=False)\n",
    "print(f\"\\n‚úÖ Êèê‰∫§Êñá‰ª∂Â∑≤‰øùÂ≠ò: submission.csv\")\n",
    "\n",
    "print(result_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffc024",
   "metadata": {
    "papermill": {
     "duration": 0.005026,
     "end_time": "2026-01-27T01:49:51.996718",
     "exception": false,
     "start_time": "2026-01-27T01:49:51.991692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# stage2 online training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b168072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:52.008576Z",
     "iopub.status.busy": "2026-01-27T01:49:52.008002Z",
     "iopub.status.idle": "2026-01-27T01:49:52.021024Z",
     "shell.execute_reply": "2026-01-27T01:49:52.020308Z"
    },
    "papermill": {
     "duration": 0.020382,
     "end_time": "2026-01-27T01:49:52.022032",
     "exception": false,
     "start_time": "2026-01-27T01:49:52.001650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_single.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_single.py\n",
    "\n",
    "# üì¶\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.amp import autocast, GradScaler       \n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import get_model_weights\n",
    "import collections\n",
    "\n",
    "\n",
    "dir = Path('/kaggle/input/csiro-biomass')\n",
    "DIRS = {\n",
    "    \"dir\"  : dir,\n",
    "    \"train\": Path(dir, \"train\"),\n",
    "    \"test\" : Path(dir, \"test\"),\n",
    "    \"model\": Path('/kaggle/working/stage2_train_single_swa'),\n",
    "    \"save\" : Path('/kaggle/working/stage2_train_single'),\n",
    "    \"data\" : Path(\"/kaggle/working/\"),\n",
    "}\n",
    "\n",
    "\n",
    "def show_df_info(df, name: str):\n",
    "    print(f\"üìä {name:<16} shape: {str(df.shape):<16}  ÂàóÂêç: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "def move_column_first(df, col_name):\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(f\"Âàó '{col_name}' ‰∏çÂ≠òÂú®‰∫é DataFrame ‰∏≠„ÄÇ\")\n",
    "    cols = [col_name] + [c for c in df.columns if c != col_name]\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def setup_seed(seed, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def load_and_prepare_train_stage2_df():\n",
    "    df_file_path = 'submission_stage1.csv'\n",
    "    df = pd.read_csv(df_file_path)\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "    df[\"image_path\"] = df[\"ID\"].apply(lambda x: f\"test/{x}.jpg\")\n",
    "    df[\"target_name\"] = df[\"sample_id\"].str.split(\"__\").str[1]\n",
    "    df = move_column_first(df, \"ID\")\n",
    "\n",
    "    df_targets = (\n",
    "        df.pivot_table(\n",
    "            index=\"ID\",\n",
    "            columns=\"target_name\",\n",
    "            values=\"target\",\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None  \n",
    "    meta_cols = [\n",
    "        \"ID\", \"image_path\"\n",
    "    ]\n",
    "    df_meta = df[meta_cols].drop_duplicates(subset=\"ID\")\n",
    "    df_train = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_train, \"df_train\")\n",
    "    return df_train\n",
    "\n",
    "\n",
    "df_pseudo = load_and_prepare_train_stage2_df()\n",
    "df_stage1_path = '/kaggle/input/train-single-csv/train_with_folds_singleflow.csv'\n",
    "df_stage1 = pd.read_csv(df_stage1_path)\n",
    "df_stage2_train = pd.concat([df_pseudo, df_stage1], ignore_index=True)\n",
    "df_stage2_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"seed\"                           : 42,  \n",
    "    \"epochs\"                         : 12,\n",
    "    \"freeze_ratio\"                   : 0.8,\n",
    "    \"num_workers\"                    : 4,\n",
    "    \"prefetch_factor\"                : 2,\n",
    "    \"batch_size\"                     : 4,\n",
    "    \"lr\"                             : 1e-4,\n",
    "    \"img_size\"                       : 1024,\n",
    "    \"img_ratio\"                      : 2.0, \n",
    "    \"backbone_name\"                  : \"vit_large_patch16_dinov3_qkvb.lvd1689m\",\n",
    "    \"scheduler_type\"                 : \"cosine\",\n",
    "    \"weights\": {\n",
    "        \"Dry_Green_g\" : 0.1,\n",
    "        \"Dry_Clover_g\": 0.1,\n",
    "        \"Dry_Dead_g\"  : 0.1,\n",
    "        \"GDM_g\"       : 0.2,\n",
    "        \"Dry_Total_g\" : 0.5\n",
    "    },\n",
    "    \"target_cols\": [\n",
    "        \"Dry_Green_g\",\n",
    "        \"Dry_Clover_g\",\n",
    "        \"Dry_Dead_g\",\n",
    "        \"GDM_g\",\n",
    "        \"Dry_Total_g\"\n",
    "    ]\n",
    "}\n",
    "config[\"img_width\"] = int(config[\"img_size\"] * config.get(\"img_ratio\", 1.0))\n",
    "\n",
    "\n",
    "class MySingleStreamModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                backbone_name=\"convnext_tiny\", \n",
    "                pretrained=True, \n",
    "                config = None):\n",
    "        super().__init__()\n",
    "        print(\"Current backbone:\", backbone_name)\n",
    "        img_size = (config[\"img_size\"], config.get(\"img_width\", config[\"img_size\"]))\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            img_size=img_size\n",
    "        )\n",
    "        in_dim = self.backbone.num_features\n",
    "        params = list(self.backbone.parameters())\n",
    "        freeze_until = int(len(params) * config[\"freeze_ratio\"])\n",
    "        for i, p in enumerate(params):\n",
    "            p.requires_grad = i >= freeze_until\n",
    "        self.feature_dim = in_dim\n",
    "        print(\"feature dim = \", self.feature_dim)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.feature_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1)\n",
    "            )\n",
    "        self.head_green  = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead   = make_head()\n",
    "        self.head_gdm = make_head()\n",
    "        self.head_total = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "        self.weights = config[\"weights\"]\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.backbone(img)\n",
    "        G = self.softplus(self.head_green(feat))\n",
    "        C = self.softplus(self.head_clover(feat))\n",
    "        D = self.softplus(self.head_dead(feat))\n",
    "        GDM   = self.softplus(self.head_gdm(feat))\n",
    "        Total = self.softplus(self.head_total(feat))\n",
    "        preds = torch.cat([G, C, D, GDM, Total], dim=1)  # [B, 5]\n",
    "        return preds\n",
    "\n",
    "    def compute_loss(self, preds, targets):\n",
    "        preds = preds.view(-1, 5)\n",
    "        targets = targets.view(-1, 5)\n",
    "        weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5], device=preds.device)\n",
    "        y_true_flat = targets.view(-1)\n",
    "        y_pred_flat = preds.view(-1)\n",
    "        w_flat = torch.cat([\n",
    "            torch.full_like(targets[:, i], weights[i], device=preds.device)\n",
    "            for i in range(5)\n",
    "        ])\n",
    "        y_mean = torch.sum(w_flat * y_true_flat) / torch.sum(w_flat)\n",
    "        ss_res = torch.sum(w_flat * (y_true_flat - y_pred_flat) ** 2)\n",
    "        ss_tot = torch.sum(w_flat * (y_true_flat - y_mean) ** 2)\n",
    "        loss = ss_res / ss_tot\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SingleStreamDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, config, pre_transform=None, transform=None, mode=\"train\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.target_cols = config[\"target_cols\"]\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(self.df) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = Path(self.image_dir, str(row[\"image_path\"]))\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        if self.pre_transform:\n",
    "            image = self.pre_transform(image=image)[\"image\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if self.target_cols is not None:\n",
    "            targets = torch.tensor(\n",
    "                row[self.target_cols].astype(float).values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            return image, targets\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "\n",
    "def get_pre_transforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=(0.8, 1.2), \n",
    "                contrast_limit=(0.8, 1.2),   \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.ColorJitter(p=0.7)\n",
    "        ], p=0.4),\n",
    "    ])\n",
    "\n",
    "\n",
    "def _get_resize_dims(config):\n",
    "    height = config[\"img_size\"]\n",
    "    width = int(config.get(\"img_width\", config[\"img_size\"]))\n",
    "    return height, width\n",
    "\n",
    "\n",
    "def get_train_transforms(config):\n",
    "    height, width = _get_resize_dims(config)\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(config):\n",
    "    height, width = _get_resize_dims(config)\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_tta_transforms(config):\n",
    "    height, width = _get_resize_dims(config)\n",
    "    return {\n",
    "        \"base\": A.Compose([\n",
    "            A.Resize(height, width),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        \"hflip\": A.Compose([\n",
    "            A.HorizontalFlip(p=1.0)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device, scaler, config):\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    start_epoch = time.time()\n",
    "    prev_end = start_epoch  \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\", leave=False)\n",
    "\n",
    "    for step, (images, targets) in pbar:\n",
    "        t_load = time.time()  \n",
    "        data_load_time = t_load - prev_end\n",
    "        t0 = time.time()\n",
    "        images = images.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        t1 = time.time()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            preds = model(images)\n",
    "            loss = model.compute_loss(preds, targets)    \n",
    "        t2 = time.time()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        t3 = time.time()\n",
    "        running_loss.append(loss.item())\n",
    "        prev_end = t3  \n",
    "    end_epoch = time.time()\n",
    "    epoch_time = end_epoch - start_epoch\n",
    "    avg_batch_time = epoch_time / len(dataloader)\n",
    "    return float(np.mean(running_loss))\n",
    "\n",
    "\n",
    "\n",
    "def get_fold_loaders(df, config):\n",
    "    train_df = df\n",
    "    train_dataset = SingleStreamDataset(train_df, DIRS[\"dir\"],\n",
    "                                        config, pre_transform=get_pre_transforms(),\n",
    "                                        transform=get_train_transforms(config), mode=\"train\")\n",
    "    num_workers = config[\"num_workers\"]\n",
    "    prefetch_factor = config[\"prefetch_factor\"]\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,        \n",
    "        pin_memory=True,                 \n",
    "        prefetch_factor=prefetch_factor,  \n",
    "        persistent_workers=True         \n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def fetch_scheduler(optimizer, config):\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config[\"epochs\"], eta_min=config[\"lr\"]/100)\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def train_one_fold(df, save_dir, config, device):   \n",
    "    train_loader = get_fold_loaders(df, config)\n",
    "    model = MySingleStreamModel(config[\"backbone_name\"], pretrained=False, config=config)\n",
    "    model = model.to(device).to(memory_format=torch.channels_last)\n",
    "    try:\n",
    "        state_dict = torch.load('/kaggle/input/single-1209-swa-models/fold2_swa.pt', map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state_dict = torch.load('/kaggle/input/single-1209-swa-models/fold2_swa.pt', map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model = torch.compile(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=config[\"lr\"], weight_decay=2e-5)\n",
    "    scheduler = fetch_scheduler(optimizer, config)\n",
    "    scaler = torch.amp.GradScaler(device=\"cuda\")\n",
    "    train_losses, LR_records = [], []\n",
    "    epoch_times = [] \n",
    "    all_progress = config[\"epochs\"]\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        epoch_start = time.time()\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scaler, config)\n",
    "        scheduler.step()\n",
    "        train_losses.append(train_loss)\n",
    "        LR_records.append(scheduler.get_last_lr()[0])\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        if epoch > 0:\n",
    "            epoch_times.append(epoch_time)\n",
    "            if len(epoch_times) > 10:\n",
    "                epoch_times.pop(0)\n",
    "        if len(epoch_times) > 0:\n",
    "            avg_epoch_time = np.mean(epoch_times)\n",
    "        else:\n",
    "            avg_epoch_time = epoch_time\n",
    "\n",
    "        progress = epoch + 1\n",
    "        remaining_epochs = all_progress - progress\n",
    "        eta_seconds = avg_epoch_time * remaining_epochs\n",
    "        if not np.isnan(eta_seconds) and not np.isinf(eta_seconds):\n",
    "            eta_time = datetime.now() + timedelta(seconds=float(eta_seconds))\n",
    "            eta_time = eta_time.replace(microsecond=0)\n",
    "            days_diff = (eta_time.date() - datetime.now().date()).days\n",
    "            eta_str = (\n",
    "                f\"T+{days_diff} \" + eta_time.strftime(\"%H:%M:%S\")\n",
    "                if days_diff > 0 else eta_time.strftime(\"%H:%M:%S\")\n",
    "            )\n",
    "        else:\n",
    "            eta_str = \"--:--:--\"\n",
    "        now_str = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(\n",
    "            f\"[{now_str}]üß©[{progress/all_progress*100:6.2f}%] \"\n",
    "            f\"Epoch {epoch+1:03d}/{config['epochs']} | \"\n",
    "            f\"Train={train_loss:.4f} | \"\n",
    "            f\"LR={scheduler.get_last_lr()[0]:.6f} | \"\n",
    "            f\"{epoch_time:6.2f}s/it | \"\n",
    "            f\"ETA‚âà{eta_str}\"\n",
    "        )\n",
    "        if epoch > 7:\n",
    "            loss_model_path = save_dir / f\"model_epoch{epoch+1}.pt\"\n",
    "            torch.save(model._orig_mod.state_dict(), loss_model_path)\n",
    "            # torch.save(model.state_dict(), loss_model_path)\n",
    "            print(f\"üåü save Epoch {epoch+1} Ê®°ÂûãÔºÅ\")\n",
    "    del train_loader, model, optimizer, scheduler, scaler\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def train_with_groupkfold(df_train, save_dir, config, device):\n",
    "    df = df_train.copy()\n",
    "    metrics = train_one_fold(df, save_dir, config, device)\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"üéØ All folds training completed.\")\n",
    "\n",
    "\n",
    "isTRAIN     = True\n",
    "isPREDICT   = True\n",
    "DEBUG = False\n",
    "print(\"DEBUGÊ®°Âºè\",DEBUG)\n",
    "\n",
    "\n",
    "if (\n",
    "    __name__ == \"__main__\"\n",
    "    and isTRAIN\n",
    "):\n",
    "    torch.multiprocessing.freeze_support()       \n",
    "    setup_seed(config[\"seed\"])        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_root = DIRS[\"save\"]\n",
    "    os.makedirs(model_root, exist_ok=True)\n",
    "    if DEBUG:\n",
    "        config[\"epochs\"] = 2\n",
    "        print(f\"‚ö†Ô∏è DEBUG mode enabled ‚Äî running only {config['epochs']} epochs\\n\")\n",
    "\n",
    "\n",
    "    print(\"\\nüöÄüöÄüöÄ Starting training process... üöÄüöÄüöÄ\\n\")\n",
    "    df_train = df_stage2_train\n",
    "    train_with_groupkfold(\n",
    "        df_train             = df_train,\n",
    "        save_dir             = model_root,\n",
    "        config               = config,\n",
    "        device               = device\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Training completed! Results saved in: {model_root}\")\n",
    "    print(\"‚úÖ\"*65)\n",
    "\n",
    "    model_dir = DIRS[\"save\"]\n",
    "    out_dir = DIRS[\"model\"]\n",
    "    model_paths = sorted(Path(model_dir).glob(\"*.pt\"))\n",
    "    print(f\": Found {len(model_paths)} unique models!\")\n",
    "    for path in model_paths:\n",
    "        print(f\" - {path}\")\n",
    "    if len(model_paths) < 2:\n",
    "        print(f\"‚ö†Ô∏è Only {len(model_paths)} unique models, skipping SWA...\")\n",
    "    \n",
    "    models = []\n",
    "    for module_path in model_paths:\n",
    "        if os.path.exists(module_path):\n",
    "            model = torch.load(module_path, map_location='cpu')\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(f\"‚ùå Model file not found: {module_path}\")\n",
    "    \n",
    "    worker_state_dicts = [m for m in models]\n",
    "    weight_keys = list(worker_state_dicts[0].keys())\n",
    "    print(f\"Example weight keys: {list(weight_keys)[:5]}\")\n",
    "    fed_state_dict = collections.OrderedDict()\n",
    "    for key in weight_keys:\n",
    "        key_sum = 0\n",
    "        for i in range(len(models)):\n",
    "            key_sum += worker_state_dicts[i][key]\n",
    "        fed_state_dict[key] = key_sum / len(models)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    output_path = os.path.join(out_dir, f'swa.pt')\n",
    "    torch.save(fed_state_dict, output_path)\n",
    "    print(f\"averaging complete. Saved to: {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_and_prepare_test_df():\n",
    "    df_file_path = Path(DIRS[\"dir\"]) / \"test.csv\"\n",
    "    df = pd.read_csv(df_file_path)\n",
    "\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "    df = move_column_first(df, \"ID\")\n",
    "    df[\"target\"] = 0  \n",
    "    df_targets = (\n",
    "        df.pivot_table(index=\"ID\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None\n",
    "    df_meta = df[[\"ID\", \"image_path\"]].drop_duplicates(subset=\"ID\")\n",
    "    df_test = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_test, \"df_test\")\n",
    "    print(f\"‚úÖ Test set loaded: {df_test.shape}\")\n",
    "    return df_test\n",
    "\n",
    "\n",
    "def load_model_for_inference(model_path, device, config):\n",
    "    model = MySingleStreamModel(config[\"backbone_name\"], pretrained=False, config=config)\n",
    "    model = model.to(device).to(memory_format=torch.channels_last)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_with_model(model, dataloader, device):\n",
    "    preds_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (images, targets) in enumerate(dataloader):\n",
    "            images = images.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                preds = model(images)\n",
    "            preds_list.append(preds.cpu().numpy())\n",
    "    return np.concatenate(preds_list, axis=0)\n",
    "\n",
    "\n",
    "def predict_ensemble(df_test, pre_transform, transform, model_dir, device, config):\n",
    "    model_paths = sorted(Path(model_dir).glob(\"*.pt\"))\n",
    "    assert len(model_paths) > 0, f\"‚ùå No model files found in: {model_dir}\"\n",
    "    print(f\"‚úÖ Detected {len(model_paths)} ‰∏™Ê®°Âûã:\")\n",
    "    for p in model_paths:\n",
    "        print(\"   -\", p.name)\n",
    "    test_dataset = SingleStreamDataset(\n",
    "        df_test,\n",
    "        DIRS[\"dir\"],\n",
    "        config,\n",
    "        pre_transform=pre_transform,\n",
    "        transform=transform,\n",
    "        mode=\"test\"\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    fold_preds = []\n",
    "    for fold, model_path in enumerate(model_paths):\n",
    "        print(f\"Fold {fold+1}/{len(model_paths)} Êé®ÁêÜ: {model_path.name}\")\n",
    "        model = load_model_for_inference(model_path, device, config)\n",
    "        fold_pred = predict_with_model(model, test_loader, device)\n",
    "        fold_preds.append(fold_pred)\n",
    "    preds_mean = np.mean(fold_preds, axis=0)\n",
    "    df_pred = pd.DataFrame(preds_mean, columns=config[\"target_cols\"])\n",
    "    df_pred[\"ID\"] = df_test[\"ID\"]\n",
    "    df_pred = df_pred[[\"ID\"] + config[\"target_cols\"]]\n",
    "    show_df_info(df_pred, \"df_pred\")\n",
    "    return df_pred\n",
    "\n",
    "\n",
    "def generate_submission(df_pred_final):\n",
    "    ordered_target_cols = [\n",
    "        \"Dry_Green_g\",  # 1Ô∏è‚É£\n",
    "        \"Dry_Clover_g\", # 2Ô∏è‚É£\n",
    "        \"Dry_Dead_g\",   # 3Ô∏è‚É£\n",
    "        \"GDM_g\",        # 4Ô∏è‚É£\n",
    "        \"Dry_Total_g\"   # 5Ô∏è‚É£\n",
    "    ]\n",
    "    # if \"Dry_Clover_g\" in df_pred_final.columns:\n",
    "    #     df_pred_final[\"Dry_Clover_g\"] = df_pred_final[\"Dry_Clover_g\"] * 0.8\n",
    "    # else:\n",
    "    #     print(\"   ‚ö†Ô∏è Warning: Column Dry_Clover_g not found in DataFrame\")\n",
    "\n",
    "    df_submit = (\n",
    "        df_pred_final.melt(\n",
    "            id_vars=\"ID\",\n",
    "            value_vars=ordered_target_cols,\n",
    "            var_name=\"target_name\",\n",
    "            value_name=\"target\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_submit[\"sample_id\"] = df_submit[\"ID\"] + \"__\" + df_submit[\"target_name\"]\n",
    "    df_submit = df_submit[[\"sample_id\", \"target\"]]\n",
    "    df_submit = df_submit.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "    df_submit.to_csv(\"submission_stage2_1.csv\", index=False)\n",
    "    print(\"\\n‚úÖ Submission file generated: submission_stage2_1.csv\")\n",
    "\n",
    "\n",
    "def run_tta_prediction(df_test, model_dir, device, config):\n",
    "    tta_transforms = get_tta_transforms(config)\n",
    "    tta_names = list(tta_transforms.keys())\n",
    "    print(f\"\\n‚úÖ Detected {len(tta_names)} TTA modes: {tta_names}\\n\")\n",
    "    all_preds = []\n",
    "    for name, _ in tta_transforms.items():\n",
    "        print(f\"\\nüöÄ TTA mode: {name}\")\n",
    "        if name == \"base\":\n",
    "            print(\"base no pre_transform\")\n",
    "            pre_transform = None\n",
    "            transform = tta_transforms[name]\n",
    "        else:\n",
    "            pre_transform = tta_transforms[name]\n",
    "            transform = tta_transforms[\"base\"]\n",
    "        df_pred = predict_ensemble(df_test, pre_transform, transform, model_dir, device, config)\n",
    "        all_preds.append(df_pred[config[\"target_cols\"]].values)\n",
    "\n",
    "    mean_preds = np.mean(all_preds, axis=0)\n",
    "    df_pred_final = df_pred.copy()\n",
    "    df_pred_final[config[\"target_cols\"]] = mean_preds\n",
    "    return df_pred_final\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and isPREDICT:\n",
    "    print(\"\\nüß† Starting prediction pipeline...\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    df_test = load_and_prepare_test_df()\n",
    "    print(f\"\\nCurrent dataset shape: {df_test.shape}\\n\")\n",
    "    model_dir = DIRS[\"model\"]\n",
    "\n",
    "    print(f\"Model directory loaded: {model_dir}\")\n",
    "\n",
    "    df_pred_final = run_tta_prediction(df_test, model_dir, device, config)\n",
    "    generate_submission(df_pred_final)\n",
    "    print(\"üéØ Prediction pipeline completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1c89de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:52.033538Z",
     "iopub.status.busy": "2026-01-27T01:49:52.033316Z",
     "iopub.status.idle": "2026-01-27T01:49:52.045623Z",
     "shell.execute_reply": "2026-01-27T01:49:52.044932Z"
    },
    "papermill": {
     "duration": 0.019625,
     "end_time": "2026-01-27T01:49:52.046668",
     "exception": false,
     "start_time": "2026-01-27T01:49:52.027043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_dual.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_dual.py\n",
    "\n",
    "# üì¶\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.amp import autocast, GradScaler       \n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import get_model_weights\n",
    "import collections\n",
    "\n",
    "\n",
    "dir = Path('/kaggle/input/csiro-biomass')\n",
    "DIRS = {\n",
    "    \"dir\"  : dir,\n",
    "    \"train\": Path(dir, \"train\"),\n",
    "    \"test\" : Path(dir, \"test\"),\n",
    "    \"model\": Path('/kaggle/working/stage2_train_dual_swa'),\n",
    "    \"save\" : Path('/kaggle/working/stage2_train_dual'),\n",
    "    \"data\" : Path(\"/kaggle/working/\"),\n",
    "}\n",
    "\n",
    "\n",
    "def show_df_info(df, name: str):\n",
    "    print(f\"üìä {name:<16} shape: {str(df.shape):<16}  ÂàóÂêç: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "def move_column_first(df, col_name):\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(f\"Âàó '{col_name}' ‰∏çÂ≠òÂú®‰∫é DataFrame ‰∏≠„ÄÇ\")\n",
    "    cols = [col_name] + [c for c in df.columns if c != col_name]\n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def setup_seed(seed, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def load_and_prepare_train_stage2_df():\n",
    "    df_file_path = 'submission_stage1.csv'\n",
    "    df = pd.read_csv(df_file_path)\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "    df[\"image_path\"] = df[\"ID\"].apply(lambda x: f\"test/{x}.jpg\")\n",
    "    df[\"target_name\"] = df[\"sample_id\"].str.split(\"__\").str[1]\n",
    "    df = move_column_first(df, \"ID\")\n",
    "\n",
    "    df_targets = (\n",
    "        df.pivot_table(\n",
    "            index=\"ID\",\n",
    "            columns=\"target_name\",\n",
    "            values=\"target\",\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None  \n",
    "    meta_cols = [\n",
    "        \"ID\", \"image_path\"\n",
    "    ]\n",
    "    df_meta = df[meta_cols].drop_duplicates(subset=\"ID\")\n",
    "    df_train = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_train, \"df_train\")\n",
    "    return df_train\n",
    "\n",
    "\n",
    "df_pseudo = load_and_prepare_train_stage2_df()\n",
    "df_stage1_path = '/kaggle/input/train-single-csv/train_with_folds_singleflow.csv'\n",
    "df_stage1 = pd.read_csv(df_stage1_path)\n",
    "df_stage2_train = pd.concat([df_pseudo, df_stage1], ignore_index=True)\n",
    "df_stage2_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"seed\"                           : 3407,  \n",
    "    \"epochs\"                         : 12,\n",
    "    \"freeze_ratio\"                   : 0.8,\n",
    "    \"num_workers\"                    : 2,\n",
    "    \"prefetch_factor\"                : 2,\n",
    "    \"batch_size\"                     : 4,\n",
    "    \"lr\"                             : 1e-4,\n",
    "    \"img_size\"                       : 1024,\n",
    "    \"backbone_name\"                  : \"vit_large_patch16_dinov3_qkvb.lvd1689m\",\n",
    "    \"scheduler_type\"                 : \"cosine\",\n",
    "    \"weights\": {\n",
    "        \"Dry_Green_g\" : 0.1,\n",
    "        \"Dry_Clover_g\": 0.1,\n",
    "        \"Dry_Dead_g\"  : 0.1,\n",
    "        \"GDM_g\"       : 0.2,\n",
    "        \"Dry_Total_g\" : 0.5\n",
    "    },\n",
    "    \"target_cols\": [\n",
    "        \"Dry_Green_g\",\n",
    "        \"Dry_Clover_g\",\n",
    "        \"Dry_Dead_g\",\n",
    "        \"GDM_g\",\n",
    "        \"Dry_Total_g\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Model \n",
    "class MyDualStreamModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                backbone_name=\"convnext_tiny\", \n",
    "                pretrained=True, \n",
    "                config = None):\n",
    "        super().__init__()\n",
    "        print(\"Current backbone:\", backbone_name)\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)\n",
    "        in_dim = self.backbone.num_features\n",
    "        params = list(self.backbone.parameters())\n",
    "        freeze_until = int(len(params) * config[\"freeze_ratio\"])\n",
    "        for i, p in enumerate(params):\n",
    "            p.requires_grad = i >= freeze_until    \n",
    "        self.fusion_dim = in_dim * 2\n",
    "        print(\"feature fusion dim = \", self.fusion_dim)\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.fusion_dim, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 1)\n",
    "            )\n",
    "\n",
    "        self.head_green  = make_head()  \n",
    "        self.head_clover = make_head()   \n",
    "        self.head_dead   = make_head()  \n",
    "        self.head_gdm = make_head()\n",
    "        self.head_total = make_head()\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "        self.weights = config[\"weights\"]\n",
    "    def forward(self, img_left, img_right):\n",
    "        feat_left  = self.backbone(img_left)\n",
    "        feat_right = self.backbone(img_right)\n",
    "        fused = torch.cat([feat_left, feat_right], dim=1)\n",
    "        G = self.softplus(self.head_green(fused))\n",
    "        C = self.softplus(self.head_clover(fused))\n",
    "        D = self.softplus(self.head_dead(fused))\n",
    "        if self.training:\n",
    "            GDM   = self.softplus(self.head_gdm(fused))\n",
    "            Total = self.softplus(self.head_total(fused))\n",
    "        else:\n",
    "            GDM   = G + C\n",
    "            Total = G + C + D\n",
    "        preds = torch.cat([G, C, D, GDM, Total], dim=1)  # [B, 5]\n",
    "        return preds\n",
    "\n",
    "    def compute_loss(self, preds, targets):\n",
    "        preds = preds.view(-1, 5)\n",
    "        targets = targets.view(-1, 5)\n",
    "        weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5], device=preds.device)\n",
    "        y_true_flat = targets.view(-1)\n",
    "        y_pred_flat = preds.view(-1)\n",
    "        w_flat = torch.cat([\n",
    "            torch.full_like(targets[:, i], weights[i], device=preds.device)\n",
    "            for i in range(5)\n",
    "        ])\n",
    "        y_mean = torch.sum(w_flat * y_true_flat) / torch.sum(w_flat)\n",
    "        ss_res = torch.sum(w_flat * (y_true_flat - y_pred_flat) ** 2)\n",
    "        ss_tot = torch.sum(w_flat * (y_true_flat - y_mean) ** 2)\n",
    "        loss = ss_res / ss_tot\n",
    "        return loss\n",
    "\n",
    "\n",
    "class DualStreamDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, config, pre_transform=None, transform=None, mode=\"train\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.target_cols = config[\"target_cols\"]\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(self.df) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = Path(self.image_dir, str(row[\"image_path\"]))\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        if self.pre_transform:\n",
    "            image = self.pre_transform(image=image)[\"image\"]\n",
    "        \n",
    "        h, w, _ = image.shape\n",
    "        mid = w // 2\n",
    "        img_left = image[:, :mid]\n",
    "        img_right = image[:, mid:]\n",
    "        if self.transform:\n",
    "            img_left = self.transform(image=img_left)[\"image\"]\n",
    "            img_right = self.transform(image=img_right)[\"image\"]\n",
    "        if self.target_cols is not None:\n",
    "            targets = torch.tensor(\n",
    "                row[self.target_cols].astype(float).values,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            return img_left, img_right, targets\n",
    "        else:\n",
    "            return img_left, img_right\n",
    "\n",
    "\n",
    "def get_pre_transforms():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=(0.8, 1.2), \n",
    "                contrast_limit=(0.8, 1.2),   \n",
    "                p=0.3\n",
    "            ),\n",
    "            A.ColorJitter(p=0.7)\n",
    "        ], p=0.4),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_train_transforms(size):\n",
    "    return A.Compose([\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(size):\n",
    "    return A.Compose([\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_tta_transforms(size):\n",
    "    return {\n",
    "        \"base\": A.Compose([\n",
    "            A.Resize(size, size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2()\n",
    "        ]),\n",
    "        \"hflip\": A.Compose([\n",
    "            A.HorizontalFlip(p=1.0)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device, scaler, config):\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    start_epoch = time.time()\n",
    "    prev_end = start_epoch  \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\", leave=False)\n",
    "    for step, (img_left, img_right, targets) in enumerate(dataloader):\n",
    "        t_load = time.time()  \n",
    "        data_load_time = t_load - prev_end\n",
    "        t0 = time.time()\n",
    "        img_left, img_right, targets = (\n",
    "            img_left.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last),\n",
    "            img_right.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last),\n",
    "            targets.to(device, non_blocking=True),\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            preds = model(img_left, img_right)\n",
    "            loss = model.compute_loss(preds, targets)    \n",
    "        t2 = time.time()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        t3 = time.time()\n",
    "        running_loss.append(loss.item())\n",
    "        prev_end = t3  \n",
    "    end_epoch = time.time()\n",
    "    epoch_time = end_epoch - start_epoch\n",
    "    avg_batch_time = epoch_time / len(dataloader)\n",
    "    return float(np.mean(running_loss))\n",
    "\n",
    "\n",
    "\n",
    "def get_fold_loaders(df, config):\n",
    "    train_df = df\n",
    "    train_dataset = DualStreamDataset(train_df, DIRS[\"dir\"],\n",
    "                                        config, pre_transform=get_pre_transforms(),\n",
    "                                        transform=get_train_transforms(config[\"img_size\"]), mode=\"train\")\n",
    "    num_workers = config[\"num_workers\"]\n",
    "    prefetch_factor = config[\"prefetch_factor\"]\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,        \n",
    "        pin_memory=True,                 \n",
    "        prefetch_factor=prefetch_factor,  \n",
    "        persistent_workers=True         \n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def fetch_scheduler(optimizer, config):\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config[\"epochs\"], eta_min=config[\"lr\"]/100)\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def train_one_fold(df, save_dir, config, device):   \n",
    "    train_loader = get_fold_loaders(df, config)\n",
    "    model = MyDualStreamModel(config[\"backbone_name\"], pretrained=False, config=config)\n",
    "    model = model.to(device).to(memory_format=torch.channels_last)\n",
    "    try:\n",
    "        state_dict = torch.load('/kaggle/input/dinvov3large-1204-cv/fold2_swa.pt', map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state_dict = torch.load('/kaggle/input/dinvov3large-1204-cv/fold2_swa.pt', map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model = torch.compile(model)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=config[\"lr\"], weight_decay=2e-5)\n",
    "    scheduler = fetch_scheduler(optimizer, config)\n",
    "    scaler = torch.amp.GradScaler(device=\"cuda\")\n",
    "    train_losses, LR_records = [], []\n",
    "    epoch_times = [] \n",
    "    all_progress = config[\"epochs\"]\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        epoch_start = time.time()\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device, scaler, config)\n",
    "        scheduler.step()\n",
    "        train_losses.append(train_loss)\n",
    "        LR_records.append(scheduler.get_last_lr()[0])\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        if epoch > 0:\n",
    "            epoch_times.append(epoch_time)\n",
    "            if len(epoch_times) > 10:\n",
    "                epoch_times.pop(0)\n",
    "        if len(epoch_times) > 0:\n",
    "            avg_epoch_time = np.mean(epoch_times)\n",
    "        else:\n",
    "            avg_epoch_time = epoch_time\n",
    "\n",
    "        progress = epoch + 1\n",
    "        remaining_epochs = all_progress - progress\n",
    "        eta_seconds = avg_epoch_time * remaining_epochs\n",
    "        if not np.isnan(eta_seconds) and not np.isinf(eta_seconds):\n",
    "            eta_time = datetime.now() + timedelta(seconds=float(eta_seconds))\n",
    "            eta_time = eta_time.replace(microsecond=0)\n",
    "            days_diff = (eta_time.date() - datetime.now().date()).days\n",
    "            eta_str = (\n",
    "                f\"T+{days_diff} \" + eta_time.strftime(\"%H:%M:%S\")\n",
    "                if days_diff > 0 else eta_time.strftime(\"%H:%M:%S\")\n",
    "            )\n",
    "        else:\n",
    "            eta_str = \"--:--:--\"\n",
    "        now_str = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(\n",
    "            f\"[{now_str}]üß©[{progress/all_progress*100:6.2f}%] \"\n",
    "            f\"Epoch {epoch+1:03d}/{config['epochs']} | \"\n",
    "            f\"Train={train_loss:.4f} | \"\n",
    "            f\"LR={scheduler.get_last_lr()[0]:.6f} | \"\n",
    "            f\"{epoch_time:6.2f}s/it | \"\n",
    "            f\"ETA‚âà{eta_str}\"\n",
    "        )\n",
    "        if epoch > 7:\n",
    "            loss_model_path = save_dir / f\"model_epoch{epoch+1}.pt\"\n",
    "            torch.save(model._orig_mod.state_dict(), loss_model_path)\n",
    "            # torch.save(model.state_dict(), loss_model_path)\n",
    "            print(f\"üåü save Epoch {epoch+1} Ê®°ÂûãÔºÅ\")\n",
    "    del train_loader, model, optimizer, scheduler, scaler\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def train_with_groupkfold(df_train, save_dir, config, device):\n",
    "    df = df_train.copy()\n",
    "    metrics = train_one_fold(df, save_dir, config, device)\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"üéØ All folds training completed.\")\n",
    "\n",
    "\n",
    "isTRAIN     = True\n",
    "isPREDICT   = True\n",
    "DEBUG = False\n",
    "print(\"DEBUGÊ®°Âºè\",DEBUG)\n",
    "\n",
    "\n",
    "if (\n",
    "    __name__ == \"__main__\"\n",
    "    and isTRAIN\n",
    "):\n",
    "    torch.multiprocessing.freeze_support()       \n",
    "    setup_seed(config[\"seed\"])        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_root = DIRS[\"save\"]\n",
    "    os.makedirs(model_root, exist_ok=True)\n",
    "    if DEBUG:\n",
    "        config[\"epochs\"] = 2\n",
    "        print(f\"‚ö†Ô∏è DEBUG mode enabled ‚Äî running only {config['epochs']} epochs\\n\")\n",
    "\n",
    "\n",
    "    print(\"\\nüöÄüöÄüöÄ Starting training process... üöÄüöÄüöÄ\\n\")\n",
    "    df_train = df_stage2_train\n",
    "    train_with_groupkfold(\n",
    "        df_train             = df_train,\n",
    "        save_dir             = model_root,\n",
    "        config               = config,\n",
    "        device               = device\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Training completed! Results saved in: {model_root}\")\n",
    "    print(\"‚úÖ\"*65)\n",
    "\n",
    "    model_dir = DIRS[\"save\"]\n",
    "    out_dir = DIRS[\"model\"]\n",
    "    model_paths = sorted(Path(model_dir).glob(\"*.pt\"))\n",
    "    print(f\": Found {len(model_paths)} unique models!\")\n",
    "    for path in model_paths:\n",
    "        print(f\" - {path}\")\n",
    "    if len(model_paths) < 2:\n",
    "        print(f\"‚ö†Ô∏è Only {len(model_paths)} unique models, skipping SWA...\")\n",
    "    \n",
    "    models = []\n",
    "    for module_path in model_paths:\n",
    "        if os.path.exists(module_path):\n",
    "            model = torch.load(module_path, map_location='cpu')\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(f\"‚ùå Model file not found: {module_path}\")\n",
    "    \n",
    "    worker_state_dicts = [m for m in models]\n",
    "    weight_keys = list(worker_state_dicts[0].keys())\n",
    "    print(f\"Example weight keys: {list(weight_keys)[:5]}\")\n",
    "    fed_state_dict = collections.OrderedDict()\n",
    "    for key in weight_keys:\n",
    "        key_sum = 0\n",
    "        for i in range(len(models)):\n",
    "            key_sum += worker_state_dicts[i][key]\n",
    "        fed_state_dict[key] = key_sum / len(models)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    output_path = os.path.join(out_dir, f'swa.pt')\n",
    "    torch.save(fed_state_dict, output_path)\n",
    "    print(f\"averaging complete. Saved to: {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_and_prepare_test_df():\n",
    "    df_file_path = Path(DIRS[\"dir\"]) / \"test.csv\"\n",
    "    df = pd.read_csv(df_file_path)\n",
    "\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "    df = move_column_first(df, \"ID\")\n",
    "    df[\"target\"] = 0  \n",
    "    df_targets = (\n",
    "        df.pivot_table(index=\"ID\", columns=\"target_name\", values=\"target\", aggfunc=\"first\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None\n",
    "    df_meta = df[[\"ID\", \"image_path\"]].drop_duplicates(subset=\"ID\")\n",
    "    df_test = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_test, \"df_test\")\n",
    "    print(f\"‚úÖ Test set loaded: {df_test.shape}\")\n",
    "    return df_test\n",
    "\n",
    "\n",
    "def load_model_for_inference(model_path, device, config):\n",
    "    model = MyDualStreamModel(config[\"backbone_name\"], pretrained=False, config=config)\n",
    "    model = model.to(device).to(memory_format=torch.channels_last)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_with_model(model, dataloader, device):\n",
    "    preds_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (img_left, img_right, targets) in enumerate(dataloader):\n",
    "            img_left   = img_left.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            img_right  = img_right.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            targets    = targets.to(device, non_blocking=True)\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                preds = model(img_left, img_right)\n",
    "            preds_list.append(preds.cpu().numpy())\n",
    "    return np.concatenate(preds_list, axis=0)\n",
    "\n",
    "\n",
    "def predict_ensemble(df_test, pre_transform, transform, model_dir, device, config):\n",
    "    model_paths = sorted(Path(model_dir).glob(\"*.pt\"))\n",
    "    assert len(model_paths) > 0, f\"‚ùå No model files found in: {model_dir}\"\n",
    "    print(f\"‚úÖ Detected {len(model_paths)} ‰∏™Ê®°Âûã:\")\n",
    "    for p in model_paths:\n",
    "        print(\"   -\", p.name)\n",
    "    test_dataset = DualStreamDataset(\n",
    "        df_test,\n",
    "        DIRS[\"dir\"],\n",
    "        config,\n",
    "        pre_transform=pre_transform,\n",
    "        transform=transform,\n",
    "        mode=\"test\"\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    fold_preds = []\n",
    "    for fold, model_path in enumerate(model_paths):\n",
    "        print(f\"Fold {fold+1}/{len(model_paths)} Êé®ÁêÜ: {model_path.name}\")\n",
    "        model = load_model_for_inference(model_path, device, config)\n",
    "        fold_pred = predict_with_model(model, test_loader, device)\n",
    "        fold_preds.append(fold_pred)\n",
    "    preds_mean = np.mean(fold_preds, axis=0)\n",
    "    df_pred = pd.DataFrame(preds_mean, columns=config[\"target_cols\"])\n",
    "    df_pred[\"ID\"] = df_test[\"ID\"]\n",
    "    df_pred = df_pred[[\"ID\"] + config[\"target_cols\"]]\n",
    "    show_df_info(df_pred, \"df_pred\")\n",
    "    return df_pred\n",
    "\n",
    "\n",
    "def generate_submission(df_pred_final):\n",
    "    ordered_target_cols = [\n",
    "        \"Dry_Green_g\",  \n",
    "        \"Dry_Clover_g\",\n",
    "        \"Dry_Dead_g\",\n",
    "        \"GDM_g\",       \n",
    "        \"Dry_Total_g\"\n",
    "    ]\n",
    "    # if \"Dry_Clover_g\" in df_pred_final.columns:\n",
    "    #     df_pred_final[\"Dry_Clover_g\"] = df_pred_final[\"Dry_Clover_g\"] * 0.8\n",
    "    # else:\n",
    "    #     print(\"   ‚ö†Ô∏è Warning: Column Dry_Clover_g not found in DataFrame\")\n",
    "\n",
    "    df_submit = (\n",
    "        df_pred_final.melt(\n",
    "            id_vars=\"ID\",\n",
    "            value_vars=ordered_target_cols,\n",
    "            var_name=\"target_name\",\n",
    "            value_name=\"target\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_submit[\"sample_id\"] = df_submit[\"ID\"] + \"__\" + df_submit[\"target_name\"]\n",
    "    df_submit = df_submit[[\"sample_id\", \"target\"]]\n",
    "    df_submit = df_submit.sort_values(\"sample_id\").reset_index(drop=True)\n",
    "    df_submit.to_csv(\"submission_stage2_2.csv\", index=False)\n",
    "    print(\"\\n‚úÖ Submission file generated: submission_stage2_2.csv\")\n",
    "\n",
    "\n",
    "def run_tta_prediction(df_test, model_dir, device, config):\n",
    "    tta_transforms = get_tta_transforms(config[\"img_size\"])\n",
    "    tta_names = list(tta_transforms.keys())\n",
    "    print(f\"\\n‚úÖ Detected {len(tta_names)} TTA modes: {tta_names}\\n\")\n",
    "    all_preds = []\n",
    "    for name, _ in tta_transforms.items():\n",
    "        print(f\"\\nüöÄ TTA mode: {name}\")\n",
    "        if name == \"base\":\n",
    "            print(\"base no pre_transform\")\n",
    "            pre_transform = None\n",
    "            transform = tta_transforms[name]\n",
    "        else:\n",
    "            pre_transform = tta_transforms[name]\n",
    "            transform = tta_transforms[\"base\"]\n",
    "        df_pred = predict_ensemble(df_test, pre_transform, transform, model_dir, device, config)\n",
    "        all_preds.append(df_pred[config[\"target_cols\"]].values)\n",
    "\n",
    "    mean_preds = np.mean(all_preds, axis=0)\n",
    "    df_pred_final = df_pred.copy()\n",
    "    df_pred_final[config[\"target_cols\"]] = mean_preds\n",
    "    return df_pred_final\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and isPREDICT:\n",
    "    print(\"\\nüß† Starting prediction pipeline...\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    df_test = load_and_prepare_test_df()\n",
    "    print(f\"\\nCurrent dataset shape: {df_test.shape}\\n\")\n",
    "    model_dir = DIRS[\"model\"]\n",
    "\n",
    "    print(f\"Model directory loaded: {model_dir}\")\n",
    "\n",
    "    df_pred_final = run_tta_prediction(df_test, model_dir, device, config)\n",
    "    generate_submission(df_pred_final)\n",
    "    print(\"üéØ Prediction pipeline completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73fc8b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T01:49:52.057549Z",
     "iopub.status.busy": "2026-01-27T01:49:52.057332Z",
     "iopub.status.idle": "2026-01-27T03:25:08.049250Z",
     "shell.execute_reply": "2026-01-27T03:25:08.048410Z"
    },
    "papermill": {
     "duration": 5716.019146,
     "end_time": "2026-01-27T03:25:08.070867",
     "exception": false,
     "start_time": "2026-01-27T01:49:52.051721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Single Stream\n",
      "GPU 1: Dual Stream\n",
      "single&&dual doneÔºÅ\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "CUDA_VISIBLE_DEVICES=0 python train_single.py > log_single_train.txt 2>&1 &\n",
    "CUDA_VISIBLE_DEVICES=1 python train_dual.py > log_dual_train.txt 2>&1 &\n",
    "echo \"GPU 0: Single Stream\"\n",
    "echo \"GPU 1: Dual Stream\"\n",
    "\n",
    "wait\n",
    "\n",
    "echo \"single&&dual doneÔºÅ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff664cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T03:25:08.092579Z",
     "iopub.status.busy": "2026-01-27T03:25:08.092290Z",
     "iopub.status.idle": "2026-01-27T03:25:08.653685Z",
     "shell.execute_reply": "2026-01-27T03:25:08.652911Z"
    },
    "papermill": {
     "duration": 0.573206,
     "end_time": "2026-01-27T03:25:08.654934",
     "exception": false,
     "start_time": "2026-01-27T03:25:08.081728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "üìä df_train         shape: (1, 7)            ÂàóÂêç: ['ID', 'image_path', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\r\n",
      "DEBUGÊ®°Âºè False\r\n",
      "\r\n",
      "üöÄüöÄüöÄ Starting training process... üöÄüöÄüöÄ\r\n",
      "\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "Training:   0%|          | 0/89 [00:00<?, ?it/s]W0127 01:51:16.397000 309 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\r\n",
      "[02:01:22]üß©[  8.33%] Epoch 001/12 | Train=0.1743 | LR=0.000098 | 642.57s/it | ETA‚âà03:59:11\r\n",
      "[02:08:56]üß©[ 16.67%] Epoch 002/12 | Train=0.1407 | LR=0.000093 | 453.90s/it | ETA‚âà03:24:35\r\n",
      "[02:16:30]üß©[ 25.00%] Epoch 003/12 | Train=0.1003 | LR=0.000086 | 453.92s/it | ETA‚âà03:24:35\r\n",
      "[02:24:04]üß©[ 33.33%] Epoch 004/12 | Train=0.1226 | LR=0.000075 | 453.42s/it | ETA‚âà03:24:34\r\n",
      "[02:31:37]üß©[ 41.67%] Epoch 005/12 | Train=0.0706 | LR=0.000063 | 453.64s/it | ETA‚âà03:24:33\r\n",
      "[02:39:11]üß©[ 50.00%] Epoch 006/12 | Train=0.1119 | LR=0.000050 | 453.16s/it | ETA‚âà03:24:32\r\n",
      "[02:46:44]üß©[ 58.33%] Epoch 007/12 | Train=0.0642 | LR=0.000038 | 453.84s/it | ETA‚âà03:24:33\r\n",
      "[02:54:18]üß©[ 66.67%] Epoch 008/12 | Train=0.1042 | LR=0.000026 | 453.77s/it | ETA‚âà03:24:33\r\n",
      "[03:01:51]üß©[ 75.00%] Epoch 009/12 | Train=0.0973 | LR=0.000015 | 452.96s/it | ETA‚âà03:24:32\r\n",
      "üåü save Epoch 9 Ê®°ÂûãÔºÅ\r\n",
      "[03:09:27]üß©[ 83.33%] Epoch 010/12 | Train=0.0636 | LR=0.000008 | 453.94s/it | ETA‚âà03:24:34\r\n",
      "üåü save Epoch 10 Ê®°ÂûãÔºÅ\r\n",
      "[03:17:01]üß©[ 91.67%] Epoch 011/12 | Train=0.0828 | LR=0.000003 | 452.68s/it | ETA‚âà03:24:34\r\n",
      "üåü save Epoch 11 Ê®°ÂûãÔºÅ\r\n",
      "[03:24:35]üß©[100.00%] Epoch 012/12 | Train=0.0583 | LR=0.000001 | 453.22s/it | ETA‚âà03:24:35\r\n",
      "üåü save Epoch 12 Ê®°ÂûãÔºÅ\r\n",
      "üéØ All folds training completed.\r\n",
      "\r\n",
      "‚úÖ Training completed! Results saved in: /kaggle/working/stage2_train_single\r\n",
      "‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ\r\n",
      ": Found 4 unique models!\r\n",
      " - /kaggle/working/stage2_train_single/model_epoch10.pt\r\n",
      " - /kaggle/working/stage2_train_single/model_epoch11.pt\r\n",
      " - /kaggle/working/stage2_train_single/model_epoch12.pt\r\n",
      " - /kaggle/working/stage2_train_single/model_epoch9.pt\r\n",
      "Example weight keys: ['backbone.cls_token', 'backbone.reg_token', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.gamma_1']\r\n",
      "averaging complete. Saved to: /kaggle/working/stage2_train_single_swa/swa.pt\r\n",
      "\r\n",
      "üß† Starting prediction pipeline...\r\n",
      "üìä df_test          shape: (1, 7)            ÂàóÂêç: ['ID', 'image_path', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\r\n",
      "‚úÖ Test set loaded: (1, 7)\r\n",
      "\r\n",
      "Current dataset shape: (1, 7)\r\n",
      "\r\n",
      "Model directory loaded: /kaggle/working/stage2_train_single_swa\r\n",
      "\r\n",
      "‚úÖ Detected 2 TTA modes: ['base', 'hflip']\r\n",
      "\r\n",
      "\r\n",
      "üöÄ TTA mode: base\r\n",
      "base no pre_transform\r\n",
      "‚úÖ Detected 1 ‰∏™Ê®°Âûã:\r\n",
      "   - swa.pt\r\n",
      "Fold 1/1 Êé®ÁêÜ: swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "\r\n",
      "üöÄ TTA mode: hflip\r\n",
      "‚úÖ Detected 1 ‰∏™Ê®°Âûã:\r\n",
      "   - swa.pt\r\n",
      "Fold 1/1 Êé®ÁêÜ: swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature dim =  1024\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "\r\n",
      "‚úÖ Submission file generated: submission_stage2_1.csv\r\n",
      "üéØ Prediction pipeline completed.\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1000 log_single_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0d798dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T03:25:08.670662Z",
     "iopub.status.busy": "2026-01-27T03:25:08.670397Z",
     "iopub.status.idle": "2026-01-27T03:25:08.797481Z",
     "shell.execute_reply": "2026-01-27T03:25:08.796568Z"
    },
    "papermill": {
     "duration": 0.136052,
     "end_time": "2026-01-27T03:25:08.798690",
     "exception": false,
     "start_time": "2026-01-27T03:25:08.662638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "üìä df_train         shape: (1, 7)            ÂàóÂêç: ['ID', 'image_path', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\r\n",
      "DEBUGÊ®°Âºè False\r\n",
      "\r\n",
      "üöÄüöÄüöÄ Starting training process... üöÄüöÄüöÄ\r\n",
      "\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "Training:   0%|          | 0/89 [00:00<?, ?it/s]W0127 01:51:23.212000 310 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\r\n",
      "[02:00:30]üß©[  8.33%] Epoch 001/12 | Train=0.1632 | LR=0.000098 | 590.14s/it | ETA‚âà03:48:42\r\n",
      "[02:06:05]üß©[ 16.67%] Epoch 002/12 | Train=0.1852 | LR=0.000093 | 335.09s/it | ETA‚âà03:01:56\r\n",
      "[02:11:41]üß©[ 25.00%] Epoch 003/12 | Train=0.1903 | LR=0.000086 | 336.25s/it | ETA‚âà03:02:02\r\n",
      "[02:17:17]üß©[ 33.33%] Epoch 004/12 | Train=0.2525 | LR=0.000075 | 335.75s/it | ETA‚âà03:02:03\r\n",
      "[02:22:53]üß©[ 41.67%] Epoch 005/12 | Train=0.1503 | LR=0.000063 | 336.15s/it | ETA‚âà03:02:04\r\n",
      "[02:28:29]üß©[ 50.00%] Epoch 006/12 | Train=0.1303 | LR=0.000050 | 335.31s/it | ETA‚âà03:02:03\r\n",
      "[02:34:04]üß©[ 58.33%] Epoch 007/12 | Train=0.0801 | LR=0.000038 | 335.42s/it | ETA‚âà03:02:02\r\n",
      "[02:39:40]üß©[ 66.67%] Epoch 008/12 | Train=0.1656 | LR=0.000026 | 335.58s/it | ETA‚âà03:02:02\r\n",
      "[02:45:14]üß©[ 75.00%] Epoch 009/12 | Train=0.1045 | LR=0.000015 | 334.79s/it | ETA‚âà03:02:01\r\n",
      "üåü save Epoch 9 Ê®°ÂûãÔºÅ\r\n",
      "[02:50:52]üß©[ 83.33%] Epoch 010/12 | Train=0.1189 | LR=0.000008 | 335.87s/it | ETA‚âà03:02:03\r\n",
      "üåü save Epoch 10 Ê®°ÂûãÔºÅ\r\n",
      "[02:56:29]üß©[ 91.67%] Epoch 011/12 | Train=0.0958 | LR=0.000003 | 335.72s/it | ETA‚âà03:02:05\r\n",
      "üåü save Epoch 11 Ê®°ÂûãÔºÅ\r\n",
      "[03:02:07]üß©[100.00%] Epoch 012/12 | Train=0.0678 | LR=0.000001 | 335.73s/it | ETA‚âà03:02:07\r\n",
      "üåü save Epoch 12 Ê®°ÂûãÔºÅ\r\n",
      "üéØ All folds training completed.\r\n",
      "\r\n",
      "‚úÖ Training completed! Results saved in: /kaggle/working/stage2_train_dual\r\n",
      "‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ‚úÖ\r\n",
      ": Found 4 unique models!\r\n",
      " - /kaggle/working/stage2_train_dual/model_epoch10.pt\r\n",
      " - /kaggle/working/stage2_train_dual/model_epoch11.pt\r\n",
      " - /kaggle/working/stage2_train_dual/model_epoch12.pt\r\n",
      " - /kaggle/working/stage2_train_dual/model_epoch9.pt\r\n",
      "Example weight keys: ['backbone.cls_token', 'backbone.reg_token', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.gamma_1']\r\n",
      "averaging complete. Saved to: /kaggle/working/stage2_train_dual_swa/swa.pt\r\n",
      "\r\n",
      "üß† Starting prediction pipeline...\r\n",
      "üìä df_test          shape: (1, 7)            ÂàóÂêç: ['ID', 'image_path', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\r\n",
      "‚úÖ Test set loaded: (1, 7)\r\n",
      "\r\n",
      "Current dataset shape: (1, 7)\r\n",
      "\r\n",
      "Model directory loaded: /kaggle/working/stage2_train_dual_swa\r\n",
      "\r\n",
      "‚úÖ Detected 2 TTA modes: ['base', 'hflip']\r\n",
      "\r\n",
      "\r\n",
      "üöÄ TTA mode: base\r\n",
      "base no pre_transform\r\n",
      "‚úÖ Detected 1 ‰∏™Ê®°Âûã:\r\n",
      "   - swa.pt\r\n",
      "Fold 1/1 Êé®ÁêÜ: swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "\r\n",
      "üöÄ TTA mode: hflip\r\n",
      "‚úÖ Detected 1 ‰∏™Ê®°Âûã:\r\n",
      "   - swa.pt\r\n",
      "Fold 1/1 Êé®ÁêÜ: swa.pt\r\n",
      "Current backbone: vit_large_patch16_dinov3_qkvb.lvd1689m\r\n",
      "feature fusion dim =  2048\r\n",
      "üìä df_pred          shape: (1, 6)            ÂàóÂêç: ['ID', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']\r\n",
      "\r\n",
      "‚úÖ Submission file generated: submission_stage2_2.csv\r\n",
      "üéØ Prediction pipeline completed.\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1000 log_dual_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca4f285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T03:25:08.815365Z",
     "iopub.status.busy": "2026-01-27T03:25:08.814732Z",
     "iopub.status.idle": "2026-01-27T03:25:08.839835Z",
     "shell.execute_reply": "2026-01-27T03:25:08.838966Z"
    },
    "papermill": {
     "duration": 0.034249,
     "end_time": "2026-01-27T03:25:08.840959",
     "exception": false,
     "start_time": "2026-01-27T03:25:08.806710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Êèê‰∫§Êñá‰ª∂Â∑≤‰øùÂ≠ò: submission_stage2.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.123179\n",
      "1    ID1001187975__Dry_Dead_g  32.610937\n",
      "2   ID1001187975__Dry_Green_g  37.190625\n",
      "3   ID1001187975__Dry_Total_g  69.735866\n",
      "4         ID1001187975__GDM_g  37.476492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv('submission_stage2_1.csv')\n",
    "df2 = pd.read_csv('submission_stage2_2.csv')\n",
    "\n",
    "df1 = df1.sort_values('sample_id').reset_index(drop=True)\n",
    "df2 = df2.sort_values('sample_id').reset_index(drop=True)\n",
    "\n",
    "if not df1['sample_id'].equals(df2['sample_id']):\n",
    "    print(\"Ë≠¶ÂëäÔºö‰∏§‰∏™Êñá‰ª∂ÁöÑsample_id‰∏çÂÆåÂÖ®‰∏ÄËá¥ÔºÅ\")\n",
    "    print(\"Â∞ÜÊåâsample_idÂØπÈΩê...\")\n",
    "    df_merged = pd.merge(df1, df2, on='sample_id', suffixes=('_1', '_2'))\n",
    "else:\n",
    "    df_merged = df1.copy()\n",
    "    df_merged['target_1'] = df1['target']\n",
    "    df_merged['target_2'] = df2['target']\n",
    "\n",
    "\n",
    "df_merged['target'] = 0.6 * df_merged['target_1'] + 0.4 * df_merged['target_2']\n",
    "df_merged['target'] = df_merged['target'].apply(lambda x: max(x, 0) if x >= 0.1 else 0)\n",
    "df_merged['target'] = df_merged['target'].clip(lower=0)\n",
    "result_df = df_merged[['sample_id', 'target']].copy()\n",
    "result_df.to_csv('submission_stage2.csv', index=False)\n",
    "print(f\"\\n‚úÖ Êèê‰∫§Êñá‰ª∂Â∑≤‰øùÂ≠ò: submission_stage2.csv\")\n",
    "print(result_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beed7263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T03:25:08.856823Z",
     "iopub.status.busy": "2026-01-27T03:25:08.856612Z",
     "iopub.status.idle": "2026-01-27T03:25:08.875676Z",
     "shell.execute_reply": "2026-01-27T03:25:08.874763Z"
    },
    "papermill": {
     "duration": 0.028671,
     "end_time": "2026-01-27T03:25:08.876908",
     "exception": false,
     "start_time": "2026-01-27T03:25:08.848237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â§ÑÁêÜÂêéÁªüËÆ°:\n",
      "  Ë¥üÂÄºÊï∞Èáè: 0\n",
      "  ÂéüÂßãÂÄº‰Ωé‰∫é0.1ÁöÑÊï∞Èáè: 1\n",
      "  Ë¢´ÁΩÆ‰∏∫0ÁöÑÊï∞Èáè: 1\n",
      "  ÊúÄÁªàÂÄºËåÉÂõ¥: [0.000, 68.902]\n",
      "\n",
      "‚úÖ Êèê‰∫§Êñá‰ª∂Â∑≤‰øùÂ≠ò: submission.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.000000\n",
      "1    ID1001187975__Dry_Dead_g  32.024312\n",
      "2   ID1001187975__Dry_Green_g  36.914500\n",
      "3   ID1001187975__Dry_Total_g  68.902161\n",
      "4         ID1001187975__GDM_g  37.122600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv('submission_stage1.csv')\n",
    "df2 = pd.read_csv('submission_stage2.csv')\n",
    "\n",
    "df1 = df1.sort_values('sample_id').reset_index(drop=True)\n",
    "df2 = df2.sort_values('sample_id').reset_index(drop=True)\n",
    "\n",
    "if not df1['sample_id'].equals(df2['sample_id']):\n",
    "    print(\"Ë≠¶ÂëäÔºö‰∏§‰∏™Êñá‰ª∂ÁöÑsample_id‰∏çÂÆåÂÖ®‰∏ÄËá¥ÔºÅ\")\n",
    "    print(\"Â∞ÜÊåâsample_idÂØπÈΩê...\")\n",
    "    df_merged = pd.merge(df1, df2, on='sample_id', suffixes=('_1', '_2'))\n",
    "else:\n",
    "    df_merged = df1.copy()\n",
    "    df_merged['target_1'] = df1['target']\n",
    "    df_merged['target_2'] = df2['target']\n",
    "\n",
    "\n",
    "df_merged['target'] = 0.2 * df_merged['target_1'] + 0.8 * df_merged['target_2']\n",
    "df_merged['target'] = df_merged['target'].apply(lambda x: max(x, 0) if x >= 0.2 else 0)\n",
    "df_merged['target'] = df_merged['target'].clip(lower=0)\n",
    "result_df = df_merged[['sample_id', 'target']].copy()\n",
    "\n",
    "negative_count = (result_df['target'] < 0).sum()\n",
    "below_01_count = ((df_merged['target_1'] < 0.2) | (df_merged['target_2'] < 0.2)).sum()\n",
    "clipped_count = (result_df['target'] == 0).sum()\n",
    "\n",
    "print(f\"Â§ÑÁêÜÂêéÁªüËÆ°:\")\n",
    "print(f\"  Ë¥üÂÄºÊï∞Èáè: {negative_count}\")\n",
    "print(f\"  ÂéüÂßãÂÄº‰Ωé‰∫é0.1ÁöÑÊï∞Èáè: {below_01_count}\")\n",
    "print(f\"  Ë¢´ÁΩÆ‰∏∫0ÁöÑÊï∞Èáè: {clipped_count}\")\n",
    "print(f\"  ÊúÄÁªàÂÄºËåÉÂõ¥: [{result_df['target'].min():.3f}, {result_df['target'].max():.3f}]\")\n",
    "\n",
    "result_df.to_csv('submission.csv', index=False)\n",
    "print(f\"\\n‚úÖ Êèê‰∫§Êñá‰ª∂Â∑≤‰øùÂ≠ò: submission.csv\")\n",
    "\n",
    "print(result_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 8741100,
     "sourceId": 13737905,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8913148,
     "sourceId": 13986965,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8953834,
     "sourceId": 14067043,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9058629,
     "sourceId": 14203354,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9011999,
     "sourceId": 14464889,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5909.93258,
   "end_time": "2026-01-27T03:25:09.705568",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-27T01:46:39.772988",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

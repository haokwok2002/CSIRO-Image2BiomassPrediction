{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423eb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70825c32",
   "metadata": {},
   "source": [
    "# æŸ¥çœ‹é¢„æµ‹ç›®æ ‡å†…éƒ¨å…³ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0c00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\conda\\envs\\kaggle2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import h5py\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import socket\n",
    "import psutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast, GradScaler       \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import get_model_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f331799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… file path ï¼š\n",
      "dir          : D:\\DATA_hao\\Kaggle_\\csiro-biomass\n",
      "train        : D:\\DATA_hao\\Kaggle_\\csiro-biomass\\train\n",
      "test         : D:\\DATA_hao\\Kaggle_\\csiro-biomass\\test\n",
      "model        : D:\\DATA_hao\\Kaggle_\\csiro-biomass\\DualStream_multihead\n",
      "data         : D:\\DATA_hao\\Kaggle_\\csiro-biomass\n"
     ]
    }
   ],
   "source": [
    "# ðŸŒ± Path Initialization\n",
    "if socket.gethostname() == 'hao-2':\n",
    "    dir = Path('D:/DATA_hao/Kaggle_/csiro-biomass/')\n",
    "    DIRS = {\n",
    "        \"dir\"  : dir,\n",
    "        \"train\": Path(dir, \"train\"),\n",
    "        \"test\" : Path(dir, \"test\"),\n",
    "        \"model\": Path(dir, \"DualStream_multihead\"),\n",
    "        \"data\" : Path(dir),\n",
    "    }\n",
    "\n",
    "\n",
    "    print(\"âœ… file path ï¼š\")\n",
    "    for key, path in DIRS.items():\n",
    "        print(f\"{key:<12} : {path}\")\n",
    "\n",
    "elif socket.gethostname() == 'user-PowerEdge-XE9680':\n",
    "    dir = Path('/data4/huangweigang/gh/csiro-biomass')\n",
    "    DIRS = {\n",
    "        \"dir\"  : dir,\n",
    "        \"train\": Path(dir, \"train\"),\n",
    "        \"test\" : Path(dir, \"test\"),\n",
    "        \"model\": Path(dir, \"DualStream_multihead\"),\n",
    "        \"data\" : Path(dir),\n",
    "    }\n",
    "\n",
    "\n",
    "    print(\"âœ… file path ï¼š\")\n",
    "    for key, path in DIRS.items():\n",
    "        print(f\"{key:<12} : {path}\")\n",
    "\n",
    "else:\n",
    "    dir = Path('/kaggle/input/csiro-biomass')\n",
    "    DIRS = {\n",
    "        \"dir\"  : dir,\n",
    "        \"train\": Path(dir, \"train\"),\n",
    "        \"test\" : Path(dir, \"test\"),\n",
    "        \"model\": Path('/kaggle/input', \"dualstream-multihead2025-11-04-02-07-11\"),\n",
    "        \"data\" : Path(\"/kaggle/working/\"),\n",
    "    }\n",
    "\n",
    "\n",
    "    print(\"âœ… file path ï¼š\")\n",
    "    for key, path in DIRS.items():\n",
    "        print(f\"{key:<12} : {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeaa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def show_df_info(df, name: str):\n",
    "    \"\"\"\n",
    "    Print the shape and column names of a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df   : pandas.DataFrame\n",
    "        name : Display name (string)\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ“Š {name:<16} shape: {str(df.shape):<16}  columns: {df.columns.tolist()}\")\n",
    "\n",
    "def select_free_gpu(threshold_mem_MB = 500, threshold_util = 20):\n",
    "    \"\"\"\n",
    "    Automatically select an available GPU (works in both .py and Jupyter environments).\n",
    "    \"\"\"\n",
    "\n",
    "    # === Internal function: query GPU info from nvidia-smi ===\n",
    "    def get_gpu_info():\n",
    "        \"\"\"Retrieve GPU information using nvidia-smi.\"\"\"\n",
    "        query = (\n",
    "            \"index,name,memory.used,memory.total,utilization.gpu,temperature.gpu,power.draw\"\n",
    "        )\n",
    "        result = subprocess.run(\n",
    "            [\"nvidia-smi\", f\"--query-gpu={query}\", \"--format=csv,noheader,nounits\"],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "\n",
    "        gpus = []\n",
    "        for line in result.stdout.strip().split(\"\\n\"):\n",
    "            idx, name, mem_used, mem_total, util, temp, power = [x.strip() for x in line.split(\",\")]\n",
    "            gpus.append({\n",
    "                \"index\": int(idx),\n",
    "                \"name\": name,\n",
    "                \"mem_used_MB\": int(mem_used),\n",
    "                \"mem_total_MB\": int(mem_total),\n",
    "                \"util_%\": int(util),\n",
    "                \"temp_C\": int(temp),\n",
    "                \"power_W\": float(power),\n",
    "            })\n",
    "        return gpus\n",
    "\n",
    "    # === Main logic ===\n",
    "    gpus = get_gpu_info()\n",
    "\n",
    "    # Select GPUs with low memory and utilization\n",
    "    free_gpus = [\n",
    "        g for g in gpus\n",
    "        if g[\"mem_used_MB\"] < threshold_mem_MB and g[\"util_%\"] <= threshold_util\n",
    "    ]\n",
    "\n",
    "    if not free_gpus:\n",
    "        gpus.sort(key=lambda x: x[\"mem_used_MB\"])\n",
    "        selected = gpus[0]\n",
    "        reason = \"(No fully idle GPU found â€” selected the one with lowest memory usage)\"\n",
    "    else:\n",
    "        selected = free_gpus[0]\n",
    "        reason = \"(Idle GPU detected)\"\n",
    "\n",
    "    # Print GPU information table\n",
    "    print(tabulate(\n",
    "        [[g[\"index\"], g[\"name\"], f\"{g['mem_used_MB']}/{g['mem_total_MB']} MB\",\n",
    "          f\"{g['util_%']}%\", f\"{g['temp_C']}Â°C\", f\"{g['power_W']}W\"]\n",
    "         for g in gpus],\n",
    "        headers=[\"GPU\", \"Name\", \"Memory\", \"Util\", \"Temp\", \"Power\"],\n",
    "        tablefmt=\"grid\"\n",
    "    ))\n",
    "\n",
    "    idx = selected[\"index\"]\n",
    "    device_name = f\"cuda:{idx}\"\n",
    "\n",
    "    # Detect if running inside a Jupyter Notebook\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        in_notebook = get_ipython() is not None\n",
    "    except Exception:\n",
    "        in_notebook = False\n",
    "\n",
    "    if not in_notebook:\n",
    "        # âœ… Safe to set environment variable in normal Python script\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(idx)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"\\nâœ… Selected GPU {idx} {reason}\")\n",
    "        print(f\"Current device: {device} (logical GPU {idx})\\n\")\n",
    "    else:\n",
    "        # âš ï¸ In notebook environments, do not modify environment variables\n",
    "        device = torch.device(device_name if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"\\nâš ï¸ Detected Jupyter environment â€” not modifying CUDA_VISIBLE_DEVICES.\")\n",
    "        print(f\"âœ… Using device: {device_name} {reason}\\n\")\n",
    "\n",
    "    return idx, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess training data\n",
    "def load_and_prepare_train_df():\n",
    "    # 1ï¸âƒ£ Read raw CSV file\n",
    "    df_file_path = Path(DIRS[\"dir\"]) / \"train.csv\"\n",
    "    df = pd.read_csv(df_file_path)\n",
    "\n",
    "    # 2ï¸âƒ£ Extract unique ID (e.g., \"ID1011485656__Dry_Green_g\" â†’ \"ID1011485656\")\n",
    "    df[\"ID\"] = df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "\n",
    "    # 3ï¸âƒ£ Move ID column to the front\n",
    "    df = df[[\"ID\"] + [c for c in df if c != \"ID\"]]\n",
    "\n",
    "    # 4ï¸âƒ£ Pivot target values (long â†’ wide format)\n",
    "    df_targets = (\n",
    "        df.pivot_table(\n",
    "            index=\"ID\",\n",
    "            columns=\"target_name\",\n",
    "            values=\"target\",\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_targets.columns.name = None  # remove multi-index column names\n",
    "\n",
    "    # 5ï¸âƒ£ Extract metadata (one row per ID)\n",
    "    meta_cols = [\n",
    "        \"ID\", \"image_path\", \"Sampling_Date\", \"State\",\n",
    "        \"Species\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\"\n",
    "    ]\n",
    "    df_meta = df[meta_cols].drop_duplicates(subset=\"ID\")\n",
    "\n",
    "    # 6ï¸âƒ£ Merge metadata with target values\n",
    "    df_train = pd.merge(df_meta, df_targets, on=\"ID\", how=\"left\")\n",
    "    show_df_info(df_train, \"df_train\")\n",
    "\n",
    "    return df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ac761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fe813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–è®­ç»ƒæ•°æ®\n",
    "df = load_and_prepare_train_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2daf4",
   "metadata": {},
   "source": [
    "# æœ€ç»ˆæŠ¥å‘Šåˆ›å»ºæ–°ç‰¹å¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04adc091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š df_train         shape: (357, 12)         columns: ['ID', 'image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
      "ðŸŒ¿ Cleaning species names ...\n",
      "\n",
      "ðŸ“Š Species frequency:\n",
      "                Count  count\n",
      "0              clover    207\n",
      "1            ryegrass    175\n",
      "2            phalaris     76\n",
      "3              fescue     38\n",
      "4             lucerne     22\n",
      "5         barleygrass     18\n",
      "6         silvergrass     11\n",
      "7            capeweed     11\n",
      "8          speargrass     11\n",
      "9           crumbweed     10\n",
      "10        whiteclover     10\n",
      "11         bromegrass      7\n",
      "12      subcloverlosa      5\n",
      "13  subcloverdalkeith      3\n",
      "14              mixed      2\n"
     ]
    }
   ],
   "source": [
    "df_train = load_and_prepare_train_df().copy()\n",
    "\n",
    "print(\"ðŸŒ¿ Cleaning species names ...\")\n",
    "df_train[\"Species\"] = df_train[\"Species\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "# --- æŒ‰ä¸‹åˆ’çº¿åˆ†å‰²ï¼Œå¹¶å±•å¼€ ---\n",
    "all_species = (\n",
    "    df_train[\"Species\"]\n",
    "    .str.split(\"_\")         # åˆ†å‰²\n",
    "    .explode()              # å±•å¼€æˆæ–°è¡Œ\n",
    "    .str.strip()            # åŽ»ç©ºæ ¼\n",
    ")\n",
    "\n",
    "# --- ç»Ÿè®¡å‡ºçŽ°æ¬¡æ•° ---\n",
    "species_counts = (\n",
    "    all_species.value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"Species\", \"Species\": \"Count\"})\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Species frequency:\")\n",
    "print(species_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# ğŸ“¦ å¯¼å…¥åº“
import os
import socket
from lion_pytorch import Lion
import json
import time
import cv2
import h5py
import numpy as np
import pandas as pd
from tqdm import tqdm
from pathlib import Path
from datetime import datetime, timedelta
from PIL import Image
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
from torch.utils.data import DataLoader
import multiprocessing
import time
import numpy as np
import torch
from torch.cuda.amp import autocast
import gc, psutil, torch
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
import torch
from torch.optim.lr_scheduler import CosineAnnealingLR

import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
from torchvision import transforms, models
from torchvision.datasets import ImageFolder
from torchvision.models import get_model_weights

from sklearn.model_selection import GroupKFold, KFold
from sklearn.metrics import r2_score

# âš™ï¸ å…¨å±€é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åˆå§‹åŒ–
if socket.gethostname() == 'hao-2':
    dir = Path('D:/DATA_hao/Kaggle_/csiro-biomass/')
    DIRS = {
    "dir":        dir,                                       
    "train":     Path(dir, "train"),                              
    "test":     Path(dir, "test"),                              
    "model":     Path(dir,"DualStream_multihead"),              
    "data":     Path(dir),   
    }
    
    # # æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€
    # print("âœ… è·¯å¾„ï¼š\n")
    # for key, path in DIRS.items():
    #     print(f"{key:<12} : {path}")
else:
    dir = Path('/kaggle/input/csiro-biomass')
    DIRS = {
    "dir":        dir,                                       
    "train":     Path(dir, "train"),                              
    "test":     Path(dir, "test"),                              
    "model":     Path('/kaggle/input', "dualstream-multihead-model"),              
    "data":     Path("/kaggle/working/"),   
    }

    # # æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€
    # print("âœ… è·¯å¾„ï¼š\n")
    # for key, path in DIRS.items():
    #     print(f"{key:<12} : {path}")

# å°å‡½æ•°
def show_df_info(df, name: str):
    """
    æ‰“å°å•ä¸ª DataFrame çš„å½¢çŠ¶ä¸åˆ—åä¿¡æ¯ã€‚
    å‚æ•°:
        df   : pandas.DataFrame
        name : æ˜¾ç¤ºåç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    print(f"ğŸ“Š {name:<16} shape: {str(df.shape):<16}  åˆ—å: {df.columns.tolist()}")

def move_column_first(df, col_name):
    """
    å°† DataFrame ä¸­æŒ‡å®šåˆ—ç§»åŠ¨åˆ°æœ€å‰é¢ã€‚
    å‚æ•°:
        df (pd.DataFrame): åŸå§‹æ•°æ®æ¡†
        col_name (str): è¦ç§»åŠ¨åˆ°æœ€å‰é¢çš„åˆ—å
    è¿”å›:
        pd.DataFrame: è°ƒæ•´åçš„æ–° DataFrame
    """
    if col_name not in df.columns:
        raise ValueError(f"åˆ— '{col_name}' ä¸å­˜åœ¨äº DataFrame ä¸­ã€‚")

    cols = [col_name] + [c for c in df.columns if c != col_name]
    return df[cols]

# ğŸ§® åå¤„ç†å‡½æ•°ï¼ˆæ¢å¤ 5 ä¸ªç›®æ ‡ï¼‰
def recover_all_targets(df_pred_3):
    df = df_pred_3.copy()
    df["Dry_Clover_g"] = np.maximum(0, df["GDM_g"] - df["Dry_Green_g"])
    df["Dry_Dead_g"] = np.maximum(0, df["Dry_Total_g"] - df["GDM_g"])
    return df[["Dry_Green_g", "Dry_Dead_g", "Dry_Clover_g", "GDM_g", "Dry_Total_g"]]




# ğŸ§  MyDualStreamModelï¼šåŒæµ + å¤šå¤´å›å½’ + å†…éƒ¨è®­ç»ƒé€»è¾‘
class MyDualStreamModel(nn.Module):
    def __init__(self, 
                backbone_name="convnext_tiny", 
                pretrained=True, 
                config = None):
        """
        å‚æ•°:
        - backbone_name: timm æ¨¡å‹åç§° (å¦‚ convnext_tiny, resnet50)
        - pretrained: æ˜¯å¦åŠ è½½ ImageNet æƒé‡
        - freeze_ratio: å†»ç»“æ¯”ä¾‹ï¼ˆ0~1ï¼‰
        - weights_dict: å„ç›®æ ‡æƒé‡ (dict), ç”¨äº WeightedSmoothL1Loss
        """
        super().__init__()

        # 1ï¸âƒ£ Backbone
        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)
        in_dim = self.backbone.num_features

        # 2ï¸âƒ£ å†»ç»“éƒ¨åˆ†å‚æ•°
        params = list(self.backbone.parameters())
        freeze_until = int(len(params) * config["freeze_ratio"])
        for i, p in enumerate(params):
            p.requires_grad = i >= freeze_until  # å‰éƒ¨åˆ†å†»ç»“ï¼Œåéƒ¨åˆ†å¯å­¦ä¹ 

        # 3ï¸âƒ£ åŒæµèåˆ
        self.fusion_dim = in_dim * 2

        # 4ï¸âƒ£ ä¸‰ä¸ªè¾“å‡º Head
        def make_head():
            return nn.Sequential(
                nn.Linear(self.fusion_dim, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 128),
                nn.ReLU(),
                nn.Linear(128, 1)
            )

        # æ¨¡å‹ä»…é¢„æµ‹ä¸‰ä¸ªâ€œç‹¬ç«‹å˜é‡â€
        self.head_green  = make_head()   # Dry_Green_g
        self.head_clover = make_head()   # Dry_Clover_g
        self.head_dead   = make_head()   # Dry_Dead_g

        # 5ï¸âƒ£ æ³¨å†Œæ ‡å‡†åŒ–å‚æ•°
        self.register_buffer("y_mean", torch.tensor([
            config["mean"]["Dry_Green_g"],
            config["mean"]["Dry_Clover_g"],
            config["mean"]["Dry_Dead_g"]
        ]).float().view(1, 3))

        self.register_buffer("y_std", torch.tensor([
            config["std"]["Dry_Green_g"],
            config["std"]["Dry_Clover_g"],
            config["std"]["Dry_Dead_g"]
        ]).float().view(1, 3))

        # 6ï¸âƒ£ æƒé‡
        self.weights = config["weights"]

    # ------------------------------------------------------------
    # ğŸ” Forward
    # ------------------------------------------------------------
    def forward(self, img_left, img_right):
        # æå–ç‰¹å¾
        feat_left  = self.backbone(img_left)
        feat_right = self.backbone(img_right)
        fused = torch.cat([feat_left, feat_right], dim=1)

        # ä¸‰å¤´é¢„æµ‹ï¼ˆæ ‡å‡†åŒ–ç©ºé—´ï¼‰
        zG = self.head_green(fused)
        zC = self.head_clover(fused)
        zD = self.head_dead(fused)
        z = torch.cat([zG, zC, zD], dim=1)  # [B, 3]

        # åæ ‡å‡†åŒ– + éè´Ÿçº¦æŸ
        preds_3 = F.softplus(z * self.y_std + self.y_mean)

        # ç»“æ„åŒ–æ¨å¯¼å‡º GDM å’Œ Total
        G, C, D = preds_3[:, 0:1], preds_3[:, 1:2], preds_3[:, 2:3]
        GDM = G + C
        Total = G + C + D

        preds_full = torch.cat([G, C, D, GDM, Total], dim=1)  # [B, 5]
        return preds_full

    # ------------------------------------------------------------
    # ğŸ§® æŸå¤±è®¡ç®—ï¼ˆå†…éƒ¨è°ƒç”¨ï¼‰
    # ------------------------------------------------------------
    def compute_loss(self, preds, targets):
        """
        preds:   [B, 5] -> æ¨¡å‹é¢„æµ‹çš„ (G, C, D, GDM, Total)
        targets: [B, 5] -> å®Œæ•´çœŸå®å€¼ (G, C, D, GDM, Total)
        """
        l1 = nn.SmoothL1Loss(reduction="mean")
        w = self.weights

        G_pred, C_pred, D_pred, GDM_pred, Total_pred = [
            preds[:, i:i+1] for i in range(5)
        ]
        G_true, C_true, D_true, GDM_true, Total_true = [
            targets[:, i:i+1] for i in range(5)
        ]

        loss = (
            w["Dry_Green_g"]  * l1(G_pred, G_true) +
            w["Dry_Clover_g"] * l1(C_pred, C_true) +
            w["Dry_Dead_g"]   * l1(D_pred, D_true) +
            w["GDM_g"]        * l1(GDM_pred, GDM_true) +
            w["Dry_Total_g"]  * l1(Total_pred, Total_true)
        )
        return loss



# æ•°æ®é›†åŠ è½½å®šä¹‰
class DualStreamDataset(Dataset):
    def __init__(self, df, image_dir, config, transform=None):
        """
        df: DataFrameï¼ŒåŒ…å« image_path åˆ—
        image_dir: å›¾åƒç›®å½•
        target_cols: å¦‚æœæ˜¯è®­ç»ƒé›†ï¼ŒæŒ‡å®šç›®æ ‡åˆ—
        transform: Albumentations å˜æ¢
        """
        self.df = df.reset_index(drop=True)
        self.image_dir = image_dir
        self.target_cols = config["target_cols"]
        self.transform = transform

    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = Path(self.image_dir, str(row["image_path"]))
        
        # ====== 1ï¸âƒ£ å®‰å…¨åŠ è½½ ======
        if not img_path.exists():
            print(f"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
            image = np.zeros((1000, 2000, 3), dtype=np.uint8)
        else:
            try:
                image = Image.open(img_path).convert("RGB")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path} ({e})")
                image = np.zeros((1000, 2000, 3), dtype=np.uint8)

        # ====== 2ï¸âƒ£ ç¡®ä¿è½¬æ¢ä¸º NumPy æ•°ç»„ ======
        image = np.array(image)  # è½¬æ¢ä¸º NumPy æ•°ç»„
        h, w, _ = image.shape
        mid = w // 2
        
        # æ‹†åˆ†æˆå·¦å³ä¸¤ä¸ª patch
        img_left = image[:, :mid]
        img_right = image[:, mid:]

        # ====== 4ï¸âƒ£ åº”ç”¨ Albumentations å˜æ¢ ======
        if self.transform:
            img_left = self.transform(image=img_left)["image"]
            img_right = self.transform(image=img_right)["image"]

        # ====== 5ï¸âƒ£ è¿”å›ç»“æœ ======
        if self.target_cols is not None:
            targets = torch.tensor(row[self.target_cols].astype(float).values, dtype=torch.float32)
            return img_left, img_right, targets
        else:
            return img_left, img_right



# Albumentations å˜æ¢   è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•TTA
def get_train_transforms(size):
    return A.Compose([
        A.Resize(size, size),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.ColorJitter(p=0.3),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_valid_transforms(size):
    return A.Compose([
        A.Resize(size, size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_tta_transforms(size):
    return {
        "base": A.Compose([
            A.Resize(size, size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "hflip": A.Compose([
            A.Resize(size, size),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "vflip": A.Compose([
            A.Resize(size, size),
            A.VerticalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
    }




# è®¡ç®— Weighted RÂ² åˆ†æ•°ï¼ˆä¸ Kaggle Metric å¯¹é½ï¼‰
def compute_cv_score(all_preds, all_targets):
    preds = np.concatenate(all_preds, axis=0)
    targets = np.concatenate(all_targets, axis=0)

    # è®¡ç®—å„åˆ—RÂ²
    target_cols = ["Dry_Green_g", "Dry_Clover_g", "Dry_Dead_g", "GDM_g", "Dry_Total_g"]
    weights = np.array([0.1, 0.1, 0.1, 0.2, 0.5])

    # è®¡ç®—å„åˆ— RÂ²
    r2_each = {col: r2_score(targets[:, i], preds[:, i]) for i, col in enumerate(target_cols)}

    # åŠ æƒå¹³å‡
    weighted_r2 = sum(r2_each[col] * w for col, w in zip(target_cols, weights))

    return weighted_r2, r2_each

# ğŸ”¹ å•è½®è®­ç»ƒ
def train_one_epoch(model, dataloader, optimizer, device, scaler):
    model.train()
    running_loss = []

    start_epoch = time.time()
    prev_end = start_epoch  # â±ï¸ ä¸Šä¸€ batch ç»“æŸæ—¶é—´ï¼Œç”¨äºç»Ÿè®¡ data loading time

    for step, (img_left, img_right, targets) in enumerate(dataloader):
        t_load = time.time()  # dataloader å–åˆ° batch åçš„æ—¶é—´
        data_load_time = t_load - prev_end

        # ====== æ•°æ®æ‹·è´åˆ° GPU ======
        t0 = time.time()
        img_left, img_right, targets = (
            img_left.to(device, non_blocking=True),
            img_right.to(device, non_blocking=True),
            targets.to(device, non_blocking=True),
        )
        t1 = time.time()

        # ====== å‰å‘ + åå‘ ======
        optimizer.zero_grad(set_to_none=True)  # âœ… æ›´é«˜æ•ˆæ¸…ç©ºæ¢¯åº¦
        # âœ… AMPæ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
        with autocast():
            preds = model(img_left, img_right)
            loss = model.compute_loss(preds, targets)
        t2 = time.time()

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        t3 = time.time()

        running_loss.append(loss.item())
        prev_end = t3  # ä¸‹æ¬¡è®¡ç®— data_load_time ç”¨

        # # æ¯ N æ­¥æ‰“å°è€—æ—¶ç»†åˆ†
        # if step  == 0  or step  == 1:
        #     print(
        #         f"[TRAIN] Step {step:4d} | "
        #         f"data load: {data_load_time*1000:.1f} ms | "
        #         f"to(device): {(t1-t0)*1000:.1f} ms | "
        #         f"forward+loss: {(t2-t1)*1000:.1f} ms | "
        #         f"backward+opt: {(t3-t2)*1000:.1f} ms | "
        #         f"total: {(t3-t_load)*1000:.1f} ms"
        #     )

    end_epoch = time.time()
    epoch_time = end_epoch - start_epoch
    avg_batch_time = epoch_time / len(dataloader)

    # print(f"[TRAIN] Epoch total time: {epoch_time:.2f}s | "
    #       f"{len(dataloader)} batches | {avg_batch_time:.3f}s/batch")

    return float(np.mean(running_loss))

# ğŸ”¹ å•è½®éªŒè¯ + æœ¬åœ°CV
def validate_one_epoch(model, dataloader, device):
    model.eval()
    val_losses, all_preds, all_targets = [], [], []

    start_epoch = time.time()
    prev_end = start_epoch  # â±ï¸ ä¸Šä¸€ batch ç»“æŸæ—¶é—´ï¼ˆç”¨äºç»Ÿè®¡ data loading timeï¼‰

    with torch.no_grad():
        for step, (img_left, img_right, targets) in enumerate(dataloader):
            t_load = time.time()  # dataloader æä¾›å½“å‰ batch çš„æ—¶é—´
            data_load_time = t_load - prev_end

            # ====== æ•°æ®æ‹·è´åˆ° GPU ======
            t0 = time.time()
            img_left, img_right, targets = (
                img_left.to(device, non_blocking=True),
                img_right.to(device, non_blocking=True),
                targets.to(device, non_blocking=True),
            )
            t1 = time.time()

            # ====== å‰å‘æ¨ç† + è®¡ç®—æŸå¤± ======
            preds = model(img_left, img_right)
            val_loss = model.compute_loss(preds, targets).item()
            t2 = time.time()

            val_losses.append(val_loss)
            all_preds.append(preds.cpu().numpy())
            all_targets.append(targets.cpu().numpy())

            prev_end = t2  # ç”¨äºè®¡ç®—ä¸‹ä¸€ä¸ª batch çš„ data_load_time

            # æ¯ N æ­¥æ‰“å°è€—æ—¶ç»†åˆ†
            
            # if step  == 0  or step  == 1:
            #     print(
            #         f"[VAL] Step {step:4d} | "
            #         f"data load: {data_load_time*1000:.1f} ms | "
            #         f"to(device): {(t1 - t0)*1000:.1f} ms | "
            #         f"forward+loss: {(t2 - t1)*1000:.1f} ms | "
            #         f"total: {(t2 - t_load)*1000:.1f} ms"
            #     )

    end_epoch = time.time()
    epoch_time = end_epoch - start_epoch
    avg_val_loss = float(np.mean(val_losses))
    weighted_r2, _ = compute_cv_score(all_preds, all_targets)

    # print(
    #     f"[VAL] Epoch total time: {epoch_time:.2f}s | "
    #     f"{len(dataloader)} batches | {epoch_time / len(dataloader):.3f}s/batch"
    # )

    return avg_val_loss, weighted_r2

# ğŸ”¹ ä¸»å‡½æ•°ï¼šKFold è®­ç»ƒ
def train_with_groupkfold(
    df_train,
    save_dir,
    get_train_transforms,
    get_valid_transforms,
    config,
    device=None,
):
    """ä½¿ç”¨ GroupKFold è¿›è¡Œäº¤å‰éªŒè¯è®­ç»ƒ"""

    # åˆ›å»ºåˆ†ç»„ K æŠ˜å¯¹è±¡ï¼ˆæŒ‰é‡‡æ ·æ—¥æœŸåˆ†ç»„ï¼‰
    gkf = GroupKFold(n_splits=config["n_splits"])
    df = df_train.copy()
    groups = df["Sampling_Date"]

    # ä¿å­˜å„æŠ˜çš„æŒ‡æ ‡
    fold_train_losses, fold_val_losses, fold_cv_scores, fold_LR_records = [], [], [], []
    epoch_times = []  # â±ï¸ ä¿å­˜æœ€è¿‘ 10 ä¸ª epoch è€—æ—¶ï¼Œç”¨äºè®¡ç®— ETA


    # ğŸ” é€æŠ˜è®­ç»ƒ
    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=groups)):

        # åˆ’åˆ†å½“å‰æŠ˜çš„è®­ç»ƒé›†ä¸éªŒè¯é›†
        train_df = df.iloc[train_idx].reset_index(drop=True)
        valid_df = df.iloc[val_idx].reset_index(drop=True)

        # æ„å»º Dataset ä¸ DataLoader
        train_dataset = DualStreamDataset(train_df, DIRS["dir"], config, transform=get_train_transforms(config["img_size"]))
        valid_dataset = DualStreamDataset(valid_df, DIRS["dir"], config, transform=get_valid_transforms(config["img_size"]))


        # è‡ªåŠ¨è·å– CPU æ ¸å¿ƒæ•°ï¼ˆæ­¤å¤„æ‰‹åŠ¨è®¾å®šä¸º 4ï¼‰
        num_workers = 4
        prefetch_factor = 3

        train_loader = DataLoader(
            train_dataset,
            batch_size=config["batch_size"],
            shuffle=True,
            num_workers=num_workers,           # âœ… å¯ç”¨å¤šæ ¸åŠ è½½
            pin_memory=True,                   # âœ… åŠ é€Ÿ CPUâ†’GPU æ‹·è´
            prefetch_factor=prefetch_factor,   # âœ… æ¯ä¸ª worker é¢„åŠ è½½ 3 ä¸ª batch
            persistent_workers=True            # âœ… ä¿æŒ worker å¸¸é©»
        )
        valid_loader = DataLoader(
            valid_dataset,
            batch_size=config["batch_size"],
            shuffle=False,
            num_workers=max(1, num_workers // 2),  # éªŒè¯é›†çº¿ç¨‹å°‘ä¸€ç‚¹å³å¯
            pin_memory=True,
            prefetch_factor=prefetch_factor,
            persistent_workers=True
        )

        # âœ… æ¨¡å‹åˆå§‹åŒ–ï¼šchannels_last å†…å­˜å¸ƒå±€ + AMP å…¼å®¹
        model = MyDualStreamModel("convnext_tiny", pretrained=True, config=config)
        model = model.to(device).to(memory_format=torch.channels_last)

        # âœ… ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆæ¨èé¦–é€‰ï¼‰
        optimizer = torch.optim.AdamW(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=config["lr"],          # ä¸»å­¦ä¹ ç‡
            weight_decay=1e-2         # æ§åˆ¶å‚æ•°è§„æ¨¡çš„ L2 æ­£åˆ™ï¼ˆå»ºè®® 1e-2 ~ 5e-3ï¼‰
        )

        # âœ… è°ƒåº¦å™¨ï¼šä½™å¼¦é€€ç«ï¼ˆä¸€ä¸ªå®Œæ•´å‘¨æœŸï¼‰
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=config["epochs"],         # å­¦ä¹ ç‡é€€ç«å®Œæ•´å‘¨æœŸ
            eta_min=config["lr"] / 50       # æœ€ä½å­¦ä¹ ç‡æ¯”ä¾‹
        )

        # âœ… æ··åˆç²¾åº¦ç¼©æ”¾å™¨ï¼ˆæå‡é€Ÿåº¦ä¸æ˜¾å­˜æ•ˆç‡ï¼‰
        scaler = torch.cuda.amp.GradScaler()

        # è®°å½•å½“å‰æŠ˜æŒ‡æ ‡
        train_losses, val_losses, cv_scores, LR_records = [], [], [], []


        # ğŸ” é€ epoch è®­ç»ƒ
        for epoch in range(config["epochs"]):
            epoch_start = time.time()

            # --- å•è½®è®­ç»ƒä¸éªŒè¯ ---
            avg_train_loss = train_one_epoch(model, train_loader, optimizer, device, scaler)
            avg_val_loss, weighted_r2 = validate_one_epoch(model, valid_loader, device)
            scheduler.step()

            # --- è®°å½•æŒ‡æ ‡ ---
            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)
            cv_scores.append(weighted_r2)
            LR_records.append(scheduler.get_last_lr()[0])

            # --- å®šæœŸä¿å­˜æ¨¡å‹ ---
            if (epoch + 1) % config["save_interval"] == 0:
                save_path = save_dir / f"model_weights_fold{fold}_epoch{epoch+1}.pt"
                torch.save(model.state_dict(), save_path)

            # --- æ—¶é—´ç»Ÿè®¡ä¸ ETA ---
            epoch_time = time.time() - epoch_start
            if epoch > 0:
                epoch_times.append(epoch_time)
                if len(epoch_times) > 10:
                    epoch_times.pop(0)  # åªä¿ç•™æœ€è¿‘ 10 ä¸ª

            now_str = datetime.now().strftime("%H:%M:%S")
            progress = (epoch + 1) + fold * config["epochs"]
            all_progress = config["epochs"] * config["n_splits"]
            remaining_epochs = all_progress - progress

            avg_epoch_time = np.mean(epoch_times) if epoch_times else epoch_time
            eta_seconds = avg_epoch_time * remaining_epochs if epoch_times else float('nan')

            # ====== é¢„è®¡å®Œæˆæ—¶é—´ ======
            if not np.isnan(eta_seconds):
                eta_time = datetime.now() + timedelta(seconds=eta_seconds)
                eta_time = eta_time.replace(microsecond=0)
                days_diff = (eta_time.date() - datetime.now().date()).days
                eta_str = f"T+{days_diff} " + eta_time.strftime("%H:%M:%S") if days_diff > 0 else eta_time.strftime("%H:%M:%S")
            else:
                eta_str = "--:--:--"

            # --- æ—¥å¿—è¾“å‡º ---
            print(
                f"[{now_str}]ğŸ§©[{progress/all_progress*100:.2f}%] "
                f"Fold {fold}/{config['n_splits']} | "
                f"Epoch {epoch+1}/{config['epochs']} | "
                f"Train={avg_train_loss:.4f} | "
                f"Val={avg_val_loss:.4f} | "
                f"CV={weighted_r2:.4f} | "
                f"lr={scheduler.get_last_lr()[0]:.6f} | "
                f"{avg_epoch_time:.2f}s/it | "
                f"ETAâ‰ˆ{eta_str}\n",
                end="\r",
                flush=True
            )

        # ğŸ“¦ å½“å‰ Fold è®­ç»ƒå®Œæˆ
        torch.save(model.state_dict(), save_dir / f"model_weights_fold{fold}_final.pt")

        fold_train_losses.append(train_losses)
        fold_val_losses.append(val_losses)
        fold_cv_scores.append(cv_scores)
        fold_LR_records.append(LR_records)

        # ğŸ§¹ Fold ç»“æŸåæ¸…ç†ï¼ˆæ›´å½»åº•ï¼‰
        try:
            del train_loader, valid_loader, train_dataset, valid_dataset
        except Exception:
            pass
        try:
            del optimizer, scheduler, scaler
        except Exception:
            pass
        del model

        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        time.sleep(2)  # ç»™ dataloader worker é‡Šæ”¾æ—¶é—´


    # ğŸ“Š ä¿å­˜æ•´ä½“è®­ç»ƒæ—¥å¿—
    max_epochs = max(len(x) for x in fold_train_losses)
    df_out = pd.DataFrame({"Epoch": range(1, max_epochs + 1)})

    for i, (train_list, val_list, cv_list, lr_list) in enumerate(
        zip(fold_train_losses, fold_val_losses, fold_cv_scores, fold_LR_records),
        start=1
    ):
        df_out[f"Train_Loss_Fold{i}"] = train_list + [None] * (max_epochs - len(train_list))
        df_out[f"Val_Loss_Fold{i}"]   = val_list   + [None] * (max_epochs - len(val_list))
        df_out[f"CV_Fold{i}"]         = cv_list    + [None] * (max_epochs - len(cv_list))
        df_out[f"LR_Fold{i}"]         = lr_list    + [None] * (max_epochs - len(lr_list))

    out_path = Path(save_dir) / "fold_metrics.xlsx"
    df_out.to_excel(out_path, index=False)
    print(f"\nâœ… è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {out_path}")


# ğŸ“˜ è®­ç»ƒæ•°æ®è¯»å–ä¸é¢„å¤„ç†
def load_and_prepare_train_df():
    # 1ï¸âƒ£ è¯»å–åŸå§‹æ•°æ®
    df_file_path = Path(DIRS["dir"]) / "train.csv"
    df = pd.read_csv(df_file_path)
    # show_df_info(df, "train.csv")

    # 2ï¸âƒ£ æå–å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "ID1011485656__Dry_Green_g" â†’ "ID1011485656"ï¼‰
    df["ID"] = df["sample_id"].str.split("__").str[0]

    # 3ï¸âƒ£ å°† ID åˆ—ç§»åŠ¨åˆ°æœ€å‰é¢
    df = move_column_first(df, "ID")
    # show_df_info(df, "df")

    # 4ï¸âƒ£ ç›®æ ‡å€¼é€è§†ï¼ˆè¡Œè½¬åˆ—ï¼‰
    df_targets = (
        df
        .pivot_table(
            index="ID",
            columns="target_name",
            values="target",
            aggfunc="first"
        )
        .reset_index()
    )
    df_targets.columns.name = None  # å»æ‰å¤šçº§åˆ—åå±‚æ¬¡
    # show_df_info(df_targets, "df_targets")

    # 5ï¸âƒ£ æå–å…ƒä¿¡æ¯ï¼ˆæ¯ä¸ª ID ä»…ä¿ç•™ä¸€è¡Œï¼‰
    meta_cols = [
        "ID", "image_path", "Sampling_Date", "State",
        "Species", "Pre_GSHH_NDVI", "Height_Ave_cm"
    ]
    df_meta = df[meta_cols].drop_duplicates(subset="ID")
    # show_df_info(df_meta, "df_meta")

    # 6ï¸âƒ£ åˆå¹¶å…ƒä¿¡æ¯ä¸ç›®æ ‡æ•°æ®
    df_train = pd.merge(df_meta, df_targets, on="ID", how="left")
    show_df_info(df_train, "df_train")

    
    return df_train








# # è®­ç»ƒéƒ¨åˆ† æœ¬åœ°è¿è¡Œ

config = {
    # âš™ï¸ åŸºç¡€è®­ç»ƒå‚æ•°
    "epochs"       : 200,
    "freeze_ratio" : 0.5,
    "batch_size"   : 20,
    "lr"           : 1e-4,
    "n_splits"     : 5,
    "save_interval": 20,
    "img_size"     : 768,

    # ğŸ§® æ ‡å‡†åŒ–å‚æ•°ï¼ˆç”±è®­ç»ƒé›†è®¡ç®—å¾—å‡ºï¼‰
    "mean": {
        "Dry_Green_g" : 26.62472240896359,
        "Dry_Clover_g": 6.649692156862745,
        "Dry_Dead_g"  : 12.04454761904762
    },
    "std": {
        "Dry_Green_g" : 25.3656312828872,
        "Dry_Clover_g": 12.100777404153357,
        "Dry_Dead_g"  : 12.384625001433664
    },

    # âš–ï¸ æŸå¤±æƒé‡ï¼ˆä¸è¯„åˆ†è§„åˆ™å¯¹åº”ï¼‰
    "weights": {
        "Dry_Green_g" : 0.1,
        "Dry_Clover_g": 0.1,
        "Dry_Dead_g"  : 0.1,
        "GDM_g"       : 0.2,
        "Dry_Total_g" : 0.5
    },

    # ğŸ¯ æ¨¡å‹å®é™…é¢„æµ‹çš„ç›®æ ‡åˆ—ï¼ˆç‹¬ç«‹å˜é‡ï¼‰
    "model_target_cols": [
        "Dry_Green_g",
        "Dry_Clover_g",
        "Dry_Dead_g"
    ],

    # ğŸ“Š å®Œæ•´ç›®æ ‡åˆ—ï¼ˆåŒ…æ‹¬è®¡ç®—æ‰€å¾—çš„ GDMã€Totalï¼‰
    "target_cols": [
        "Dry_Green_g",
        "Dry_Clover_g",
        "Dry_Dead_g",
        "GDM_g",
        "Dry_Total_g"
    ]
}




if __name__ == "__main__":
    torch.multiprocessing.freeze_support()  # âœ… ä»…åœ¨ä¸»è¿›ç¨‹å…¥å£è°ƒç”¨ä¸€æ¬¡
    torch.backends.cudnn.benchmark = True  # âœ… å…¨å±€å¯ç”¨ cudnn benchmark
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")


    # å¯åŠ¨è®­ç»ƒ ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€


    # æœ¬åœ°æœºå™¨æ‰§è¡Œï¼ˆhao-2ï¼‰
    if socket.gethostname() == "hao-2":

        # ç”Ÿæˆæ—¶é—´æˆ³ä¸ç»“æœç›®å½•
        time_str = datetime.now().strftime("%Y-%m-%d %H-%M-%S")
        print(time_str)

        history_DIR = Path(DIRS["model"], time_str)
        os.makedirs(history_DIR, exist_ok=True)

        # ä¿å­˜é…ç½®æ–‡ä»¶
        config["time_str"] = time_str
        config_path = history_DIR / "config.json"
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=4, ensure_ascii=False)
        print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {config_path}")





        # è¯»å–è®­ç»ƒæ•°æ®
        df_train = load_and_prepare_train_df()

        # ğŸš€ å¯åŠ¨ KFold è®­ç»ƒ
        train_with_groupkfold(
            df_train             = df_train,
            save_dir             = history_DIR,
            get_train_transforms = get_train_transforms,
            get_valid_transforms = get_valid_transforms,
            config               = config,
            device               = device
        )

        print("\nâœ… å…¨éƒ¨è®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜åœ¨ï¼š", history_DIR)


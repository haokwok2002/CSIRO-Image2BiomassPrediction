# ğŸ“¦ å¯¼å…¥åº“
import os, json, time, socket, gc, psutil
import numpy as np, pandas as pd, torch, timm, cv2, h5py
import torch.nn as nn
from pathlib import Path
from datetime import datetime, timedelta
from torch.utils.data import DataLoader, Dataset
from torch.cuda.amp import autocast, GradScaler
from torch.optim.lr_scheduler import CosineAnnealingLR
from sklearn.model_selection import GroupKFold, KFold
from sklearn.metrics import r2_score
import albumentations as A
from albumentations.pytorch import ToTensorV2
from PIL import Image


# âš™ï¸ å…¨å±€é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åˆå§‹åŒ–
if socket.gethostname() == 'hao-2':
    dir = Path('D:/DATA_hao/Kaggle_/csiro-biomass/')
    DIRS = {
    "dir":        dir,                                       
    "train":     Path(dir, "train"),                              
    "test":     Path(dir, "test"),                              
    "model":     Path(dir,"DualStream_multihead"),              
    "data":     Path(dir),   
    }
    
    # # æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€
    # print("âœ… è·¯å¾„ï¼š\n")
    # for key, path in DIRS.items():
    #     print(f"{key:<12} : {path}")
else:
    dir = Path('/kaggle/input/csiro-biomass')
    DIRS = {
    "dir":        dir,                                       
    "train":     Path(dir, "train"),                              
    "test":     Path(dir, "test"),                              
    "model":     Path('/kaggle/input', "dualstream-multihead-model"),              
    "data":     Path("/kaggle/working/"),   
    }

    # # æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€
    # print("âœ… è·¯å¾„ï¼š\n")
    # for key, path in DIRS.items():
    #     print(f"{key:<12} : {path}")

# å°å‡½æ•°
def show_df_info(df, name: str):
    """
    æ‰“å°å•ä¸ª DataFrame çš„å½¢çŠ¶ä¸åˆ—åä¿¡æ¯ã€‚
    å‚æ•°:
        df   : pandas.DataFrame
        name : æ˜¾ç¤ºåç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    print(f"ğŸ“Š {name:<16} shape: {str(df.shape):<16}  åˆ—å: {df.columns.tolist()}")

def move_column_first(df, col_name):
    """
    å°† DataFrame ä¸­æŒ‡å®šåˆ—ç§»åŠ¨åˆ°æœ€å‰é¢ã€‚
    å‚æ•°:
        df (pd.DataFrame): åŸå§‹æ•°æ®æ¡†
        col_name (str): è¦ç§»åŠ¨åˆ°æœ€å‰é¢çš„åˆ—å
    è¿”å›:
        pd.DataFrame: è°ƒæ•´åçš„æ–° DataFrame
    """
    if col_name not in df.columns:
        raise ValueError(f"åˆ— '{col_name}' ä¸å­˜åœ¨äº DataFrame ä¸­ã€‚")

    cols = [col_name] + [c for c in df.columns if c != col_name]
    return df[cols]

# ğŸ§® åå¤„ç†å‡½æ•°ï¼ˆæ¢å¤ 5 ä¸ªç›®æ ‡ï¼‰
def recover_all_targets(df_pred_3):
    df = df_pred_3.copy()
    df["Dry_Clover_g"] = np.maximum(0, df["GDM_g"] - df["Dry_Green_g"])
    df["Dry_Dead_g"] = np.maximum(0, df["Dry_Total_g"] - df["GDM_g"])
    return df[["Dry_Green_g", "Dry_Dead_g", "Dry_Clover_g", "GDM_g", "Dry_Total_g"]]


# ğŸ§  MyDualStreamModelï¼šåŒæµ + å¤šå¤´å›å½’ + å†…éƒ¨è®­ç»ƒé€»è¾‘
class MyDualStreamModel(nn.Module):
    def __init__(self, 
                backbone_name="convnext_tiny", 
                pretrained=True, 
                config = None):
        """
        å‚æ•°:
        - backbone_name: timm æ¨¡å‹åç§° (å¦‚ convnext_tiny, resnet50)
        - pretrained: æ˜¯å¦åŠ è½½ ImageNet æƒé‡
        - freeze_ratio: å†»ç»“æ¯”ä¾‹ï¼ˆ0~1ï¼‰
        - weights_dict: å„ç›®æ ‡æƒé‡ (dict), ç”¨äº WeightedSmoothL1Loss
        """
        super().__init__()

        # 1ï¸âƒ£ Backbone
        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)
        in_dim = self.backbone.num_features

        # 2ï¸âƒ£ å†»ç»“éƒ¨åˆ†å‚æ•°
        params = list(self.backbone.parameters())
        freeze_until = int(len(params) * config["freeze_ratio"])
        for i, p in enumerate(params):
            p.requires_grad = i >= freeze_until  # å‰éƒ¨åˆ†å†»ç»“ï¼Œåéƒ¨åˆ†å¯å­¦ä¹ 

        # 3ï¸âƒ£ åŒæµèåˆ
        self.fusion_dim = in_dim * 2

        # 4ï¸âƒ£ ä¸‰ä¸ªè¾“å‡º Head
        def make_head():
            return nn.Sequential(
                nn.Linear(self.fusion_dim, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 128),
                nn.ReLU(),
                nn.Linear(128, 1)
            )

        # æ¨¡å‹ä»…é¢„æµ‹ä¸‰ä¸ªâ€œç‹¬ç«‹å˜é‡â€
        self.head_green  = make_head()   # Dry_Green_g
        self.head_clover = make_head()   # Dry_Clover_g
        self.head_dead   = make_head()   # Dry_Dead_g

        # 5ï¸âƒ£ æƒé‡
        self.weights = config["weights"]

    # ------------------------------------------------------------
    # ğŸ” Forward
    # ------------------------------------------------------------
    def forward(self, img_left, img_right):
        # æå–ç‰¹å¾
        feat_left  = self.backbone(img_left)
        feat_right = self.backbone(img_right)
        fused = torch.cat([feat_left, feat_right], dim=1)

        # ä¸‰å¤´é¢„æµ‹ï¼ˆæ ‡å‡†åŒ–ç©ºé—´ï¼‰
        zG = self.head_green(fused)
        zC = self.head_clover(fused)
        zD = self.head_dead(fused)
        preds_3 = torch.cat([zG, zC, zD], dim=1)  # [B, 3]


        # ç»“æ„åŒ–æ¨å¯¼å‡º GDM å’Œ Total
        G, C, D = preds_3[:, 0:1], preds_3[:, 1:2], preds_3[:, 2:3]
        GDM = G + C
        Total = G + C + D

        preds_full = torch.cat([G, C, D, GDM, Total], dim=1)  # [B, 5]
        return preds_full

    # ------------------------------------------------------------
    # ğŸ§® æŸå¤±è®¡ç®—ï¼ˆå†…éƒ¨è°ƒç”¨ï¼‰
    # ------------------------------------------------------------
    def compute_loss(self, preds, targets):
        l1 = nn.SmoothL1Loss(reduction="none")
        w = torch.tensor([
            self.weights["Dry_Green_g"],
            self.weights["Dry_Clover_g"],
            self.weights["Dry_Dead_g"],
            self.weights["GDM_g"],
            self.weights["Dry_Total_g"]
        ], device=preds.device).view(1, 5)

        per_target_loss = l1(preds, targets)
        weighted_loss = (per_target_loss * w).mean()
        return weighted_loss

# æ•°æ®é›†åŠ è½½å®šä¹‰
class DualStreamDataset(Dataset):
    def __init__(self, df, image_dir, config, transform=None):
        """
        df: DataFrameï¼ŒåŒ…å« image_path åˆ—
        image_dir: å›¾åƒç›®å½•
        target_cols: å¦‚æœæ˜¯è®­ç»ƒé›†ï¼ŒæŒ‡å®šç›®æ ‡åˆ—
        transform: Albumentations å˜æ¢
        """
        self.df = df.reset_index(drop=True)
        self.image_dir = image_dir
        self.target_cols = config["target_cols"]
        self.transform = transform

    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = Path(self.image_dir, str(row["image_path"]))
        
        # ====== 1ï¸âƒ£ å®‰å…¨åŠ è½½ ======
        if not img_path.exists():
            print(f"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
            image = np.zeros((1000, 2000, 3), dtype=np.uint8)
        else:
            try:
                image = Image.open(img_path).convert("RGB")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path} ({e})")
                image = np.zeros((1000, 2000, 3), dtype=np.uint8)

        # ====== 2ï¸âƒ£ ç¡®ä¿è½¬æ¢ä¸º NumPy æ•°ç»„ ======
        image = np.array(image)  # è½¬æ¢ä¸º NumPy æ•°ç»„
        h, w, _ = image.shape
        mid = w // 2
        
        # æ‹†åˆ†æˆå·¦å³ä¸¤ä¸ª patch
        img_left = image[:, :mid]
        img_right = image[:, mid:]

        # ====== 4ï¸âƒ£ åº”ç”¨ Albumentations å˜æ¢ ======
        if self.transform:
            img_left = self.transform(image=img_left)["image"]
            img_right = self.transform(image=img_right)["image"]

        # ====== 5ï¸âƒ£ è¿”å›ç»“æœ ======
        if self.target_cols is not None:
            targets = torch.tensor(row[self.target_cols].astype(float).values, dtype=torch.float32)
            return img_left, img_right, targets
        else:
            return img_left, img_right

# Albumentations å˜æ¢   è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•TTA
def get_train_transforms(size):
    return A.Compose([
        A.Resize(size, size),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.ColorJitter(p=0.3),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_valid_transforms(size):
    return A.Compose([
        A.Resize(size, size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_tta_transforms(size):
    return {
        "base": A.Compose([
            A.Resize(size, size),
            A.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "hflip": A.Compose([
            A.Resize(size, size),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "vflip": A.Compose([
            A.Resize(size, size),
            A.VerticalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "rot90": A.Compose([
            A.Resize(size, size),
            A.RandomRotate90(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "brightness": A.Compose([
            A.Resize(size, size),
            A.RandomBrightnessContrast(brightness_limit=0.1,
                                       contrast_limit=0.1, p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "gamma": A.Compose([
            A.Resize(size, size),
            A.RandomGamma(gamma_limit=(90, 110), p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
    }

# âœ… è®¡ç®— Weighted RÂ² åˆ†æ•°ï¼ˆå®Œå…¨ä¸ Kaggle Metric å¯¹é½ï¼‰
def compute_cv_score(all_preds, all_targets):
    preds = np.concatenate(all_preds, axis=0)
    targets = np.concatenate(all_targets, axis=0)

    # äº”ä¸ªç›®æ ‡åˆ—åä¸å¯¹åº”æƒé‡ï¼ˆä¸å®˜æ–¹ç›¸åŒï¼‰
    target_cols = ["Dry_Green_g", "Dry_Clover_g", "Dry_Dead_g", "GDM_g", "Dry_Total_g"]
    weights = np.array([0.1, 0.1, 0.1, 0.2, 0.5])

    # æ‹¼æ¥æ‰€æœ‰ç›®æ ‡
    y_true_flat = np.concatenate([targets[:, i] for i in range(5)])
    y_pred_flat = np.concatenate([preds[:, i] for i in range(5)])
    w_flat = np.concatenate([np.full_like(targets[:, i], weights[i]) for i in range(5)])

    # å…¨å±€åŠ æƒå‡å€¼
    y_mean = np.sum(w_flat * y_true_flat) / np.sum(w_flat)

    # è®¡ç®—åŠ æƒæ®‹å·®å¹³æ–¹å’Œä¸æ€»å¹³æ–¹å’Œ
    ss_res = np.sum(w_flat * (y_true_flat - y_pred_flat) ** 2)
    ss_tot = np.sum(w_flat * (y_true_flat - y_mean) ** 2)

    # Kaggle å®˜æ–¹å…¨å±€åŠ æƒ RÂ²
    r2_global = 1 - ss_res / ss_tot
    return r2_global


# ğŸ”¹ å•è½®è®­ç»ƒ
def train_one_epoch(model, dataloader, optimizer, device, scaler):
    model.train()
    running_loss = []

    start_epoch = time.time()
    prev_end = start_epoch  # â±ï¸ ä¸Šä¸€ batch ç»“æŸæ—¶é—´ï¼Œç”¨äºç»Ÿè®¡ data loading time

    for step, (img_left, img_right, targets) in enumerate(dataloader):
        t_load = time.time()  # dataloader å–åˆ° batch åçš„æ—¶é—´
        data_load_time = t_load - prev_end

        # ====== æ•°æ®æ‹·è´åˆ° GPU ======
        t0 = time.time()
        img_left, img_right, targets = (
            img_left.to(device, non_blocking=True),
            img_right.to(device, non_blocking=True),
            targets.to(device, non_blocking=True),
        )
        t1 = time.time()

        # ====== å‰å‘ + åå‘ ======
        optimizer.zero_grad(set_to_none=True)  # âœ… æ›´é«˜æ•ˆæ¸…ç©ºæ¢¯åº¦
        # âœ… AMPæ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
        with autocast():
            preds = model(img_left, img_right)
            loss = model.compute_loss(preds, targets)
        t2 = time.time()

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        t3 = time.time()

        running_loss.append(loss.item())
        prev_end = t3  # ä¸‹æ¬¡è®¡ç®— data_load_time ç”¨

        # æ¯ N æ­¥æ‰“å°è€—æ—¶ç»†åˆ†
        # if step  == 0  or step  == 1:
        # print(
        #     f"[TRAIN] Step {step:4d} | "
        #     f"data load: {data_load_time*1000:.1f} ms | "
        #     f"to(device): {(t1-t0)*1000:.1f} ms | "
        #     f"forward+loss: {(t2-t1)*1000:.1f} ms | "
        #     f"backward+opt: {(t3-t2)*1000:.1f} ms | "
        #     f"total: {(t3-t_load)*1000:.1f} ms"
        # )

    end_epoch = time.time()
    epoch_time = end_epoch - start_epoch
    avg_batch_time = epoch_time / len(dataloader)

    # print(f"[TRAIN] Epoch total time: {epoch_time:.2f}s | "
    #       f"{len(dataloader)} batches | {avg_batch_time:.3f}s/batch")

    return float(np.mean(running_loss))

# ğŸ”¹ å•è½®éªŒè¯ + æœ¬åœ°CV
def validate_one_epoch(model, dataloader, device):
    model.eval()
    val_losses, all_preds, all_targets = [], [], []

    start_epoch = time.time()
    prev_end = start_epoch  # â±ï¸ ä¸Šä¸€ batch ç»“æŸæ—¶é—´ï¼ˆç”¨äºç»Ÿè®¡ data loading timeï¼‰

    with torch.no_grad():
        for step, (img_left, img_right, targets) in enumerate(dataloader):
            t_load = time.time()  # dataloader æä¾›å½“å‰ batch çš„æ—¶é—´
            data_load_time = t_load - prev_end

            # ====== æ•°æ®æ‹·è´åˆ° GPU ======
            t0 = time.time()
            img_left, img_right, targets = (
                img_left.to(device, non_blocking=True),
                img_right.to(device, non_blocking=True),
                targets.to(device, non_blocking=True),
            )
            t1 = time.time()

            # ====== å‰å‘æ¨ç† + è®¡ç®—æŸå¤± ======
            preds = model(img_left, img_right)
            val_loss = model.compute_loss(preds, targets).item()
            t2 = time.time()

            val_losses.append(val_loss)
            all_preds.append(preds.cpu().numpy())
            all_targets.append(targets.cpu().numpy())

            prev_end = t2  # ç”¨äºè®¡ç®—ä¸‹ä¸€ä¸ª batch çš„ data_load_time

            # æ¯ N æ­¥æ‰“å°è€—æ—¶ç»†åˆ†
            
            # if step  == 0  or step  == 1:
            #     print(
            #         f"[VAL] Step {step:4d} | "
            #         f"data load: {data_load_time*1000:.1f} ms | "
            #         f"to(device): {(t1 - t0)*1000:.1f} ms | "
            #         f"forward+loss: {(t2 - t1)*1000:.1f} ms | "
            #         f"total: {(t2 - t_load)*1000:.1f} ms"
            #     )

    end_epoch = time.time()
    epoch_time = end_epoch - start_epoch
    avg_val_loss = float(np.mean(val_losses))
    r2_global = compute_cv_score(all_preds, all_targets)

    # print(
    #     f"[VAL] Epoch total time: {epoch_time:.2f}s | "
    #     f"{len(dataloader)} batches | {epoch_time / len(dataloader):.3f}s/batch"
    # )

    return avg_val_loss, r2_global

# ğŸ”¹ ä¸»å‡½æ•°ï¼šKFold è®­ç»ƒ
def train_with_groupkfold(  
    df_train,
    save_dir,
    get_train_transforms,
    get_valid_transforms,
    config,
    device=None,
):
    """ä½¿ç”¨ GroupKFold è¿›è¡Œäº¤å‰éªŒè¯è®­ç»ƒ"""

    df = df_train.copy()



    # å›ºå®šéšæœºç§å­
    np.random.seed(42)
    # æ‰“ä¹±åˆ†ç»„é¡ºåºï¼ˆåªæ‰“ä¹± Sampling_Date çš„é¡ºåºï¼Œä¸ç ´åç»„å†…ç»“æ„ï¼‰
    unique_groups = df["Sampling_Date"].unique()
    shuffled_groups = np.random.permutation(unique_groups)
    # é‡å»º group åºåˆ—ï¼ˆæ˜ å°„æ‰“ä¹±é¡ºåºï¼‰
    group_mapping = {g: i for i, g in enumerate(shuffled_groups)}
    df["GroupID"] = df["Sampling_Date"].map(group_mapping)
    # é‡æ–°åˆ†ç»„
    # åˆ›å»ºåˆ†ç»„ K æŠ˜å¯¹è±¡ï¼ˆæŒ‰é‡‡æ ·æ—¥æœŸåˆ†ç»„ï¼‰
    gkf = GroupKFold(n_splits=config["n_splits"])
    groups = df["GroupID"]
    


    # ä¿å­˜å„æŠ˜çš„æŒ‡æ ‡
    fold_train_losses, fold_val_losses, fold_cv_scores, fold_LR_records = [], [], [], []
    epoch_times = []  # â±ï¸ ä¿å­˜æœ€è¿‘ 10 ä¸ª epoch è€—æ—¶ï¼Œç”¨äºè®¡ç®— ETA


    # ğŸ” é€æŠ˜è®­ç»ƒ
    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=groups)):

        # åˆ’åˆ†å½“å‰æŠ˜çš„è®­ç»ƒé›†ä¸éªŒè¯é›†
        train_df = df.iloc[train_idx].reset_index(drop=True)
        valid_df = df.iloc[val_idx].reset_index(drop=True)

        # æ„å»º Dataset ä¸ DataLoader
        train_dataset = DualStreamDataset(train_df, DIRS["dir"], config, transform=get_train_transforms(config["img_size"]))
        valid_dataset = DualStreamDataset(valid_df, DIRS["dir"], config, transform=get_valid_transforms(config["img_size"]))


        # è‡ªåŠ¨è·å– CPU æ ¸å¿ƒæ•°ï¼ˆæ­¤å¤„æ‰‹åŠ¨è®¾å®šä¸º 4ï¼‰
        num_workers = 4
        prefetch_factor = 3

        train_loader = DataLoader(
            train_dataset,
            batch_size=config["batch_size"],
            shuffle=True,
            num_workers=num_workers,           # âœ… å¯ç”¨å¤šæ ¸åŠ è½½
            pin_memory=True,                   # âœ… åŠ é€Ÿ CPUâ†’GPU æ‹·è´
            prefetch_factor=prefetch_factor,   # âœ… æ¯ä¸ª worker é¢„åŠ è½½ 3 ä¸ª batch
            persistent_workers=True            # âœ… ä¿æŒ worker å¸¸é©»
        )
        valid_loader = DataLoader(
            valid_dataset,
            batch_size=config["batch_size"],
            shuffle=False,
            num_workers=max(1, num_workers // 2),  # éªŒè¯é›†çº¿ç¨‹å°‘ä¸€ç‚¹å³å¯
            pin_memory=True,
            prefetch_factor=prefetch_factor,
            persistent_workers=True
        )


        # âœ… æ¨¡å‹åˆå§‹åŒ–ï¼šchannels_last å†…å­˜å¸ƒå±€ + AMP å…¼å®¹
        model = MyDualStreamModel(config["backbone_name"], pretrained=True, config=config)
        model = model.to(device).to(memory_format=torch.channels_last)

        # âœ… ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆæ¨èé¦–é€‰ï¼‰
        optimizer = torch.optim.AdamW(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=config["lr"]          # ä¸»å­¦ä¹ ç‡
            # weight_decay=1e-2         # æ§åˆ¶å‚æ•°è§„æ¨¡çš„ L2 æ­£åˆ™ï¼ˆå»ºè®® 1e-2 ~ 5e-3ï¼‰
        )

        # âœ… è°ƒåº¦å™¨ï¼šä½™å¼¦é€€ç«ï¼ˆä¸€ä¸ªå®Œæ•´å‘¨æœŸï¼‰
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=config["epochs"],         # å­¦ä¹ ç‡é€€ç«å®Œæ•´å‘¨æœŸ
            eta_min=config["lr"] / 100       # æœ€ä½å­¦ä¹ ç‡æ¯”ä¾‹
        )

        # âœ… æ··åˆç²¾åº¦ç¼©æ”¾å™¨ï¼ˆæå‡é€Ÿåº¦ä¸æ˜¾å­˜æ•ˆç‡ï¼‰
        scaler = torch.cuda.amp.GradScaler()

        # è®°å½•å½“å‰æŠ˜æŒ‡æ ‡
        train_losses, val_losses, cv_scores, LR_records = [], [], [], []


        # ğŸ” é€ epoch è®­ç»ƒ
        for epoch in range(config["epochs"]):
            epoch_start = time.time()

            # --- å•è½®è®­ç»ƒä¸éªŒè¯ ---
            avg_train_loss = train_one_epoch(model, train_loader, optimizer, device, scaler)
            avg_val_loss, r2_global = validate_one_epoch(model, valid_loader, device)
            scheduler.step()

            # --- è®°å½•æŒ‡æ ‡ ---
            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)
            cv_scores.append(r2_global)
            LR_records.append(scheduler.get_last_lr()[0])

            # --- Early Stopping æ¡ä»¶æ£€æµ‹ ---
            if epoch >= 20:
                window_scores = cv_scores[-20:]  # æœ€è¿‘20ä¸ªepoch
                diff = max(window_scores) - min(window_scores)
                if diff < config["cv_stability_stop_threshold"]:
                    print(
                        f"\nğŸ›‘ Early stopping triggered on Fold {fold} at Epoch {epoch+1} "
                        f"(CV fluctuation {diff:.4f} < threshold {config['cv_stability_stop_threshold']})"
                    )
                    break

            # --- å®šæœŸä¿å­˜æ¨¡å‹ ---
            if (epoch + 1) % config["save_interval"] == 0:
                save_path = save_dir / f"model_weights_fold{fold}_epoch{epoch+1}.pt"
                torch.save(model.state_dict(), save_path)

            # --- æ—¶é—´ç»Ÿè®¡ä¸ ETA ---
            epoch_time = time.time() - epoch_start
            if epoch > 0:
                epoch_times.append(epoch_time)
                if len(epoch_times) > 10:
                    epoch_times.pop(0)  # åªä¿ç•™æœ€è¿‘ 10 ä¸ª

            now_str = datetime.now().strftime("%H:%M:%S")
            progress = (epoch + 1) + fold * config["epochs"]
            all_progress = config["epochs"] * config["n_splits"]
            remaining_epochs = all_progress - progress

            avg_epoch_time = np.mean(epoch_times) if epoch_times else epoch_time
            eta_seconds = avg_epoch_time * remaining_epochs if epoch_times else float('nan')

            # ====== é¢„è®¡å®Œæˆæ—¶é—´ ======
            if not np.isnan(eta_seconds):
                eta_time = datetime.now() + timedelta(seconds=eta_seconds)
                eta_time = eta_time.replace(microsecond=0)
                days_diff = (eta_time.date() - datetime.now().date()).days
                eta_str = f"T+{days_diff} " + eta_time.strftime("%H:%M:%S") if days_diff > 0 else eta_time.strftime("%H:%M:%S")
            else:
                eta_str = "--:--:--"

            # --- æ—¥å¿—è¾“å‡º ---
            print(
                f"[{now_str}]ğŸ§©[{progress/all_progress*100:.2f}%] "
                f"Fold {fold}/{config['n_splits']} | "
                f"Epoch {epoch+1}/{config['epochs']} | "
                f"Train={avg_train_loss:.4f} | "
                f"Val={avg_val_loss:.4f} | "
                f"CV={r2_global:.4f} | "
                f"lr={scheduler.get_last_lr()[0]:.6f} | "
                f"{avg_epoch_time:.2f}s/it | "
                f"ETAâ‰ˆ{eta_str}\n",
                end="\r",
                flush=True
            )







        # ğŸ“¦ å½“å‰ Fold è®­ç»ƒå®Œæˆ
        torch.save(model.state_dict(), save_dir / f"model_weights_fold{fold}_epoch{epoch+1}_final.pt")

        fold_train_losses.append(train_losses)
        fold_val_losses.append(val_losses)
        fold_cv_scores.append(cv_scores)
        fold_LR_records.append(LR_records)

        # ğŸ§¹ Fold ç»“æŸåæ¸…ç†ï¼ˆæ›´å½»åº•ï¼‰
        try:
            del train_loader, valid_loader, train_dataset, valid_dataset
        except Exception:
            pass
        try:
            del optimizer, scheduler, scaler
        except Exception:
            pass
        del model

        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        time.sleep(2)  # ç»™ dataloader worker é‡Šæ”¾æ—¶é—´


    # ğŸ“Š ä¿å­˜æ•´ä½“è®­ç»ƒæ—¥å¿—
    max_epochs = max(len(x) for x in fold_train_losses)
    df_out = pd.DataFrame({"Epoch": range(1, max_epochs + 1)})

    for i, (train_list, val_list, cv_list, lr_list) in enumerate(
        zip(fold_train_losses, fold_val_losses, fold_cv_scores, fold_LR_records),
        start=1
    ):
        df_out[f"Train_Loss_Fold{i}"] = train_list + [None] * (max_epochs - len(train_list))
        df_out[f"Val_Loss_Fold{i}"]   = val_list   + [None] * (max_epochs - len(val_list))
        df_out[f"CV_Fold{i}"]         = cv_list    + [None] * (max_epochs - len(cv_list))
        df_out[f"LR_Fold{i}"]         = lr_list    + [None] * (max_epochs - len(lr_list))

    out_path = Path(save_dir) / "fold_metrics.xlsx"
    df_out.to_excel(out_path, index=False)
    print(f"\nâœ… è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {out_path}")

# ğŸ“˜ è®­ç»ƒæ•°æ®è¯»å–ä¸é¢„å¤„ç†
def load_and_prepare_train_df():
    # 1ï¸âƒ£ è¯»å–åŸå§‹æ•°æ®
    df_file_path = Path(DIRS["dir"]) / "train.csv"
    df = pd.read_csv(df_file_path)
    # show_df_info(df, "train.csv")

    # 2ï¸âƒ£ æå–å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "ID1011485656__Dry_Green_g" â†’ "ID1011485656"ï¼‰
    df["ID"] = df["sample_id"].str.split("__").str[0]

    # 3ï¸âƒ£ å°† ID åˆ—ç§»åŠ¨åˆ°æœ€å‰é¢
    df = move_column_first(df, "ID")
    # show_df_info(df, "df")

    # 4ï¸âƒ£ ç›®æ ‡å€¼é€è§†ï¼ˆè¡Œè½¬åˆ—ï¼‰
    df_targets = (
        df
        .pivot_table(
            index="ID",
            columns="target_name",
            values="target",
            aggfunc="first"
        )
        .reset_index()
    )
    df_targets.columns.name = None  # å»æ‰å¤šçº§åˆ—åå±‚æ¬¡
    # show_df_info(df_targets, "df_targets")

    # 5ï¸âƒ£ æå–å…ƒä¿¡æ¯ï¼ˆæ¯ä¸ª ID ä»…ä¿ç•™ä¸€è¡Œï¼‰
    meta_cols = [
        "ID", "image_path", "Sampling_Date", "State",
        "Species", "Pre_GSHH_NDVI", "Height_Ave_cm"
    ]
    df_meta = df[meta_cols].drop_duplicates(subset="ID")
    # show_df_info(df_meta, "df_meta")

    # 6ï¸âƒ£ åˆå¹¶å…ƒä¿¡æ¯ä¸ç›®æ ‡æ•°æ®
    df_train = pd.merge(df_meta, df_targets, on="ID", how="left")
    show_df_info(df_train, "df_train")

    
    return df_train



config = {
    # âš™ï¸ åŸºç¡€è®­ç»ƒå‚æ•°
    "epochs"       : 240,
    "freeze_ratio" : 0.0,
    "batch_size"   : 12,
    "lr"           : 1e-4,
    "n_splits"     : 5,
    "save_interval": 20,
    "img_size"     : 500,
    "backbone_name"     : "focalnet_tiny_srf",
    "cv_stability_stop_threshold"     : 0.03,

    # âš–ï¸ æŸå¤±æƒé‡ï¼ˆä¸è¯„åˆ†è§„åˆ™å¯¹åº”ï¼‰
    "weights": {
        "Dry_Green_g" : 0.1,
        "Dry_Clover_g": 0.1,
        "Dry_Dead_g"  : 0.1,
        "GDM_g"       : 0.2,
        "Dry_Total_g" : 0.5
    },

    # ğŸ“Š å®Œæ•´ç›®æ ‡åˆ—ï¼ˆåŒ…æ‹¬è®¡ç®—æ‰€å¾—çš„ GDMã€Totalï¼‰
    "target_cols": [
        "Dry_Green_g",
        "Dry_Clover_g",
        "Dry_Dead_g",
        "GDM_g",
        "Dry_Total_g"
    ]
}


# è®­ç»ƒéƒ¨åˆ†
isTRAIN = True
if __name__ == "__main__" and isTRAIN: 
    torch.multiprocessing.freeze_support()  # âœ… ä»…åœ¨ä¸»è¿›ç¨‹å…¥å£è°ƒç”¨ä¸€æ¬¡
    torch.backends.cudnn.benchmark = True  # âœ… å…¨å±€å¯ç”¨ cudnn benchmark
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")


    # å¯åŠ¨è®­ç»ƒ ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€


    # æœ¬åœ°æœºå™¨æ‰§è¡Œï¼ˆhao-2ï¼‰
    if socket.gethostname() == "hao-2":

        # ç”Ÿæˆæ—¶é—´æˆ³ä¸ç»“æœç›®å½•
        time_str = datetime.now().strftime("%Y-%m-%d %H-%M-%S")
        print(time_str)

        history_DIR = Path(DIRS["model"], time_str)
        os.makedirs(history_DIR, exist_ok=True)

        # ä¿å­˜é…ç½®æ–‡ä»¶
        config["time_str"] = time_str
        config_path = history_DIR / "config.json"
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=4, ensure_ascii=False)
        print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {config_path}")





        # è¯»å–è®­ç»ƒæ•°æ®
        df_train = load_and_prepare_train_df()

        # ğŸš€ å¯åŠ¨ KFold è®­ç»ƒ
        train_with_groupkfold(
            df_train             = df_train,
            save_dir             = history_DIR,
            get_train_transforms = get_train_transforms,
            get_valid_transforms = get_valid_transforms,
            config               = config,
            device               = device
        )

        print("\nâœ… å…¨éƒ¨è®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜åœ¨ï¼š", history_DIR)





# é¢„æµ‹éƒ¨åˆ†
# ğŸ“˜ æ•°æ®è¯»å–ä¸é¢„å¤„ç†ï¼ˆæµ‹è¯•é›†ï¼‰
def load_and_prepare_test_df():
    # 1ï¸âƒ£ è¯»å–åŸå§‹æ•°æ®
    df_file_path = Path(DIRS["dir"]) / "test.csv"
    df = pd.read_csv(df_file_path)
    show_df_info(df, "test.csv")

    # 2ï¸âƒ£ æå–å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "ID1011485656__Dry_Green_g" â†’ "ID1011485656"ï¼‰
    df["ID"] = df["sample_id"].str.split("__").str[0]

    # 3ï¸âƒ£ å°† ID åˆ—ç§»åŠ¨åˆ°æœ€å‰é¢
    df = move_column_first(df, "ID")

    # 4ï¸âƒ£ åˆå§‹åŒ–ç›®æ ‡åˆ—ï¼ˆtest é›†æ— ç›®æ ‡å€¼ï¼‰
    df["target"] = 0
    show_df_info(df, "df")

    # 5ï¸âƒ£ ç›®æ ‡åˆ—é€è§†ï¼ˆè¡Œè½¬åˆ—ç»“æ„ä¿æŒä¸€è‡´ï¼‰
    df_targets = (
        df
        .pivot_table(
            index="ID",
            columns="target_name",
            values="target",
            aggfunc="first"
        )
        .reset_index()
    )
    df_targets.columns.name = None  # å»æ‰å¤šçº§åˆ—åå±‚æ¬¡
    show_df_info(df_targets, "df_targets")

    # 6ï¸âƒ£ æå–å…ƒä¿¡æ¯ï¼ˆæ¯ä¸ª ID ä»…ä¿ç•™ä¸€è¡Œï¼‰
    meta_cols = [
        "ID",
        "image_path",
    ]
    df_meta = df[meta_cols].drop_duplicates(subset="ID")
    show_df_info(df_meta, "df_meta")

    # 7ï¸âƒ£ åˆå¹¶å…ƒä¿¡æ¯ä¸ç›®æ ‡æ•°æ®
    df_test = pd.merge(df_meta, df_targets, on="ID", how="left")
    show_df_info(df_test, "df_test")

    return df_test

# åŸºäº model  transform  model_dir  é¢„æµ‹
def predict_ensemble_df(df_test, transform, model, model_target_cols, model_dir, device, batch_size=32, img_size=768):

    model_dir = model_dir
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    assert model_dir.exists(), f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}"

    # ğŸ” æœç´¢æ‰€æœ‰ fold æ¨¡å‹
    model_paths = sorted(model_dir.glob("model_weights_fold*_final.pt"))
    if not model_paths:
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_dir}/model_weights_fold*.pt")

    print(f"ğŸ”¹ æ£€æµ‹åˆ° {len(model_paths)} ä¸ªæ¨¡å‹:")
    for p in model_paths:
        print("   -", p.name)

    # 3ï¸âƒ£ æ„å»ºæµ‹è¯•æ•°æ®é›†
    test_dataset = DualStreamDataset(
        df_test, 
        DIRS["dir"], 
        config, 
        transform=transform 
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    # å­˜å‚¨æ¯ä¸ªfoldçš„é¢„æµ‹
    fold_preds = []

    for fold, model_path in enumerate(model_paths):
        print(f"ğŸš€ åŠ è½½æ¨¡å‹ {fold+1}/{len(model_paths)}: {model_path.name}")

        # 1ï¸âƒ£ åŠ è½½æ¨¡å‹ç»“æ„
        model = model

        # 2ï¸âƒ£ åŠ è½½æƒé‡
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
        model.eval()

        # 3ï¸âƒ£ æ¨ç†
        preds_list = []
        with torch.no_grad():
            for img_left, img_right, _ in test_loader:
                img_left, img_right = img_left.to(device, non_blocking=True), img_right.to(device, non_blocking=True)
                preds = model(img_left, img_right)
                preds_list.append(preds.cpu().numpy())

        fold_pred = np.concatenate(preds_list, axis=0)
        fold_preds.append(fold_pred)

    # 4ï¸âƒ£ å¤šæ¨¡å‹å¹³å‡
    preds_mean = np.mean(fold_preds, axis=0)
    df_pred5 = pd.DataFrame(preds_mean, columns=model_target_cols)





    # è¿½åŠ æ ·æœ¬ ID å¹¶è°ƒæ•´åˆ—é¡ºåº
    df_pred5["ID"] = df_test["ID"]
    df_pred5 = df_pred5[["ID"] + model_target_cols]




    # æ‰“å°ç»“æœé¢„è§ˆ
    show_df_info(df_pred5, "final df_pred5")

    return df_pred5

# ğŸ“¤ 5ï¸âƒ£ ç”Ÿæˆ Kaggle æäº¤æ–‡ä»¶ submission.csv
def generate_Kaggle_file(df_pred_final):

    df = df_pred_final

    # æŒ‰æŒ‡å®šé¡ºåºå±•å¼€
    ordered_target_cols = [
        "Dry_Clover_g",  # 1ï¸âƒ£
        "Dry_Dead_g",    # 2ï¸âƒ£
        "Dry_Green_g",   # 3ï¸âƒ£
        "Dry_Total_g",   # 4ï¸âƒ£
        "GDM_g"          # 5ï¸âƒ£
    ]

    df_submit = (
        df
        .melt(id_vars="ID", value_vars=ordered_target_cols,
            var_name="target_name", value_name="target")
    )

    # ç»„åˆæˆ Kaggle æ‰€éœ€çš„ sample_id
    df_submit["sample_id"] = df_submit["ID"] + "__" + df_submit["target_name"]

    df_submit = move_column_first(df_submit, "target")
    df_submit = move_column_first(df_submit, "sample_id")

    # åªä¿ç•™ Kaggle è¦çš„ä¸¤åˆ—
    df_submit = df_submit[["sample_id", "target"]]
    df_submit
    # æŒ‰ sample_id æ’åºï¼ˆå¯é€‰ï¼‰
    # df_submit = df_submit.sort_values("sample_id").reset_index(drop=True)

    # ä¿å­˜æ–‡ä»¶
    df_submit.to_csv("submission.csv", index=False)
    print("âœ… å·²ç”Ÿæˆæäº¤æ–‡ä»¶ submission.csv")

# ğŸ§  æ¨¡å‹åŠ è½½ä¸ TTA æ¨ç†
if __name__ == "__main__" and not isTRAIN: 

    # 1ï¸âƒ£ åŠ è½½æ¨¡å‹ç»“æ„
    # âœ… æ¨¡å‹åˆå§‹åŒ–ï¼šchannels_last å†…å­˜å¸ƒå±€ + AMP å…¼å®¹
    model = MyDualStreamModel(config["backbone_name"], pretrained=False, config=config)
    model = model.to(device).to(memory_format=torch.channels_last)

    # 2ï¸âƒ£ è®¾ç½®æ¨¡å‹ç›®å½•ï¼ˆæ ¹æ®è¿è¡Œç¯å¢ƒè‡ªåŠ¨åˆ‡æ¢ï¼‰
    if socket.gethostname() == "hao-2":
        model_dir = Path(DIRS["model"] , "2025-11-02 23-23-25")
    else:
        model_dir = DIRS["model"]

    # 3ï¸âƒ£ æ‰§è¡Œ TTAï¼ˆTest-Time Augmentationï¼‰æ¨ç†
    tta_preds = []
    tta_transforms = get_tta_transforms(config["img_size"])

    for name, tform in tta_transforms.items():
        print(f"\nğŸš€ Running TTA: {name}")

        transform  = tform
        df_pred5   = predict_ensemble_df(
            df_test           = load_and_prepare_test_df(),
            transform         = transform,
            model             = model,
            model_target_cols = config["target_cols"],
            model_dir         = model_dir,
            device            = device,
            img_size          = config["img_size"]
        )
        
        # âœ… è¾“å‡ºé˜¶æ®µæ€§ç»“æœ
        print(f"\nğŸ“„ å½“å‰ TTA æ¨¡å¼ [{name}] çš„é¢„æµ‹ç»“æœé¢„è§ˆï¼š")
        print(df_pred5.head())

        tta_preds.append(df_pred5[config["target_cols"]].values)

        print(f"\nğŸ“¦ å½“å‰å·²æ”¶é›†çš„ TTA ç»“æœæ•°é‡ï¼š{len(tta_preds)}")
        print(f"ğŸ“Š å½“å‰ç´¯è®¡ç»“æœå½¢çŠ¶ï¼š{np.array(tta_preds).shape}")
        print("-" * 60)
        print("\n\n\n")


    # 4ï¸âƒ£ æ±‡æ€» TTA ç»“æœå¹¶è®¡ç®—å¹³å‡é¢„æµ‹
    print("\nğŸ“¦ èšåˆå…¨éƒ¨ TTA ç»“æœï¼š")
    print(f"å…±æœ‰ {len(tta_preds)} ç»„é¢„æµ‹ç»“æœã€‚")
    for i, arr in enumerate(tta_preds):
        print(f"  â””â”€ ç¬¬ {i+1} ç»„é¢„æµ‹: {arr}")

    mean_preds = np.mean(tta_preds, axis=0)

    print("\nğŸ§® è®¡ç®—å¹³å‡å€¼å®Œæˆï¼š")
    print(mean_preds)
    print(f"\nâœ… èšåˆå®Œæˆï¼Œmean_preds å½¢çŠ¶ï¼š{mean_preds.shape}")


    # 5ï¸âƒ£ ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ DataFrame
    df_pred_final = df_pred5.copy()
    df_pred_final[config["target_cols"]] = mean_preds

    print("\nğŸ§¾ æœ€ç»ˆé¢„æµ‹ DataFrame é¢„è§ˆï¼š")
    print(df_pred_final.head())
    show_df_info(df_pred_final, "df_pred_final")

    generate_Kaggle_file(df_pred_final)



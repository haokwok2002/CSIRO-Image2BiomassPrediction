# ğŸ“¦ å¯¼å…¥åº“
import os
import socket
from lion_pytorch import Lion
import json
import time
import cv2
import h5py
import numpy as np
import pandas as pd
from tqdm import tqdm
from pathlib import Path
from datetime import datetime, timedelta
from PIL import Image
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts

from torch.utils.data import DataLoader
import multiprocessing
import time
import numpy as np
import torch
from torch.cuda.amp import autocast

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
import torch
from torch.optim.lr_scheduler import CosineAnnealingLR

import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
from torchvision import transforms, models
from torchvision.datasets import ImageFolder
from torchvision.models import get_model_weights

from sklearn.model_selection import GroupKFold, KFold
from sklearn.metrics import r2_score

# âš™ï¸ å…¨å±€é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åˆå§‹åŒ–
if socket.gethostname() == 'hao-2':
    dir = Path('D:/DATA_hao/Kaggle_/csiro-biomass/')
    DIRS = {
    "dir":        dir,                                       
    "train":     Path(dir, "train"),                              
    "test":     Path(dir, "test"),                              
    "model":     Path(dir,"DualStream_multihead"),              
    "data":     Path(dir),   
    }
    
    # # æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€
    # print("âœ… è·¯å¾„ï¼š\n")
    # for key, path in DIRS.items():
    #     print(f"{key:<12} : {path}")
else:
    dir = Path('/kaggle/input/csiro-biomass')
    DIRS = {
    "dir":        dir,                                       
    "train":     Path(dir, "train"),                              
    "test":     Path(dir, "test"),                              
    "model":     Path('/kaggle/input', "dualstream-multihead-model"),              
    "data":     Path("/kaggle/working/"),   
    }

    # # æ‰“å°æ—¶ä¸€è¡Œä¸€ä¸ªåœ°å€
    # print("âœ… è·¯å¾„ï¼š\n")
    # for key, path in DIRS.items():
    #     print(f"{key:<12} : {path}")

# å°å‡½æ•°
def show_df_info(df, name: str):
    """
    æ‰“å°å•ä¸ª DataFrame çš„å½¢çŠ¶ä¸åˆ—åä¿¡æ¯ã€‚
    å‚æ•°:
        df   : pandas.DataFrame
        name : æ˜¾ç¤ºåç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    print(f"ğŸ“Š {name:<16} shape: {str(df.shape):<16}  åˆ—å: {df.columns.tolist()}")

def move_column_first(df, col_name):
    """
    å°† DataFrame ä¸­æŒ‡å®šåˆ—ç§»åŠ¨åˆ°æœ€å‰é¢ã€‚
    å‚æ•°:
        df (pd.DataFrame): åŸå§‹æ•°æ®æ¡†
        col_name (str): è¦ç§»åŠ¨åˆ°æœ€å‰é¢çš„åˆ—å
    è¿”å›:
        pd.DataFrame: è°ƒæ•´åçš„æ–° DataFrame
    """
    if col_name not in df.columns:
        raise ValueError(f"åˆ— '{col_name}' ä¸å­˜åœ¨äº DataFrame ä¸­ã€‚")

    cols = [col_name] + [c for c in df.columns if c != col_name]
    return df[cols]

# ğŸ§® åå¤„ç†å‡½æ•°ï¼ˆæ¢å¤ 5 ä¸ªç›®æ ‡ï¼‰
def recover_all_targets(df_pred_3):
    df = df_pred_3.copy()
    df["Dry_Clover_g"] = np.maximum(0, df["GDM_g"] - df["Dry_Green_g"])
    df["Dry_Dead_g"] = np.maximum(0, df["Dry_Total_g"] - df["GDM_g"])
    return df[["Dry_Green_g", "Dry_Dead_g", "Dry_Clover_g", "GDM_g", "Dry_Total_g"]]




# # æ•°æ®é›†ã€æ¨¡å‹ã€è®­ç»ƒ å®šä¹‰
# ğŸ§  MyDualStreamModelï¼šåŒæµ + å¤šå¤´å›å½’ + å†…éƒ¨è®­ç»ƒé€»è¾‘
class WeightedSmoothL1Loss(nn.Module):
    def __init__(self, weights):
        super().__init__()
        self.weights = list(weights.values())
        self.loss_fn = nn.SmoothL1Loss(reduction="none")

    def forward(self, pred, target):
        losses = self.loss_fn(pred, target)
        weighted = sum(losses[:, i] * w for i, w in enumerate(self.weights))
        return weighted.mean()

class MyDualStreamModel(nn.Module):
    def __init__(self, 
                backbone_name="convnext_tiny", 
                pretrained=True, 
                freeze_ratio=0.8,
                weights_dict=None):
        """
        å‚æ•°:
        - backbone_name: timm æ¨¡å‹åç§° (å¦‚ convnext_tiny, resnet50)
        - pretrained: æ˜¯å¦åŠ è½½ ImageNet æƒé‡
        - freeze_ratio: å†»ç»“æ¯”ä¾‹ï¼ˆ0~1ï¼‰
        - weights_dict: å„ç›®æ ‡æƒé‡ (dict), ç”¨äº WeightedSmoothL1Loss
        """
        super().__init__()

        # 1ï¸âƒ£ Backbone
        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)
        in_dim = self.backbone.num_features

        # 2ï¸âƒ£ å†»ç»“éƒ¨åˆ†å‚æ•°
        params = list(self.backbone.parameters())
        freeze_until = int(len(params) * freeze_ratio)
        for i, p in enumerate(params):
            p.requires_grad = i >= freeze_until  # å‰éƒ¨åˆ†å†»ç»“ï¼Œåéƒ¨åˆ†å¯å­¦ä¹ 

        # 3ï¸âƒ£ åŒæµèåˆ
        self.fusion_dim = in_dim * 2

        # 4ï¸âƒ£ ä¸‰ä¸ªè¾“å‡º Head
        def make_head():
            return nn.Sequential(
                nn.Linear(self.fusion_dim, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 128),
                nn.ReLU(),
                nn.Linear(128, 1)
            )

        self.head_total = make_head()
        self.head_gdm   = make_head()
        self.head_green = make_head()

        # 5ï¸âƒ£ æŸå¤±å‡½æ•°ï¼ˆWeighted SmoothL1Lossï¼‰
        self.loss_fn = WeightedSmoothL1Loss(weights_dict) if weights_dict else nn.SmoothL1Loss()



    # ------------------------------------------------------------
    # ğŸ” Forward
    # ------------------------------------------------------------
    def forward(self, img_left, img_right):
        feat_left  = self.backbone(img_left)
        feat_right = self.backbone(img_right)
        fused = torch.cat([feat_left, feat_right], dim=1)

        total = self.head_total(fused)
        gdm   = self.head_gdm(fused)
        green = self.head_green(fused)
        preds = torch.cat([green, gdm, total], dim=1)
        return preds  # shape: [batch, 3]

    # ------------------------------------------------------------
    # ğŸ§® æŸå¤±è®¡ç®—ï¼ˆå†…éƒ¨è°ƒç”¨ï¼‰
    # ------------------------------------------------------------
    def compute_loss(self, preds, targets):
        return self.loss_fn(preds, targets)



# æ•°æ®é›†åŠ è½½å®šä¹‰
# ä¸€æ¬¡æ€§æŠŠæ‰€æœ‰å›¾ç‰‡åŠ è½½è¿› RAM
def preload_images_to_ram(df, image_dir):
    cache = {}
    print(f"ğŸš€ é¢„åŠ è½½ {len(df)} å¼ å›¾ç‰‡åˆ°å†…å­˜ä¸­...")
    for _, row in tqdm(df.iterrows(), total=len(df)):
        img_path = Path(image_dir) / str(row["image_path"])
        try:
            image = Image.open(img_path).convert("RGB")
            cache[str(img_path)] = np.array(image, dtype=np.uint8)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path} ({e})")
            cache[str(img_path)] = np.zeros((1000, 2000, 3), dtype=np.uint8)
    print(f"âœ… å›¾ç‰‡å·²å…¨éƒ¨ç¼“å­˜åˆ°å†…å­˜ï¼Œå…± {len(cache)} å¼ ")
    return cache

class DualStreamDataset(Dataset):
    def __init__(self, df, image_dir, target_cols=None, transform=None, cache=None):
        """
        df: DataFrameï¼ŒåŒ…å« image_path åˆ—
        image_dir: å›¾åƒç›®å½•
        target_cols: å¦‚æœæ˜¯è®­ç»ƒé›†ï¼ŒæŒ‡å®šç›®æ ‡åˆ—
        transform: Albumentations å˜æ¢
        """
        self.df = df
        self.image_dir = image_dir
        self.target_cols = target_cols
        self.transform = transform
        self.cache = cache  # âœ… æ–°å¢

    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = Path(self.image_dir, str(row["image_path"]))
        
        # ====== 1ï¸âƒ£ å®‰å…¨åŠ è½½ ======
        if not img_path.exists():
            print(f"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
            image = np.zeros((1000, 2000, 3), dtype=np.uint8)
        else:
            try:
                image = Image.open(img_path).convert("RGB")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path} ({e})")
                image = np.zeros((1000, 2000, 3), dtype=np.uint8)

        # ====== 2ï¸âƒ£ ç¡®ä¿è½¬æ¢ä¸º NumPy æ•°ç»„ ======
        image = np.array(image)  # è½¬æ¢ä¸º NumPy æ•°ç»„
        h, w, _ = image.shape
        mid = w // 2
        
        # æ‹†åˆ†æˆå·¦å³ä¸¤ä¸ª patch
        img_left = image[:, :mid]
        img_right = image[:, mid:]

        # ====== 4ï¸âƒ£ åº”ç”¨ Albumentations å˜æ¢ ======
        if self.transform:
            img_left = self.transform(image=img_left)["image"]
            img_right = self.transform(image=img_right)["image"]

        # ====== 5ï¸âƒ£ è¿”å›ç»“æœ ======
        if self.target_cols is not None:
            targets = torch.tensor(row[self.target_cols].astype(float).values, dtype=torch.float32)
            return img_left, img_right, targets
        else:
            return img_left, img_right
        

    # def __getitem__(self, idx):
    #     row = self.df.iloc[idx]
    #     img_path = str(Path(self.image_dir) / row["image_path"])

    #     # 1ï¸âƒ£ ä¼˜å…ˆä»å†…å­˜è¯»å–
    #     if self.cache is not None and img_path in self.cache:
    #         image = self.cache[img_path]
    #     else:
    #         try:
    #             image = np.array(Image.open(img_path).convert("RGB"), dtype=np.uint8)
    #         except Exception as e:
    #             print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path} ({e})")
    #             image = np.zeros((1000, 2000, 3), dtype=np.uint8)

    #     # 2ï¸âƒ£ æ‹†å·¦å³
    #     h, w, _ = image.shape
    #     mid = w // 2
    #     img_left, img_right = image[:, :mid], image[:, mid:]

    #     # 3ï¸âƒ£ Albumentations å˜æ¢
    #     if self.transform:
    #         img_left = self.transform(image=img_left)["image"]
    #         img_right = self.transform(image=img_right)["image"]

    #     # 4ï¸âƒ£ è¿”å›
    #     if self.target_cols is not None:
    #         targets = torch.tensor(row[self.target_cols].astype(float).values, dtype=torch.float32)
    #         return img_left, img_right, targets
    #     else:
    #         return img_left, img_right



# Albumentations å˜æ¢   è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•TTA
def get_train_transforms(size):
    return A.Compose([
        A.Resize(size, size),
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.ColorJitter(p=0.3),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_valid_transforms(size):
    return A.Compose([
        A.Resize(size, size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def get_tta_transforms(size):
    return {
        "base": A.Compose([
            A.Resize(size, size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "hflip": A.Compose([
            A.Resize(size, size),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
        "vflip": A.Compose([
            A.Resize(size, size),
            A.VerticalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ]),
    }




# è®¡ç®— Weighted RÂ² åˆ†æ•°ï¼ˆä¸ Kaggle Metric å¯¹é½ï¼‰
def compute_cv_score(valid_df, all_preds, all_targets):
    """
    è®¡ç®—å•ä¸ª Fold çš„ Weighted RÂ² åˆ†æ•°ï¼ˆä¸ Kaggle Metric å¯¹é½ï¼‰

    å‚æ•°:
        valid_df      : å½“å‰ fold çš„éªŒè¯ DataFrameï¼ˆå«çœŸå®å€¼5åˆ—ï¼‰
        all_preds     : æ¨¡å‹é¢„æµ‹ç»“æœ (list of numpy arrays, shape=[N,3])
        all_targets   : çœŸå®ç›®æ ‡ (list of numpy arrays, shape=[N,3])

    è¿”å›:
        weighted_r2   : åŠ æƒ RÂ² åˆ†æ•°
        r2_each       : å„ç›®æ ‡å•ç‹¬ RÂ²
    """
    preds_array = np.concatenate(all_preds)
    targets_array = np.concatenate(all_targets)

    # æ„å»ºçœŸå®å€¼è¡¨
    df_val = valid_df.copy()
    df_val[["Dry_Green_g", "GDM_g", "Dry_Total_g"]] = targets_array

    # æ„å»ºé¢„æµ‹è¡¨
    df_pred = df_val.copy()
    df_pred["Dry_Green_g"] = preds_array[:, 0]
    df_pred["GDM_g"]       = preds_array[:, 1]
    df_pred["Dry_Total_g"] = preds_array[:, 2]

    # æ ¹æ®å…³ç³»å¼è¡¥é½
    df_pred["Dry_Clover_g"] = df_pred["GDM_g"] - df_pred["Dry_Green_g"]
    df_pred["Dry_Dead_g"]   = df_pred["Dry_Total_g"] - df_pred["GDM_g"]

    # è®¡ç®—å„åˆ—RÂ²
    target_cols = ["Dry_Green_g", "Dry_Dead_g", "Dry_Clover_g", "GDM_g", "Dry_Total_g"]
    r2_each = {col: r2_score(df_val[col], df_pred[col]) for col in target_cols}

    # åŠ æƒå¹³å‡ï¼ˆæƒé‡ä¸ Kaggle ä¸€è‡´ï¼‰
    weights = {
        "Dry_Green_g": 0.1,
        "Dry_Dead_g": 0.1,
        "Dry_Clover_g": 0.1,
        "GDM_g": 0.2,
        "Dry_Total_g": 0.5,
    }
    weighted_r2 = sum(r2_each[k] * w for k, w in weights.items())
    return weighted_r2, r2_each

# ğŸ”¹ å•è½®è®­ç»ƒ
def train_one_epoch(model, dataloader, optimizer, device, scaler):
    model.train()
    running_loss = []

    start_epoch = time.time()
    prev_end = start_epoch  # â±ï¸ ä¸Šä¸€ batch ç»“æŸæ—¶é—´ï¼Œç”¨äºç»Ÿè®¡ data loading time

    for step, (img_left, img_right, targets) in enumerate(dataloader):
        t_load = time.time()  # dataloader å–åˆ° batch åçš„æ—¶é—´
        data_load_time = t_load - prev_end

        # ====== æ•°æ®æ‹·è´åˆ° GPU ======
        t0 = time.time()
        img_left, img_right, targets = (
            img_left.to(device, non_blocking=True),
            img_right.to(device, non_blocking=True),
            targets.to(device, non_blocking=True),
        )
        t1 = time.time()

        # ====== å‰å‘ + åå‘ ======
        optimizer.zero_grad(set_to_none=True)  # âœ… æ›´é«˜æ•ˆæ¸…ç©ºæ¢¯åº¦
        # âœ… AMPæ··åˆç²¾åº¦ä¸Šä¸‹æ–‡
        with autocast():
            preds = model(img_left, img_right)
            loss = model.compute_loss(preds, targets)
        t2 = time.time()

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        t3 = time.time()

        running_loss.append(loss.item())
        prev_end = t3  # ä¸‹æ¬¡è®¡ç®— data_load_time ç”¨

        # # æ¯ N æ­¥æ‰“å°è€—æ—¶ç»†åˆ†
        # if step  == 0  or step  == 1:
        #     print(
        #         f"[TRAIN] Step {step:4d} | "
        #         f"data load: {data_load_time*1000:.1f} ms | "
        #         f"to(device): {(t1-t0)*1000:.1f} ms | "
        #         f"forward+loss: {(t2-t1)*1000:.1f} ms | "
        #         f"backward+opt: {(t3-t2)*1000:.1f} ms | "
        #         f"total: {(t3-t_load)*1000:.1f} ms"
        #     )

    end_epoch = time.time()
    epoch_time = end_epoch - start_epoch
    avg_batch_time = epoch_time / len(dataloader)

    # print(f"[TRAIN] Epoch total time: {epoch_time:.2f}s | "
    #       f"{len(dataloader)} batches | {avg_batch_time:.3f}s/batch")

    return float(np.mean(running_loss))

# ğŸ”¹ å•è½®éªŒè¯ + æœ¬åœ°CV
def validate_one_epoch(model, dataloader, valid_df, device):
    model.eval()
    val_losses, all_preds, all_targets = [], [], []

    start_epoch = time.time()
    prev_end = start_epoch  # â±ï¸ ä¸Šä¸€ batch ç»“æŸæ—¶é—´ï¼ˆç”¨äºç»Ÿè®¡ data loading timeï¼‰

    with torch.no_grad():
        for step, (img_left, img_right, targets) in enumerate(dataloader):
            t_load = time.time()  # dataloader æä¾›å½“å‰ batch çš„æ—¶é—´
            data_load_time = t_load - prev_end

            # ====== æ•°æ®æ‹·è´åˆ° GPU ======
            t0 = time.time()
            img_left, img_right, targets = (
                img_left.to(device, non_blocking=True),
                img_right.to(device, non_blocking=True),
                targets.to(device, non_blocking=True),
            )
            t1 = time.time()

            # ====== å‰å‘æ¨ç† + è®¡ç®—æŸå¤± ======
            preds = model(img_left, img_right)
            val_loss = model.compute_loss(preds, targets).item()
            t2 = time.time()

            val_losses.append(val_loss)
            all_preds.append(preds.cpu().numpy())
            all_targets.append(targets.cpu().numpy())

            prev_end = t2  # ç”¨äºè®¡ç®—ä¸‹ä¸€ä¸ª batch çš„ data_load_time

            # æ¯ N æ­¥æ‰“å°è€—æ—¶ç»†åˆ†
            
            # if step  == 0  or step  == 1:
            #     print(
            #         f"[VAL] Step {step:4d} | "
            #         f"data load: {data_load_time*1000:.1f} ms | "
            #         f"to(device): {(t1 - t0)*1000:.1f} ms | "
            #         f"forward+loss: {(t2 - t1)*1000:.1f} ms | "
            #         f"total: {(t2 - t_load)*1000:.1f} ms"
            #     )

    end_epoch = time.time()
    epoch_time = end_epoch - start_epoch
    avg_val_loss = float(np.mean(val_losses))
    weighted_r2, _ = compute_cv_score(valid_df, all_preds, all_targets)

    # print(
    #     f"[VAL] Epoch total time: {epoch_time:.2f}s | "
    #     f"{len(dataloader)} batches | {epoch_time / len(dataloader):.3f}s/batch"
    # )

    return avg_val_loss, weighted_r2

# ğŸ”¹ ä¸»å‡½æ•°ï¼šKFold è®­ç»ƒ
def train_with_groupkfold(
    df_train,
    cache,  
    save_dir,
    model_target_cols,
    get_train_transforms,
    get_valid_transforms,
    weights,
    freeze_ratio=0.8,
    batch_size=32,
    epochs=50,
    lr=1e-4,
    device=None,
    n_splits=5,
    save_interval=20,
    img_size = 768, # âœ… ä¼ å…¥ç¼“å­˜
):


    gkf = GroupKFold(n_splits=n_splits)

    df = df_train.copy()
    groups = df["Sampling_Date"]

    # ç”¨äºä¿å­˜æ¯æŠ˜ è®­ç»ƒæŸå¤±  éªŒè¯  æœ¬åœ°CV
    fold_train_losses, fold_val_losses, fold_cv_scores, fold_LR_records = [], [], [], []
    epoch_times = []  # â±ï¸ ä¿å­˜æœ€è¿‘ 11 ä¸ª epoch è€—æ—¶

    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=groups)):
        
        
        train_df = df.iloc[train_idx].reset_index(drop=True)
        valid_df = df.iloc[val_idx].reset_index(drop=True)

        train_dataset = DualStreamDataset(train_df, DIRS["dir"], model_target_cols, transform=get_train_transforms(img_size), cache = cache)
        valid_dataset = DualStreamDataset(valid_df, DIRS["dir"], model_target_cols, transform=get_valid_transforms(img_size), cache = cache)

        # è‡ªåŠ¨è·å– CPU æ ¸å¿ƒæ•°çš„ä¸€åŠï¼ˆå®‰å…¨è€Œé«˜æ•ˆï¼‰
        num_workers = max(1, multiprocessing.cpu_count() // 2)
        num_workers = 4
        prefetch_factor = 3
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,         # âœ… å¯ç”¨å¤šæ ¸åŠ è½½
            pin_memory=True,                 # âœ… åŠ é€Ÿ CPUâ†’GPU æ‹·è´
            prefetch_factor=prefetch_factor,               # âœ… æ¯ä¸ª worker é¢„åŠ è½½2ä¸ªbatch
            persistent_workers=True          # âœ… ä¿æŒ worker å¸¸é©»ï¼Œä¸æ¯è½®é‡å¯
        )

        valid_loader = DataLoader(
            valid_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=max(1, num_workers // 2),  # éªŒè¯é›†å¯ä»¥å°‘ç‚¹çº¿ç¨‹
            pin_memory=True,
            prefetch_factor=prefetch_factor,
            persistent_workers=True
        )



        # # âœ… å¢åŠ  pin_memory æé«˜ä¸»æœºâ†’GPU ä¼ è¾“é€Ÿåº¦
        # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True , num_workers=0, pin_memory=True)
        # valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)

        # âœ… æ¨¡å‹ä¼˜åŒ–ï¼šchannels_last å†…å­˜å¸ƒå±€ + AMP å…¼å®¹
        model = MyDualStreamModel("convnext_tiny", pretrained=True, freeze_ratio=freeze_ratio, weights_dict=weights)
        model = model.to(device).to(memory_format=torch.channels_last)

        # âœ… ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆæ¨èé¦–é€‰ï¼‰
        optimizer = torch.optim.AdamW(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=lr,                    # ä¸»å­¦ä¹ ç‡
            weight_decay=1e-2         # æ§åˆ¶å‚æ•°è§„æ¨¡çš„L2æ­£åˆ™ï¼ˆå»ºè®®1e-2~5e-3ï¼‰
        )

        # âœ… è°ƒåº¦å™¨ï¼šä½™å¼¦é€€ç«ï¼ˆæ ¹æ®ä½ 160 epochå·¦å³æ”¶æ•›æƒ…å†µï¼‰
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=epochs,                # å­¦ä¹ ç‡é€€ç«ä¸€ä¸ªå®Œæ•´å‘¨æœŸï¼ˆè€Œä¸æ˜¯300ï¼‰
            eta_min=lr / 50           # æœ€ä½å­¦ä¹ ç‡æ¯”ä¾‹ï¼ˆé¿å…å¤ªæ—©è¡°å‡ï¼‰
        )

        # âœ… æ··åˆç²¾åº¦ç¼©æ”¾å™¨ï¼ˆæå‡é€Ÿåº¦ä¸æ˜¾å­˜æ•ˆç‡ï¼‰
        scaler = torch.cuda.amp.GradScaler()



        
        # ç”¨äºä¿å­˜å½“å‰æŠ˜ è®­ç»ƒæŸå¤±  éªŒè¯  æœ¬åœ°CV
        train_losses, val_losses, cv_scores, LR_records = [], [], [], []

        for epoch in range(epochs):
            epoch_start = time.time()
            

            avg_train_loss = train_one_epoch(model, train_loader, optimizer, device, scaler)
            avg_val_loss, weighted_r2 = validate_one_epoch(model, valid_loader, valid_df, device)

            scheduler.step()  

            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)
            cv_scores.append(weighted_r2)
            LR_records.append(scheduler.get_last_lr()[0])



            # ===  ä¿å­˜  ===
            if (epoch + 1) % save_interval == 0:
                save_path = save_dir / f"model_weights_fold{fold}_epoch{epoch+1}.pt"
                torch.save(model.state_dict(), save_path)

            # === æ—¶é—´è®¡ç®— ===
            epoch_time = time.time() - epoch_start
            
            # ====== æ›´æ–°æ»‘åŠ¨çª—å£ï¼ˆè·³è¿‡ç¬¬ 0 è½®ï¼‰ ======
            if epoch > 0:
                epoch_times.append(epoch_time)
                if len(epoch_times) > 50:
                    epoch_times.pop(0)  # å›ºå®šé•¿åº¦ä¸º 10

            # ====== è®¡ç®— ETA ======
            now_str = datetime.now().strftime("%H:%M:%S")

            progress = (epoch + 1) + fold * epochs
            all_progress = epochs * n_splits
            remaining_epochs = all_progress - progress

            if len(epoch_times) == 0:
                eta_seconds = float('nan')  # ç¬¬ 0 è½®ä¸æ˜¾ç¤º ETA
                avg_epoch_time = epoch_time
            else:
                avg_epoch_time = np.mean(epoch_times)
                eta_seconds = avg_epoch_time * remaining_epochs

            # ====== é¢„è®¡å®Œæˆæ—¶é—´ ======
            if not np.isnan(eta_seconds):
                eta_time = datetime.now() + timedelta(seconds=eta_seconds)
                eta_time = eta_time.replace(microsecond=0)
                days_diff = (eta_time.date() - datetime.now().date()).days
                eta_str = f"T+{days_diff} " + eta_time.strftime("%H:%M:%S") if days_diff > 0 else eta_time.strftime("%H:%M:%S")
            else:
                eta_str = "--:--:--"



            


            # === ğŸ–¨ï¸ æ‰“å°ä¿¡æ¯ï¼ˆå¸¦æ—¶é—´ + é¢„è®¡ç»“æŸæ—¶é—´ï¼‰ ===
            print(
                f"[{now_str}]ğŸ§©[{progress/all_progress*100:.2f}%] Fold{fold+1:2d}/{n_splits} "
                f"Epoch {epoch+1:3d}/{epochs} | "
                f"Train={avg_train_loss:.4f} | "
                f"Val={avg_val_loss:.4f} | "
                f"CV={weighted_r2:.4f} | "
                f"lr={scheduler.get_last_lr()[0]:.6f} | "
                f"{avg_epoch_time:.2f}s/it | "
                f"ETAâ‰ˆ{eta_str}\n",
                end="\r",
                flush=True
            )

        # ä¿å­˜å®Œæ•´ fold
        torch.save(model.state_dict(), save_dir / f"model_weights_fold{fold}_final.pt")
        fold_train_losses.append(train_losses)
        fold_val_losses.append(val_losses)
        fold_cv_scores.append(cv_scores)
        fold_LR_records.append(LR_records)

        os.system('cls' if os.name == 'nt' else 'clear')


    # ğŸ”¹ ä¿å­˜ç»“æœ
    max_epochs = max(len(x) for x in fold_train_losses)
    df_out = pd.DataFrame({"Epoch": range(1, max_epochs + 1)})

    for i, (train_list, val_list, cv_list, lr_list) in enumerate(zip(fold_train_losses, fold_val_losses, fold_cv_scores, fold_LR_records), start=1):
        df_out[f"Train_Loss_Fold{i}"] = train_list + [None]*(max_epochs-len(train_list))
        df_out[f"Val_Loss_Fold{i}"]   = val_list   + [None]*(max_epochs-len(val_list))
        df_out[f"CV_Fold{i}"]         = cv_list    + [None]*(max_epochs-len(cv_list))
        df_out[f"LR_Fold{i}"]         = lr_list    + [None]*(max_epochs-len(lr_list))

    out_path = Path(save_dir) / "fold_metrics.xlsx"
    df_out.to_excel(out_path, index=False)
    print(f"âœ… è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {out_path}")

# ğŸ“˜ è®­ç»ƒæ•°æ®è¯»å–ä¸é¢„å¤„ç†
def load_and_prepare_train_df():
    # 1ï¸âƒ£ è¯»å–åŸå§‹æ•°æ®
    df_file_path = Path(DIRS["dir"]) / "train.csv"
    df = pd.read_csv(df_file_path)
    # show_df_info(df, "train.csv")

    # 2ï¸âƒ£ æå–å”¯ä¸€ IDï¼ˆä¾‹å¦‚ "ID1011485656__Dry_Green_g" â†’ "ID1011485656"ï¼‰
    df["ID"] = df["sample_id"].str.split("__").str[0]

    # 3ï¸âƒ£ å°† ID åˆ—ç§»åŠ¨åˆ°æœ€å‰é¢
    df = move_column_first(df, "ID")
    # show_df_info(df, "df")

    # 4ï¸âƒ£ ç›®æ ‡å€¼é€è§†ï¼ˆè¡Œè½¬åˆ—ï¼‰
    df_targets = (
        df
        .pivot_table(
            index="ID",
            columns="target_name",
            values="target",
            aggfunc="first"
        )
        .reset_index()
    )
    df_targets.columns.name = None  # å»æ‰å¤šçº§åˆ—åå±‚æ¬¡
    # show_df_info(df_targets, "df_targets")

    # 5ï¸âƒ£ æå–å…ƒä¿¡æ¯ï¼ˆæ¯ä¸ª ID ä»…ä¿ç•™ä¸€è¡Œï¼‰
    meta_cols = [
        "ID", "image_path", "Sampling_Date", "State",
        "Species", "Pre_GSHH_NDVI", "Height_Ave_cm"
    ]
    df_meta = df[meta_cols].drop_duplicates(subset="ID")
    # show_df_info(df_meta, "df_meta")

    # 6ï¸âƒ£ åˆå¹¶å…ƒä¿¡æ¯ä¸ç›®æ ‡æ•°æ®
    df_train = pd.merge(df_meta, df_targets, on="ID", how="left")
    show_df_info(df_train, "df_train")

    
    return df_train








# # è®­ç»ƒéƒ¨åˆ† æœ¬åœ°è¿è¡Œ

# âš™ï¸ æ¨¡å‹ä¸è®­ç»ƒé…ç½®
# 1ï¸âƒ£ æŸå¤±æƒé‡è®¾ç½®ï¼ˆé’ˆå¯¹ä¸»è¦ç›®æ ‡ï¼‰
weights = {
    "Dry_Green_g" : 0.1,
    "GDM_g"       : 0.2,
    "Dry_Total_g" : 0.5,
}

# 2ï¸âƒ£ æ¨¡å‹é¢„æµ‹ä¸è®­ç»ƒç›®æ ‡åˆ—
model_target_cols = [
    "Dry_Green_g",
    "GDM_g",
    "Dry_Total_g",
]

target_cols = [
    "Dry_Green_g",
    "Dry_Dead_g",
    "Dry_Clover_g",
    "GDM_g",
    "Dry_Total_g",
]

# 3ï¸âƒ£ è®­ç»ƒè¶…å‚æ•°é…ç½®
config = {
    "epochs"       : 180,
    "freeze_ratio" : 0.5,
    "batch_size"   : 20,
    "lr"           : 1e-4,
    "n_splits"     : 5,
    "save_interval": 20,
    "img_size"     : 768,

    
}



if __name__ == "__main__":
    
    # å¯åŠ¨è®­ç»ƒ ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

    # æœ¬åœ°æœºå™¨æ‰§è¡Œï¼ˆhao-2ï¼‰
    if socket.gethostname() == "hao-2":
        # ç”Ÿæˆæ—¶é—´æˆ³ä¸ç»“æœç›®å½•
        time_str = datetime.now().strftime("%Y-%m-%d %H-%M-%S")
        print(time_str)

        history_DIR = Path(DIRS["model"], time_str)
        os.makedirs(history_DIR, exist_ok=True)

        # ä¿å­˜é…ç½®æ–‡ä»¶
        config["time_str"] = time_str
        config_path = history_DIR / "config.json"
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=4, ensure_ascii=False)
        print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {config_path}")

        # è¯»å–è®­ç»ƒæ•°æ®
        df_train = load_and_prepare_train_df()

        # âœ… è‹¥å†…å­˜å…è®¸ï¼Œå¯å¯ç”¨ RAM ç¼“å­˜
        # image_cache = preload_images_to_ram(df_train, DIRS["dir"])
        image_cache = None

        # âœ… å¯ç”¨ cuDNN è‡ªåŠ¨ä¼˜åŒ–
        torch.multiprocessing.freeze_support()
        torch.backends.cudnn.benchmark = True

        # ğŸš€ å¯åŠ¨ KFold è®­ç»ƒ
        train_with_groupkfold(
            df_train             = df_train,
            cache                = image_cache,
            save_dir             = history_DIR,
            model_target_cols    = model_target_cols,
            get_train_transforms = get_train_transforms,
            get_valid_transforms = get_valid_transforms,
            weights              = weights,
            freeze_ratio         = config["freeze_ratio"],
            batch_size           = config["batch_size"],
            epochs               = config["epochs"],
            lr                   = config["lr"],
            device               = device,
            n_splits             = config["n_splits"],
            save_interval        = config["save_interval"],
        )

        print("\nâœ… å…¨éƒ¨è®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜åœ¨ï¼š", history_DIR)

